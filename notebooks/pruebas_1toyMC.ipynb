{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2672a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghcp/miniconda3/envs/haza_wokr_env/lib/python3.8/site-packages/zfit/__init__.py:63: UserWarning: TensorFlow warnings are by default suppressed by zfit. In order to show them, set the environment variable ZFIT_DISABLE_TF_WARNINGS=0. In order to suppress the TensorFlow warnings AND this warning, set ZFIT_DISABLE_TF_WARNINGS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghcp/miniconda3/envs/haza_wokr_env/lib/python3.8/site-packages/zfit/core/basemodel.py:199: UserWarning: For the future, also decorate _pdf with @supports and specify what you support (such as 'norm=True' to keep the same behavior as before)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import zfit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from iminuit import Minuit\n",
    "import warnings\n",
    "import os\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from PDFs import (FullAngular_Physical_PDF, FullAngular_Transformed_PDF, get_inverse_values, apply_transformation_equations, get_physical_region_scan)\n",
    "import matplotlib.pyplot as plt\n",
    "import cmsstyle\n",
    "import sys\n",
    "from plot_tools import create_axes_for_pulls, plot_model \n",
    "import plot_tools \n",
    "import customPDFs\n",
    "import mass_models\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import os, sys\n",
    "import common_tools\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from itertools import combinations\n",
    "import math\n",
    "import time\n",
    "from scipy.stats import chi2 as _chi2\n",
    "from scipy.integrate import quad\n",
    "from zfit import z\n",
    "hep.style.use(\"CMS\")\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f00bd",
   "metadata": {},
   "source": [
    "# Funciones importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81caf983",
   "metadata": {},
   "outputs": [],
   "source": [
    "zfit.settings.set_seed(42)\n",
    "np.random.seed(42)\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "def calculate_jacobian_numerical(func, params, keys_out, epsilon=1e-5):\n",
    "    \"\"\"Calcula la matriz Jacobiana numéricamente.\"\"\"\n",
    "    n_params = len(params)\n",
    "    n_out = len(keys_out)\n",
    "    J = np.zeros((n_out, n_params))\n",
    "    \n",
    "    def func_wrapper(p_args):\n",
    "        res_dict = func(*p_args)\n",
    "        return np.array([res_dict[k] for k in keys_out])\n",
    "\n",
    "    for i in range(n_params):\n",
    "        p_plus = np.copy(params)\n",
    "        p_minus = np.copy(params)\n",
    "        p_plus[i] += epsilon\n",
    "        p_minus[i] -= epsilon\n",
    "        \n",
    "        f_plus = func_wrapper(p_plus)\n",
    "        f_minus = func_wrapper(p_minus)\n",
    "        \n",
    "        deriv = (f_plus - f_minus) / (2 * epsilon)\n",
    "        J[:, i] = deriv\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5dae3",
   "metadata": {},
   "source": [
    "# Generación de MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48a0e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Directorios listos:\n",
      "    - Plots/Transformed_Space_vFinal\n",
      "    - Plots/Physical_Space_Zoom_vFinal\n",
      "    - Plots/Physical_Space_Full_vFinal\n",
      ">>> Generando datos (Toy MC)...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#MAIN function \n",
    "folder_trans = \"Plots/Transformed_Space_vFinal\"\n",
    "folder_phys_zoom = \"Plots/Physical_Space_Zoom_vFinal\"\n",
    "folder_phys_full = \"Plots/Physical_Space_Full_vFinal\"\n",
    "\n",
    "for f in [folder_trans, folder_phys_zoom, folder_phys_full]:\n",
    "    os.makedirs(f, exist_ok=True)\n",
    "\n",
    "print(f\">>> Directorios listos:\\n    - {folder_trans}\\n    - {folder_phys_zoom}\\n    - {folder_phys_full}\")\n",
    "# GENERACIÓN (toys) ---\n",
    "obs = zfit.Space('cosThetaL', limits=(-1, 1)) * zfit.Space('cosThetaK', limits=(-1, 1)) * zfit.Space('phi', limits=(-np.pi, np.pi))\n",
    "\n",
    "# Valores verdaderos físicos lhcb\n",
    "true_vals_phys = [0.684, 0.014, 0.029, 0.050, -0.145, -0.136, -0.204, 0.077]\n",
    "phys_keys = ['FL', 'S3', 'S9', 'AFB', 'S4', 'S7', 'S5', 'S8']\n",
    "true_dict = dict(zip(phys_keys, true_vals_phys))\n",
    "\n",
    "print(\">>> Generando datos (Toy MC)...\")\n",
    "pdf_gen = FullAngular_Physical_PDF(obs, *true_vals_phys)\n",
    "sampler = pdf_gen.create_sampler(n=2000) \n",
    "sampler.resample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e862caa",
   "metadata": {},
   "source": [
    "Fit in transformed space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09364c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 2. Ejecutando Minimización (Minuit)...\n",
      ">>> 3. Calculando Errores MINOS...\n",
      "\n",
      "================================================================================\n",
      ">>> Errores MINOS (Espacio Transformado)\n",
      "================================================================================\n",
      "PARAM      | VALOR      | ERROR -    | ERROR +    | VERDAD    \n",
      "--------------------------------------------------------------------------------\n",
      "rFL        | 0.3667     | -0.0334     | +0.0346    | 0.3861\n",
      "rS3        | 0.0596     | -0.1200     | +0.1216    | 0.0888\n",
      "rS9        | 0.1201     | -0.1300     | +0.1391    | 0.1864\n",
      "rAFB       | 0.0773     | -0.0590     | +0.0571    | 0.2189\n",
      "rS4        | -0.5490     | -0.1600     | +0.1373    | -0.7812\n",
      "rS7        | -0.3659     | -0.0888     | +0.0734    | -0.4293\n",
      "rS5        | -0.3709     | -0.0594     | +0.0553    | -0.4484\n",
      "rS8        | 0.3803     | -0.1192     | +0.1356    | 0.3654\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      ">>> Errores Gaussianos (Matriz de Covarianza Propagada)\n",
      "================================================================================\n",
      "PARAM      | VALOR      | ERROR (+/-)     | VERDAD    \n",
      "--------------------------------------------------------------------------------\n",
      "FL         | 0.6755     | +/- 0.0149      | 0.6840\n",
      "S3         | 0.0097     | +/- 0.0194      | 0.0140\n",
      "S9         | 0.0193     | +/- 0.0213      | 0.0290\n",
      "AFB        | 0.0186     | +/- 0.0139      | 0.0500\n",
      "S4         | -0.1135     | +/- 0.0235      | -0.1450\n",
      "S7         | -0.1378     | +/- 0.0236      | -0.1360\n",
      "S5         | -0.1710     | +/- 0.0235      | -0.2040\n",
      "S8         | 0.0818     | +/- 0.0240      | 0.0770\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "raw_init = get_inverse_values(true_vals_phys)\n",
    "r_keys = ['rFL', 'rS3', 'rS9', 'rAFB', 'rS4', 'rS7', 'rS5', 'rS8']\n",
    "param_names_fit = [f\"{k}_fit\" for k in r_keys]\n",
    "\n",
    "true_vals_trans_dict = dict(zip(param_names_fit, raw_init))\n",
    "\n",
    "params = {k: zfit.Parameter(p_name, v, step_size=0.01) for k, p_name, v in zip(r_keys, param_names_fit, raw_init)}\n",
    "pdf_fit = FullAngular_Transformed_PDF(obs, params['rFL'], params['rS3'], params['rS9'], params['rAFB'],params['rS4'], params['rS7'], params['rS5'], params['rS8'])\n",
    "\n",
    "print(\">>> 2. Ejecutando Minimización (Minuit)...\")\n",
    "nll = zfit.loss.UnbinnedNLL(model=pdf_fit, data=sampler)\n",
    "minimizer = zfit.minimize.Minuit(tol=0.01) \n",
    "result = minimizer.minimize(nll)\n",
    "m = result.info['minuit'] \n",
    "\n",
    "print(\">>> 3. Calculando Errores MINOS...\")\n",
    "m.minos() \n",
    "\n",
    "# =======================================\n",
    "# ESPACIO TRANSFORMADO (VALORES DE MINUIT)\n",
    "# =======================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\">>> Errores MINOS (Espacio Transformado)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'PARAM':<10} | {'VALOR':<10} | {'ERROR -':<10} | {'ERROR +':<10} | {'VERDAD':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# guarda los valores CORRECTOS de Minuit para usarlos después\n",
    "minuit_best_values = []\n",
    "\n",
    "for rk, pname in zip(r_keys, param_names_fit):\n",
    "    val = m.values[pname]\n",
    "    minuit_best_values.append(val)\n",
    "    \n",
    "    err_low = m.merrors[pname].lower  \n",
    "    err_high = m.merrors[pname].upper \n",
    "    truth = true_vals_trans_dict[pname]\n",
    "    \n",
    "    print(f\"{rk:<10} | {val:.4f}     | {err_low:.4f}     | +{err_high:.4f}    | {truth:.4f}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ===========================================\n",
    "# ESPACIO FÍSICO (CORREGIDO PARA USAR MINUIT)\n",
    "# ===========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\">>> Errores Gaussianos (Matriz de Covarianza Propagada)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# recupera la matriz de covarianza\n",
    "param_objs_ordered = [params[k] for k in r_keys]\n",
    "cov_trans = result.covariance(params=param_objs_ordered)\n",
    "\n",
    "# IMPORTANTE usar los valores de MINUIT, no los de zfit.Parameter (revisar pq)\n",
    "best_fit_r_values = np.array(minuit_best_values)\n",
    "\n",
    "# Jacobiano y Propagación\n",
    "J = calculate_jacobian_numerical(apply_transformation_equations, best_fit_r_values, phys_keys)\n",
    "cov_phys = J @ cov_trans @ J.T\n",
    "phys_errors_sigma = np.sqrt(np.diag(cov_phys))\n",
    "phys_errors_dict = dict(zip(phys_keys, phys_errors_sigma))\n",
    "\n",
    "# 4. Tabla (Calculada con los valores de Minuit)\n",
    "print(f\"{'PARAM':<10} | {'VALOR':<10} | {'ERROR (+/-)':<15} | {'VERDAD':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_fit_phys_dict = apply_transformation_equations(*best_fit_r_values)\n",
    "\n",
    "for k in phys_keys:\n",
    "    val = best_fit_phys_dict[k]\n",
    "    err = phys_errors_dict[k]\n",
    "    tru = true_dict[k]\n",
    "    print(f\"{k:<10} | {val:.4f}     | +/- {err:.4f}      | {tru:.4f}\")\n",
    "print(\"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc25af",
   "metadata": {},
   "source": [
    "# Allowed region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b1116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando cálculo de 28 fronteras...\n",
      "[1/28] FL_vs_S3 calculado en 1.56s\n",
      "[2/28] FL_vs_S9 calculado en 5.77s\n",
      "[3/28] FL_vs_AFB calculado en 5.55s\n",
      "[4/28] FL_vs_S4 calculado en 4.86s\n",
      "[5/28] FL_vs_S7 calculado en 3.92s\n",
      "[6/28] FL_vs_S5 calculado en 3.91s\n",
      "[7/28] FL_vs_S8 calculado en 4.83s\n",
      "[8/28] S3_vs_S9 calculado en 4.11s\n",
      "[9/28] S3_vs_AFB calculado en 3.92s\n",
      "[10/28] S3_vs_S4 calculado en 5.45s\n",
      "[11/28] S3_vs_S7 calculado en 5.47s\n",
      "[12/28] S3_vs_S5 calculado en 5.43s\n",
      "[13/28] S3_vs_S8 calculado en 5.47s\n",
      "[14/28] S9_vs_AFB calculado en 4.46s\n",
      "[15/28] S9_vs_S4 calculado en 6.37s\n",
      "[16/28] S9_vs_S7 calculado en 6.22s\n",
      "[17/28] S9_vs_S5 calculado en 6.16s\n",
      "[18/28] S9_vs_S8 calculado en 6.43s\n",
      "[19/28] AFB_vs_S4 calculado en 6.53s\n",
      "[20/28] AFB_vs_S7 calculado en 6.42s\n",
      "[21/28] AFB_vs_S5 calculado en 6.25s\n",
      "[22/28] AFB_vs_S8 calculado en 11.53s\n",
      "[23/28] S4_vs_S7 calculado en 8.56s\n",
      "[24/28] S4_vs_S5 calculado en 9.21s\n",
      "[25/28] S4_vs_S8 calculado en 9.53s\n",
      "[26/28] S7_vs_S5 calculado en 8.89s\n",
      "[27/28] S7_vs_S8 calculado en 9.71s\n",
      "[28/28] S5_vs_S8 calculado en 9.60s\n",
      "\n",
      "¡Datos de fronteras guardados en Plots/BoundaryData/theoretical_boundaries.npz!\n",
      "Generando ploteos con estilo CMS...\n",
      "Hecho. Gráficas CMS guardadas en: Plots/BoundaryData\n"
     ]
    }
   ],
   "source": [
    "def constraints(params):\n",
    "    \"\"\"\n",
    "    Mapeo de las 5 Desigualdades Físicas.\n",
    "    \"\"\"\n",
    "    FL, S3, S9, AFB, S4, S7, S5, S8 = params\n",
    "    \n",
    "    # --- Desigualdad 1: 0 <= FL <= 1 ---\n",
    "    # Nota: Aunque esta se suele manejar en 'bounds', si queremos ser\n",
    "    # rigurosos en esta función, podemos retornarla, aunque el optimizador\n",
    "    # ya la fuerce en los límites de caja.\n",
    "    # Se desdobla en dos: FL >= 0 y 1 - FL >= 0\n",
    "    # Pero para el conteo de desigualdades complejas, nos enfocamos en las acopladas:\n",
    "    \n",
    "    # |S3| <= 0.5 * (1 - FL)\n",
    "    # equivale a: (0.5*(1-FL))^2 - S3^2 >= 0\n",
    "    c2 = 0.25 * (1 - FL)**2 - S3**2\n",
    "    \n",
    "    # S3^2 + 4/9 AFB^2 + S9^2 <= 1/4 (1 - FL)^2\n",
    "    # Pasamos todo a un lado: RHS - LHS >= 0\n",
    "    c3 = 0.25 * (1 - FL)**2 - (S3**2 + (4.0/9.0)*AFB**2 + S9**2)\n",
    "    \n",
    "    # 4 S4^2 + S7^2 <= FL (1 - FL - 2 S3)\n",
    "    # RHS - LHS >= 0\n",
    "    c4 = FL * (1 - FL - 2*S3) - (4*S4**2 + S7**2)\n",
    "    \n",
    "    # S5^2 + 4 S8^2 <= FL (1 - FL + 2 S3)\n",
    "    # RHS - LHS >= 0\n",
    "    c5 = FL * (1 - FL + 2*S3) - (S5**2 + 4*S8**2)\n",
    "    \n",
    "    return np.array([c2, c3, c4, c5])\n",
    "\n",
    "\n",
    "\n",
    "def get_profiled_boundary(x_idx, y_idx, n_steps=60):\n",
    "    \n",
    "    # Encontrar los límites REALES de X permitidos \n",
    "    # En lugar de usar rangos fijos, preguntamos al optimizador hasta dónde llega X.\n",
    "    \n",
    "    def objective_min_x(p): return p[x_idx]\n",
    "    def objective_max_x(p): return -p[x_idx]\n",
    "    def phys_constraints(p): return constraints(p)\n",
    "    \n",
    "    cons = [{'type': 'ineq', 'fun': phys_constraints}]\n",
    "    bounds_opt = [(0, 1)] + [(-1, 1)]*7\n",
    "    \n",
    "    # Semilla central \n",
    "    x0 = np.array([0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    # Buscamos X_min real\n",
    "    res_xmin = minimize(objective_min_x, x0, method='SLSQP', bounds=bounds_opt, constraints=cons, tol=1e-6)\n",
    "    real_start = res_xmin.fun if res_xmin.success else 0.0\n",
    "    \n",
    "    # Buscamos X_max real\n",
    "    res_xmax = minimize(objective_max_x, x0, method='SLSQP', bounds=bounds_opt, constraints=cons, tol=1e-6)\n",
    "    real_end = -res_xmax.fun if res_xmax.success else 1.0\n",
    "    \n",
    "    # escanea EXACTAMENTE entre esos límites encontrados\n",
    "    # Usamos un margen epsilon mucho más pequeño, solo para estabilidad\n",
    "    epsilon = 1e-5 \n",
    "    x_vals = np.linspace(real_start + epsilon, real_end - epsilon, n_steps)\n",
    "    \n",
    "    y_min_vals = []\n",
    "    y_max_vals = []\n",
    "    valid_x = []\n",
    "    bounds = [(0, 1)] + [(-1, 1)]*7\n",
    "    base_guesses = [...]\n",
    "\n",
    "    # base_guesses = [\n",
    "    #     # Centro\n",
    "    #     np.array([0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "    #     # Extremos de FL\n",
    "    #     np.array([0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "    #     np.array([0.99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "    #     # Combinaciones de signos para parámetros acoplados\n",
    "    #     np.array([0.3, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]),\n",
    "    #     np.array([0.3, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1, -0.1]),\n",
    "    #     # Punto con FL=0.5, S3 máximo/minimo permitido\n",
    "    #     np.array([0.5, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "    #     np.array([0.5, -0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "    # ]\n",
    "    # --- SEMILLAS ---\n",
    "    base_guesses = [\n",
    "        np.array([0.5,  0.0, 0,0,0,0,0,0]), # Centro\n",
    "        np.array([0.5,  0.2, 0,0,0,0,0,0]), # S3 positivo\n",
    "        np.array([0.5, -0.2, 0,0,0,0,0,0]), # S3 negativo\n",
    "        # Semilla para FL -> 0 (Arregla los cortes en V de S9 vs S3)\n",
    "        np.array([0.01, 0.0, 0,0,0,0,0,0]), \n",
    "        # Semilla para FL -> 1 (Arregla la punta del triángulo AFB vs FL)\n",
    "        np.array([0.99, 0.0, 0,0,0,0,0,0]), \n",
    "    ]\n",
    "\n",
    "    for x_val in x_vals:\n",
    "        def objective_min(p): return p[y_idx]\n",
    "        def objective_max(p): return -p[y_idx]\n",
    "        def fix_x_constraint(p): return p[x_idx] - x_val\n",
    "        def phys_constraints(p): return constraints(p)\n",
    "        cons = [{'type': 'eq', 'fun': fix_x_constraint},{'type': 'ineq', 'fun': phys_constraints}]\n",
    "        best_min = np.inf\n",
    "        best_max = -np.inf\n",
    "        found_valid_min = False\n",
    "        found_valid_max = False\n",
    "        \n",
    "        for seed in base_guesses:\n",
    "            x0 = seed.copy()\n",
    "            x0[x_idx] = x_val \n",
    "            \n",
    "            # buscar MÁXIMO\n",
    "            res_max = minimize(objective_max, x0, method='SLSQP', bounds=bounds, constraints=cons, tol=1e-4)\n",
    "            if res_max.success and np.min(constraints(res_max.x)) > -1e-5:\n",
    "                val = -res_max.fun\n",
    "                if val > best_max: \n",
    "                    best_max = val\n",
    "                    found_valid_max = True\n",
    "\n",
    "            # buscar MÍNIMO\n",
    "            res_min = minimize(objective_min, x0, method='SLSQP', bounds=bounds, constraints=cons, tol=1e-4)\n",
    "            if res_min.success and np.min(constraints(res_min.x)) > -1e-5:\n",
    "                val = res_min.fun\n",
    "                if val < best_min: \n",
    "                    best_min = val\n",
    "                    found_valid_min = True\n",
    "\n",
    "        if found_valid_min and found_valid_max and best_max >= best_min:\n",
    "            valid_x.append(x_val)\n",
    "            y_max_vals.append(best_max)\n",
    "            y_min_vals.append(best_min)\n",
    "    \n",
    "    return np.array(valid_x), np.array(y_min_vals), np.array(y_max_vals)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_boundaries(n_steps=150):\n",
    "    params = ['FL', 'S3', 'S9', 'AFB', 'S4', 'S7', 'S5', 'S8']\n",
    "    pairs = list(combinations(enumerate(params), 2))\n",
    "    os.makedirs(\"Plots/BoundaryData\", exist_ok=True)\n",
    "    boundary_results = {}\n",
    "    print(f\"Iniciando cálculo de {len(pairs)} fronteras...\")\n",
    "    \n",
    "    for i, ((idx_x, name_x), (idx_y, name_y)) in enumerate(pairs):\n",
    "        start = time.time()\n",
    "        vx, v_min, v_max = get_profiled_boundary(idx_x, idx_y, n_steps=n_steps)\n",
    "        \n",
    "        # guarda en un diccionario \n",
    "        key = f\"{name_x}_vs_{name_y}\"\n",
    "        boundary_results[key] = {'x': vx, 'min': v_min, 'max': v_max}\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"[{i+1}/28] {key} calculado en {elapsed:.2f}s\")\n",
    "\n",
    "    np.savez_compressed(\"Plots/BoundaryData/theoretical_boundaries.npz\", **boundary_results)\n",
    "    print(\"\\n¡Datos de fronteras guardados en Plots/BoundaryData/theoretical_boundaries.npz!\")\n",
    "\n",
    "save_boundaries(n_steps=200)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_from_saved_data(df_data):\n",
    "    data = np.load(\"Plots/BoundaryData/theoretical_boundaries.npz\", allow_pickle=True)\n",
    "    params = ['FL', 'S3', 'S9', 'AFB', 'S4', 'S7', 'S5', 'S8']\n",
    "    latex_labels = {'FL': r'$F_L$', 'S3': r'$S_3$', 'S9': r'$S_9$', 'AFB': r'$A_{FB}$', 'S4': r'$S_4$', 'S7': r'$S_7$', 'S5': r'$S_5$', 'S8': r'$S_8$'}\n",
    "    pairs = list(combinations(params, 2))\n",
    "    \n",
    "    output_dir = \"Plots/BoundaryData\"\n",
    "    os.makedirs(output_dir, exist_ok=True)    \n",
    "    print(\"Generando ploteos con estilo CMS...\")\n",
    "\n",
    "    for name_x, name_y in pairs:\n",
    "        key = f\"{name_x}_vs_{name_y}\"\n",
    "        if key not in data: continue\n",
    "        res = data[key].item()\n",
    "        vx, v_min, v_max = res['x'], res['min'], res['max']\n",
    "        \n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        ax.scatter(df_data[name_x], df_data[name_y], s=1, alpha=1, c='b', label='Monte Carlo', rasterized=True, marker='o', linewidths=0)   \n",
    "        ax.plot(vx, v_max, color='red', linestyle='--', lw=2, label='Theoretical Limit')\n",
    "        ax.plot(vx, v_min, color='red', linestyle='--', lw=2)\n",
    "        #ax.fill_between(vx, v_min, v_max, color='red', alpha=0.2, label='Physical Region')\n",
    "        #ax.fill_between( vx, v_min, v_max, facecolor=\"none\", edgecolor=\"red\", hatch='////', alpha=0.5, label='Physical Region')\n",
    "        ax.set_xlabel(latex_labels[name_x], fontsize=12)\n",
    "        ax.set_ylabel(latex_labels[name_y], fontsize=12)\n",
    "        ax.grid(True, linestyle=':', alpha=0.4)\n",
    "        if name_x == 'FL': ax.set_xlim(0, 1)\n",
    "        if name_y == 'FL': ax.set_ylim(0, 1)\n",
    "        ax.legend(loc='best', fontsize=12, frameon=True, framealpha=0.8, edgecolor='white')\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20, length=10, width=1)\n",
    "        ax.tick_params(axis='both', which='minor', length=5, width=1)\n",
    "        hep.cms.label(data=False, rlabel=\"Theoretical Phase Space\", loc=0, ax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/{key}_CMS.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"Hecho. Gráficas CMS guardadas en: {output_dir}\")\n",
    "\n",
    "\n",
    "\n",
    "#GENERACIÓN DEL MAPA FÍSICO\n",
    "df_phys_region = get_physical_region_scan(n_points=1000000)\n",
    "indices = list(range(8))\n",
    "pairs_indices = list(combinations(indices, 2))\n",
    "total_plots = len(pairs_indices)\n",
    "\n",
    "if 'df_phys_region' in locals():\n",
    "    plot_from_saved_data(df_phys_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d1ab4",
   "metadata": {},
   "source": [
    "# Contornos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724118df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Datos de fronteras cargados desde: Plots/BoundaryData/theoretical_boundaries.npz\n",
      "    [28/28] S5 vs S8 ....\n",
      ">>> Generación de plots completada.\n"
     ]
    }
   ],
   "source": [
    "plt.style.use(hep.style.CMS)\n",
    "boundary_file = \"Plots/BoundaryData/theoretical_boundaries.npz\"\n",
    "boundary_data = None\n",
    "\n",
    "if os.path.exists(boundary_file):\n",
    "    boundary_data = np.load(boundary_file, allow_pickle=True)\n",
    "    print(f\">>> Datos de fronteras cargados desde: {boundary_file}\")\n",
    "else:\n",
    "    print(f\">>> No se encontró {boundary_file}.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, (idx_x, idx_y) in enumerate(pairs_indices):\n",
    "    \n",
    "    rx, ry = param_names_fit[idx_x], param_names_fit[idx_y]\n",
    "    px, py = phys_keys[idx_x], phys_keys[idx_y]\n",
    "    print(f\"    [{i+1}/{total_plots}] {px} vs {py} ...\", end=\"\\r\")\n",
    "    contour_r = m.mncontour(rx, ry, cl=0.3935, size=50)\n",
    "\n",
    "    # -------------------\n",
    "    # Espacio Transformad\n",
    "    # --------------------\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(contour_r[:, 0], contour_r[:, 1], 'b-', linewidth=2, label=r'1$\\sigma$ Contour')\n",
    "    plt.plot(m.values[rx], m.values[ry], 's', color='blue', markersize=8, label='Best Fit', zorder=10)\n",
    "    true_tx = true_vals_trans_dict[rx]\n",
    "    true_ty = true_vals_trans_dict[ry]\n",
    "    plt.plot(true_tx, true_ty, 'P', color='red', markersize=12, markeredgecolor='k', label='True Value', zorder=15)\n",
    "\n",
    "    # minos Errors\n",
    "    val_x = m.values[rx]; val_y = m.values[ry]\n",
    "    minos_x_low = val_x + m.merrors[rx].lower; minos_x_high = val_x + m.merrors[rx].upper\n",
    "    minos_y_low = val_y + m.merrors[ry].lower; minos_y_high = val_y + m.merrors[ry].upper\n",
    "    plt.axvline(minos_x_low, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.axvline(minos_x_high, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.axhline(minos_y_low, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.axhline(minos_y_high, color='gray', linestyle='--', alpha=0.5)\n",
    "    width_x = minos_x_high - minos_x_low; width_y = minos_y_high - minos_y_low\n",
    "    margin = 0.4\n",
    "    plt.xlim(minos_x_low - width_x * margin, minos_x_high + width_x * margin)\n",
    "    plt.ylim(minos_y_low - width_y * margin, minos_y_high + width_y * margin)\n",
    "    plt.xlabel(rx); plt.ylabel(ry)\n",
    "    hep.cms.label(data=False, loc=0, rlabel=\"\") \n",
    "    plt.legend(loc='upper right', frameon=True)\n",
    "    plt.grid(True, alpha=0.2)\n",
    "    plt.savefig(f\"{folder_trans}/Trans_{rx}_vs_{ry}.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ---------------\n",
    "    # espacio físico\n",
    "    # ---------------\n",
    "    n_pts = len(contour_r)\n",
    "    r_matrix = np.tile(best_fit_r_values, (n_pts, 1))\n",
    "    r_matrix[:, idx_x] = contour_r[:, 0]\n",
    "    r_matrix[:, idx_y] = contour_r[:, 1]\n",
    "    \n",
    "    #  transformación inversa\n",
    "    trans_contour_dict = apply_transformation_equations(r_matrix[:, 0], r_matrix[:, 1], r_matrix[:, 2], r_matrix[:, 3], r_matrix[:, 4], r_matrix[:, 5], r_matrix[:, 6], r_matrix[:, 7])\n",
    "    cx_phys = trans_contour_dict[px]\n",
    "    cy_phys = trans_contour_dict[py]\n",
    "\n",
    "    # errores geometricos\n",
    "    x_min_cont = np.min(cx_phys); x_max_cont = np.max(cx_phys)\n",
    "    y_min_cont = np.min(cy_phys); y_max_cont = np.max(cy_phys)\n",
    "    bf_x = best_fit_phys_dict[px]\n",
    "    bf_y = best_fit_phys_dict[py]\n",
    "    err_x_up = x_max_cont - bf_x; err_x_down = bf_x - x_min_cont\n",
    "    err_y_up = y_max_cont - bf_y; err_y_down = bf_y - y_min_cont\n",
    "\n",
    "    # datos de frontera para cada par\n",
    "    boundary_x, boundary_min, boundary_max = None, None, None\n",
    "    if boundary_data is not None:\n",
    "        key_pair = f\"{px}_vs_{py}\"\n",
    "        if key_pair in boundary_data:\n",
    "            res = boundary_data[key_pair].item()\n",
    "            boundary_x = res['x']\n",
    "            boundary_min = res['min']\n",
    "            boundary_max = res['max']\n",
    "\n",
    "    def plot_physical(view_mode, x_lims=None, y_lims=None):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        \n",
    "        # region física permitida\n",
    "        if boundary_x is not None:\n",
    "            ax.plot(boundary_x, boundary_min, color='red', linestyle='--', linewidth=1.5, alpha=0.6, zorder=1)\n",
    "            ax.plot(boundary_x, boundary_max, color='red', linestyle='--', linewidth=1.5, alpha=0.6, zorder=1)\n",
    "            ax.fill_between(boundary_x, boundary_min, boundary_max, facecolor=\"none\", edgecolor=\"red\", hatch='///', alpha=0.2, zorder=1,label='Physical Region')\n",
    "\n",
    "        # contorno y best fit\n",
    "        ax.plot(cx_phys, cy_phys, color='black', linestyle='-', linewidth=2, label=r'1$\\sigma$ Contour', zorder=5)\n",
    "        ax.plot(bf_x, bf_y, marker='s', color='blue', markersize=8, linestyle='None', label='Best Fit', zorder=10)\n",
    "        ax.plot(true_dict[px], true_dict[py], marker='P', color='red', markersize=12, markeredgecolor='black', linestyle='None', label='True Value', zorder=11)\n",
    "        #errores contorno \n",
    "        ax.axvline(x_min_cont, color='red', linestyle=':', linewidth=1.5, alpha=0.6)\n",
    "        ax.axvline(x_max_cont, color='red', linestyle=':', linewidth=1.5, alpha=0.6)\n",
    "        ax.axhline(y_min_cont, color='red', linestyle=':', linewidth=1.5, alpha=0.6)\n",
    "        ax.axhline(y_max_cont, color='red', linestyle=':', linewidth=1.5, alpha=0.6)\n",
    "        ax.set_xlabel(px, fontsize=24)\n",
    "        ax.set_ylabel(py, fontsize=24)\n",
    "        hep.cms.label(data=False, loc=0, ax=ax, rlabel=\"\")\n",
    "        \n",
    "        # Texto \n",
    "        res_text = (rf\"${px} = {bf_x:.4f}^{{+{err_x_up:.4f}}}_{{-{err_x_down:.4f}}}$\" + \"\\n\" +rf\"${py} = {bf_y:.4f}^{{+{err_y_up:.4f}}}_{{-{err_y_down:.4f}}}$\")\n",
    "        if view_mode == 'Zoom':\n",
    "            ax.text(0.05, 0.93, res_text, transform=ax.transAxes, fontsize=18, verticalalignment='top', horizontalalignment='left',bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', pad=0.5))\n",
    "            if x_lims: ax.set_xlim(x_lims)\n",
    "            if y_lims: ax.set_ylim(y_lims)\n",
    "            \n",
    "        else: # Full View\n",
    "            ax.text(0.05, 0.93, res_text, transform=ax.transAxes, fontsize=16, verticalalignment='top', horizontalalignment='left', bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "            ax.text(0.95, 0.93, \"Full Range\", transform=ax.transAxes, fontsize=16, verticalalignment='top', horizontalalignment='right', color='gray')\n",
    "            # límites Full\n",
    "            if boundary_x is not None:\n",
    "                ax.set_xlim(0 if px == 'FL' else -1.05, 1 if px == 'FL' else 1.05)\n",
    "                ax.set_ylim(0 if py == 'FL' else -1.05, 1 if py == 'FL' else 1.05)\n",
    "            else:\n",
    "                ax.set_xlim(-1.1, 1.1); ax.set_ylim(-1.1, 1.1)\n",
    "                if px == 'FL': ax.set_xlim(-0.1, 1.1)\n",
    "                if py == 'FL': ax.set_ylim(-0.1, 1.1)\n",
    "        ax.legend(loc='best', fontsize=16, frameon=True, framealpha=0.8, edgecolor='white')        \n",
    "        ax.grid(True, linestyle=':', alpha=0.4)  \n",
    "        folder = folder_phys_zoom if view_mode == 'Zoom' else folder_phys_full\n",
    "        # bbox_inches='tight'           para que no se corten las etiquetas grandes de CMS\n",
    "        plt.savefig(f\"{folder}/Phys_{px}_vs_{py}_{view_mode}.png\", bbox_inches='tight', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    # Definir límites de zoom\n",
    "    mx = (x_max_cont - x_min_cont) * 0.4\n",
    "    my = (y_max_cont - y_min_cont) * 0.4\n",
    "    plot_physical('Zoom', x_lims=(x_min_cont-mx, x_max_cont+mx), y_lims=(y_min_cont-my, y_max_cont+my))\n",
    "    plot_physical('Full')\n",
    "print(\"\\n>>> Generación de plots completada.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b30ae",
   "metadata": {},
   "source": [
    "# Proyecciones v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e99f427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_cosK(x, FL):\n",
    "    return 0.75 * (1.0 - FL) * (1.0 - x**2) + 1.5 * FL * x**2\n",
    "\n",
    "def pdf_cosL(x, FL, AFB):\n",
    "    return 3.0/8.0 * (1.0 + FL) + 3.0/8.0 * (1.0 - 3.0 * FL) * x**2 + AFB * x\n",
    "\n",
    "def pdf_phi(x, S3, S9):\n",
    "    mod = S3 * np.cos(2*x) + S9 * np.sin(2*x)\n",
    "    return (1.0 / (2 * np.pi)) * (1.0 + mod)\n",
    "\n",
    "# utils -------------------------------------------------\n",
    "def _get_data_array(sampler):\n",
    "    if hasattr(sampler, \"numpy\"): return sampler.numpy()\n",
    "    if hasattr(sampler, \"values\"): return sampler.values\n",
    "    return np.asarray(sampler)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def _calc_chi2_standardized(obs, exp, n_params):\n",
    "    \"\"\"\n",
    "    Calcula el Chi2 de Neyman, grados de libertad (ndof), p-value y pulls.\n",
    "    Lógica basada en la aproximación de Neyman:\n",
    "    \"\"\"\n",
    "    # 1. Asegurar que trabajamos con arrays de numpy flotantes\n",
    "    obs = np.asarray(obs, dtype=np.float64)\n",
    "    exp = np.asarray(exp, dtype=np.float64)\n",
    "    \n",
    "    # Verificación de integridad básica\n",
    "    if obs.shape != exp.shape:\n",
    "        raise ValueError(f\"Dimensión incorrecta: Obs {obs.shape} != Exp {exp.shape}\")\n",
    "\n",
    "    # 2. Máscara: Neyman requiere Observados > 0\n",
    "    mask = obs > 0\n",
    "    obs_m = obs[mask]\n",
    "    exp_m = exp[mask]\n",
    "    \n",
    "    # 3. Cálculo de Chi2 (Neyman)\n",
    "    # Fórmula: sum( (O - E)^2 / O )\n",
    "    terms = np.square(obs_m - exp_m) / obs_m\n",
    "    chi2_val = np.sum(terms)\n",
    "    \n",
    "    # 4. Grados de Libertad (NDOF)\n",
    "    # NDOF = N_bins_con_datos - N_parametros\n",
    "    n_bins_w_data = np.sum(mask)\n",
    "    ndof = n_bins_w_data - n_params\n",
    "    \n",
    "    # 5. Cálculo del p-value con seguridad para NDOF <= 0\n",
    "    if ndof > 0:\n",
    "        p_val = 1 - stats.chi2.cdf(chi2_val, ndof)\n",
    "    else:\n",
    "        # Si tienes más parámetros que datos, el ajuste está indeterminado\n",
    "        p_val = np.nan \n",
    "        print(f\"Advertencia: NDOF <= 0 ({ndof}). Revisa tu binning o modelo.\")\n",
    "\n",
    "    # 6. Cálculo de Pulls\n",
    "    # Inicializamos en cero para mantener la forma original del array\n",
    "    pulls = np.zeros_like(obs)\n",
    "    # Pull = (Obs - Exp) / error_obs\n",
    "    # Solo calculamos donde mask es True para evitar warnings de división por cero\n",
    "    pulls[mask] = (obs_m - exp_m) / np.sqrt(obs_m)\n",
    "    \n",
    "    return chi2_val, ndof, p_val, pulls\n",
    "#---------------------------------------------------------\n",
    "def plot_analytical_projections(sampler, params, folder_out, n_bins=30):\n",
    "    os.makedirs(folder_out, exist_ok=True)\n",
    "    data = _get_data_array(sampler)\n",
    "    N_ev = len(data)\n",
    "\n",
    "    # Extraemos parámetros globales para usarlos en el texto del plot\n",
    "    FL  = float(params.get('FL', 0.0))\n",
    "    AFB = float(params.get('AFB', 0.0))\n",
    "    S3  = float(params.get('S3', 0.0))\n",
    "    S9  = float(params.get('S9', 0.0))\n",
    "\n",
    "    # Configuración: (Array, Función, LabelEje, NombreArchivo, Rango, ArgsFunc, N_Params_NDOF)\n",
    "    config = [\n",
    "        (data[:, 1], pdf_cosK, r'$\\cos\\theta_K$', 'CosThetaK', (-1, 1), \n",
    "         (FL,), 1),\n",
    "        \n",
    "        (data[:, 0], pdf_cosL, r'$\\cos\\theta_L$', 'CosThetaL', (-1, 1), \n",
    "         (FL, AFB), 2),\n",
    "        \n",
    "        (data[:, 2], pdf_phi,  r'$\\phi$',         'Phi',       (-np.pi, np.pi), \n",
    "         (S3, S9), 2)\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for arr, func, xlabel, name, limits, args, params_effective in config:\n",
    "        # --- A. Cálculos Matemáticos (Sin cambios) ---\n",
    "        counts, edges = np.histogram(arr, bins=n_bins, range=limits)\n",
    "        centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "        bin_widths = edges[1] - edges[0] # Necesario para tu código de plot\n",
    "        \n",
    "        # Modelo Esperado (Integrado)\n",
    "        expected = []\n",
    "        val_norm_integ, _ = quad(lambda x: func(x, *args), limits[0], limits[1]) \n",
    "        for i in range(n_bins):\n",
    "            bin_integ, _ = quad(lambda x: func(x, *args), edges[i], edges[i+1])\n",
    "            expected.append((bin_integ / val_norm_integ) * N_ev)\n",
    "        expected = np.array(expected)\n",
    "        \n",
    "        # Estadística\n",
    "        chi2_val, ndof, p_val, pulls = _calc_chi2_standardized(counts, expected, params_effective)\n",
    "        chi2_red = chi2_val / ndof # Necesario para tu texto\n",
    "\n",
    "        # Preparación de curva suave (Para tu código de plot)\n",
    "        x_fine = np.linspace(limits[0], limits[1], 1000)\n",
    "        y_fine_raw = func(x_fine, *args)\n",
    "        # Normalización matemática estricta para la curva visual\n",
    "        norm_fine = np.trapz(y_fine_raw, x_fine)\n",
    "        # Escalado a eventos por bin: PDF * N_total * Ancho_Bin\n",
    "        y_smooth_counts = (y_fine_raw / norm_fine) * N_ev * bin_widths\n",
    "\n",
    "        # ====================================================================\n",
    "        # B. SECCIÓN DE PLOTEO (Tu código insertado)\n",
    "        # ====================================================================\n",
    "        \n",
    "        #======\n",
    "        # plot\n",
    "        #======\n",
    "        fig = plt.figure(figsize=(9, 9))\n",
    "        gs = GridSpec(2, 1, height_ratios=[3.5, 1], hspace=0.08)\n",
    "        ax0 = fig.add_subplot(gs[0])\n",
    "        ax1 = fig.add_subplot(gs[1])\n",
    "\n",
    "        # datos\n",
    "        y_err_data = np.sqrt(counts)\n",
    "        ax0.errorbar(centers, counts, yerr=y_err_data, xerr=bin_widths/2.0, fmt='ks', markersize=4, elinewidth=1, capsize=2, label='Toy (data)')\n",
    "        \n",
    "        # curva continua\n",
    "        ax0.plot(x_fine, y_smooth_counts, '-', linewidth=1, label='Analytical PDF', color='b')\n",
    "        \n",
    "        max_data = np.max(counts + y_err_data)\n",
    "        max_model = np.max(y_smooth_counts) \n",
    "        y_max_plot = max(max_data, max_model)\n",
    "        \n",
    "        # margen 40%\n",
    "        ax0.set_ylim(0, y_max_plot * 1.5) \n",
    "        ax0.set_ylabel(f'Events / bin', fontsize=14)\n",
    "        ax0.set_xlim(limits)\n",
    "        ax0.set_xticklabels([])\n",
    "        ax0.grid(True, alpha=0.2)\n",
    "        ax0.legend(loc='best', fontsize=12, frameon=False)\n",
    "        hep.cms.label(data=False, loc=0, ax=ax0, rlabel=\"13 TeV\")\n",
    "        \n",
    "        # anotación\n",
    "        param_text = (rf'$F_L = {FL:.3f}$' + '\\n' + rf'$A_{{FB}} = {AFB:.3f}$' + '\\n' + rf'$S_3 = {S3:.3f}$' + '\\n' + rf'$S_9 = {S9:.3f}$' + '\\n' + rf'$\\chi^2/\\mathrm{{ndof}} = {chi2_val:.2f}/{ndof} = {chi2_red:.2f}$' + '\\n' +rf'$p$-value = {p_val:.3g}')\n",
    "        ax0.text(0.05, 0.95, param_text, transform=ax0.transAxes, fontsize=11, verticalalignment='top',bbox=dict( facecolor='white', alpha=0.01))\n",
    "        \n",
    "        #pulls\n",
    "        ax1.errorbar(centers, pulls, yerr=1.0,xerr=0, fmt='ks', markersize=1, elinewidth=1.0, capsize=0)          \n",
    "        ax1.axhline(0, color='black', linewidth=1.0, linestyle='-')\n",
    "        ax1.axhline(0, color='black', linestyle='', linewidth=1, alpha=0.4)\n",
    "        ax1.axhline(3, color='black', linestyle=':', linewidth=1, alpha=0.8, label=r'3$\\sigma$')\n",
    "        ax1.axhline(-3, color='black', linestyle=':', linewidth=1, alpha=0.8)\n",
    "        ax1.set_xlabel(xlabel, fontsize=14)\n",
    "        ax1.set_ylabel(r'Pull', fontsize=11)\n",
    "        ax1.set_xlim(limits)\n",
    "        ax1.set_ylim(-5.0, 5.0)\n",
    "        ax1.grid(True, alpha=0.2)\n",
    "        ax0.tick_params(axis='both', which='major', labelsize=14) \n",
    "        ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        outname = os.path.join(folder_out, f\"CMS_Proj_{name}_Chi2.png\")\n",
    "        plt.savefig(outname, bbox_inches='tight', dpi=150)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # ====================================================================\n",
    "        \n",
    "        # guardar resultados\n",
    "        results[name] = {'counts': counts, 'edges': edges, 'expected': expected, 'pulls': pulls, 'chi2': float(chi2_val), 'ndof': int(ndof), 'chi2_red': float(chi2_red), 'p_value': float(p_val), 'n_events': int(N_ev), 'plot_file': outname}\n",
    "        print(f\"[OK] {name}: χ2/ndof = {chi2_val:.2f}/{ndof} ({chi2_red:.2f}), p = {p_val:.3g}  — plot -> {outname}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9668120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] CosThetaK: χ2/ndof = 22.61/29 (0.78), p = 0.794  — plot -> Plots/Analytic_Projections/CMS_Proj_CosThetaK_Chi2.png\n",
      "[OK] CosThetaL: χ2/ndof = 21.48/28 (0.77), p = 0.805  — plot -> Plots/Analytic_Projections/CMS_Proj_CosThetaL_Chi2.png\n",
      "[OK] Phi: χ2/ndof = 18.22/28 (0.65), p = 0.92  — plot -> Plots/Analytic_Projections/CMS_Proj_Phi_Chi2.png\n",
      ">>> Proyecciones listas.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_proj = plot_analytical_projections(\n",
    "    sampler=sampler,\n",
    "    params=best_fit_phys_dict,\n",
    "    folder_out=\"Plots/Analytic_Projections\",n_bins=30)\n",
    "\n",
    "print(\">>> Proyecciones listas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347281d",
   "metadata": {},
   "source": [
    "# Proyecciones V2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47c883d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FullAngular_Physical_PDF(zfit.pdf.BasePDF):\n",
    "    def __init__(self, obs, FL, S3, S9, AFB, S4, S7, S5, S8, name=\"FullAngular_Physical_PDF\"):\n",
    "        params = {'FL': FL, 'S3': S3, 'S9': S9, 'AFB': AFB, 'S4': S4, 'S7': S7, 'S5': S5, 'S8': S8}\n",
    "        super().__init__(obs, params, name=name)\n",
    "    \n",
    "    def _unnormalized_pdf(self, x):\n",
    "        vars_list = z.unstack_x(x)\n",
    "        cos_l = vars_list[0]\n",
    "        cos_k = vars_list[1]\n",
    "        phi   = vars_list[2]\n",
    "        \n",
    "        sin_k = tf.sqrt(1.0 - cos_k**2)\n",
    "        sin_l = tf.sqrt(1.0 - cos_l**2)\n",
    "        sin2_k = sin_k**2\n",
    "        cos2_k = cos_k**2\n",
    "        sin2_l = sin_l**2\n",
    "        \n",
    "        cos2l_term = 2.0 * cos_l**2 - 1.0\n",
    "        sin2l_term = 2.0 * sin_l * cos_l\n",
    "        sin2k_term = 2.0 * sin_k * cos_k\n",
    "        \n",
    "        cos_phi = tf.cos(phi)\n",
    "        sin_phi = tf.sin(phi)\n",
    "        cos2_phi = tf.cos(2.0 * phi)\n",
    "        sin2_phi = tf.sin(2.0 * phi)\n",
    "\n",
    "        FL = self.params['FL']\n",
    "        S3 = self.params['S3']\n",
    "        S9 = self.params['S9']\n",
    "        AFB = self.params['AFB']\n",
    "        S4 = self.params['S4']\n",
    "        S7 = self.params['S7']\n",
    "        S5 = self.params['S5']\n",
    "        S8 = self.params['S8']\n",
    "        \n",
    "        term1 = 0.75 * (1.0 - FL) * sin2_k\n",
    "        term2 = FL * cos2_k\n",
    "        term3 = 0.25 * (1.0 - FL) * sin2_k * cos2l_term\n",
    "        term4 = -1.0 * FL * cos2_k * cos2l_term\n",
    "        term5 = S3 * sin2_k * sin2_l * cos2_phi\n",
    "        term6 = S4 * sin2k_term * sin2l_term * cos_phi\n",
    "        term7 = S5 * sin2k_term * sin_l * cos_phi\n",
    "        term8 = (4.0/3.0) * AFB * sin2_k * cos_l\n",
    "        term9 = S7 * sin2k_term * sin_l * sin_phi\n",
    "        term10 = S8 * sin2k_term * sin2l_term * sin_phi\n",
    "        term11 = S9 * sin2_k * sin2_l * sin2_phi\n",
    "        \n",
    "        pdf = term1 + term2 + term3 + term4 + term5 + term6 + term7 + term8 + term9 + term10 + term11\n",
    "        return pdf\n",
    "\n",
    "    # Se ha eliminado _integrate explícitamente.\n",
    "    # zfit ahora usará integración numérica por defecto, lo que permite\n",
    "    # calcular proyecciones (integrales parciales) correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78426651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Instanciando PDF física para proyecciones...\n",
      "--- Procesando plot CMS para: cosThetaL ---\n",
      "Estimated integral error ( 4.7820036572242623e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.782862163937605e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.7826891768868406e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.782862163937605e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "    -> Gráfica guardada: Plots/Analytic_Projections_CMS/CMS_Proj_cosThetaL.png (Chi2/ndof=0.85)\n",
      "--- Procesando plot CMS para: cosThetaK ---\n",
      "Estimated integral error ( 4.8046117784449048e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.791965057808375e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.7716899659413877e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.791965057808375e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "    -> Gráfica guardada: Plots/Analytic_Projections_CMS/CMS_Proj_cosThetaK.png (Chi2/ndof=0.79)\n",
      "--- Procesando plot CMS para: phi ---\n",
      "Estimated integral error ( 4.7837541500399882e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.7836655102040825e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.7835994286037933e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 4.7836655102040825e-06 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "Estimated integral error ( 2.3815317593743481e-05 ) larger than tolerance ( 3e-06 ), which is maybe not enough (but maybe it's also fine). You can (best solution) implement an anatytical integral (see examples in repo) or manually set a higher number on the PDF with 'update_integration_options' and increase the 'max_draws' (or adjust 'tol'). If partial integration is chosen, this can lead to large memory consumption.This is a new warning checking the integral accuracy. It may warns too often as it is Work In Progress. If you have any observation on it, please tell us about it: https://github.com/zfit/zfit/issues/new/chooseTo suppress this warning, use zfit.settings.set_verbosity(-1).\n",
      "    -> Gráfica guardada: Plots/Analytic_Projections_CMS/CMS_Proj_phi.png (Chi2/ndof=0.64)\n",
      ">>> Todas las proyecciones estilo CMS generadas.\n"
     ]
    }
   ],
   "source": [
    "def plot_analytical_projections_cms(sampler, phys_params_dict, folder_out=\"Plots/Analytic_Projections_CMS\", n_bins=30):\n",
    "    \"\"\"\n",
    "    Genera proyecciones con estilo CMS usando zfit, pero estandarizando\n",
    "    el cálculo de Chi2/ndof y Pulls con la función _calc_chi2_standardized.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_out):\n",
    "        os.makedirs(folder_out)\n",
    "\n",
    "    obs_space = sampler.space\n",
    "    observables = obs_space.obs  \n",
    "    \n",
    "    # 1. Instanciar la PDF Física con los parámetros del Best Fit\n",
    "    print(f\">>> Instanciando PDF física para proyecciones...\")\n",
    "    pdf_model = FullAngular_Physical_PDF(\n",
    "        obs=obs_space,\n",
    "        **phys_params_dict \n",
    "    )\n",
    "\n",
    "    # Etiquetas LaTeX para los ejes\n",
    "    latex_labels = {\n",
    "        observables[0]: r'$\\cos(\\theta_l)$',\n",
    "        observables[1]: r'$\\cos(\\theta_K)$',\n",
    "        observables[2]: r'$\\phi$'\n",
    "    }\n",
    "\n",
    "    # Mapa de parámetros libres por variable para el cálculo correcto de NDOF\n",
    "    # Índice 0 (CosL): 2 params (FL, AFB)\n",
    "    # Índice 1 (CosK): 1 param (FL)\n",
    "    # Índice 2 (Phi) : 2 params (S3, S9)\n",
    "    n_params_map = {0: 2, 1: 1, 2: 2}\n",
    "\n",
    "    # Total de eventos (para escalar la PDF)\n",
    "    n_total = sampler.n_events.numpy()\n",
    "\n",
    "    for obs_name in observables:\n",
    "        print(f\"--- Procesando plot CMS para: {obs_name} ---\")\n",
    "        \n",
    "        # A. Crear la PDF Proyectada (integrando las otras variables)\n",
    "        vars_to_integrate = [var for var in observables if var != obs_name]\n",
    "        limits_integration = obs_space.with_obs(vars_to_integrate)\n",
    "        pdf_proj = pdf_model.create_projection_pdf(limits=limits_integration)\n",
    "        \n",
    "        # B. Preparar Datos (Histograma)\n",
    "        idx = observables.index(obs_name)\n",
    "        data_column = sampler.unstack_x()[idx]\n",
    "        \n",
    "        if hasattr(data_column, \"numpy\"):\n",
    "            data_np = data_column.numpy()\n",
    "        else:\n",
    "            data_np = np.array(data_column)\n",
    "            \n",
    "        counts, bin_edges = np.histogram(data_np, bins=n_bins)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        bin_width = bin_edges[1] - bin_edges[0]\n",
    "        y_err_data = np.sqrt(counts)\n",
    "        \n",
    "        # C. Calcular Modelo\n",
    "        lower, upper = obs_space.with_obs(obs_name).limit1d\n",
    "        \n",
    "        # C.1 Para el plot suave (alta resolución)\n",
    "        x_fine = np.linspace(lower, upper, 400)\n",
    "        y_smooth_density = pdf_proj.pdf(x_fine).numpy()\n",
    "        y_smooth_counts = y_smooth_density * n_total * bin_width\n",
    "        \n",
    "        # C.2 Para Chi2 y Pulls (evaluado en el centro del bin - Observado vs Esperado)\n",
    "        # Nota: Usamos el valor en el centro como aproximación de la integral del bin para zfit\n",
    "        y_model_at_centers_density = pdf_proj.pdf(bin_centers).numpy()\n",
    "        y_model_at_centers = y_model_at_centers_density * n_total * bin_width\n",
    "        \n",
    "        # D. ESTADÍSTICA ESTANDARIZADA\n",
    "        # ==============================================================================\n",
    "        # Aquí conectamos con tu función estandarizada para garantizar consistencia.\n",
    "        # Recuperamos el número de parámetros libres para esta variable específica\n",
    "        n_params_curr = n_params_map.get(idx, 1) \n",
    "        \n",
    "        # Llamada a la función externa que ya definiste\n",
    "        chi2_val, ndof, p_val, pulls = _calc_chi2_standardized(\n",
    "            obs=counts, \n",
    "            exp=y_model_at_centers, \n",
    "            n_params=n_params_curr\n",
    "        )\n",
    "        chi2_red = chi2_val / ndof\n",
    "        # ==============================================================================\n",
    "\n",
    "        # ====== PLOTTING ESTILO CMS (Sin cambios mayores) ======\n",
    "        fig = plt.figure(figsize=(9, 9))\n",
    "        gs = GridSpec(2, 1, height_ratios=[3.5, 1], hspace=0.08)\n",
    "        ax0 = fig.add_subplot(gs[0])\n",
    "        ax1 = fig.add_subplot(gs[1])\n",
    "\n",
    "        # --- Panel Superior (Datos + Modelo) ---\n",
    "        ax0.errorbar(bin_centers, counts, yerr=y_err_data, xerr=bin_width/2.0, \n",
    "                     fmt='ks', markersize=4, elinewidth=1, capsize=2, label='Toy (data)')\n",
    "\n",
    "        ax0.plot(x_fine, y_smooth_counts, '-', linewidth=2, label='Analytical PDF', color='b')\n",
    "        \n",
    "        # Límites dinámicos\n",
    "        max_data = np.max(counts + y_err_data)\n",
    "        max_model = np.max(y_smooth_counts)\n",
    "        y_max_plot = max(max_data, max_model)\n",
    "        ax0.set_ylim(0, y_max_plot * 1.5)\n",
    "        \n",
    "        ax0.set_xlim(lower, upper)\n",
    "        ax0.set_xticklabels([]) \n",
    "        ax0.set_ylabel(f'Events / {bin_width:.2f}', fontsize=16)\n",
    "        ax0.grid(True, alpha=0.2)\n",
    "        ax0.legend(loc='upper right', fontsize=13, frameon=False, bbox_to_anchor=(0.98, 0.88))\n",
    "\n",
    "        hep.cms.label(data=False, loc=0, ax=ax0, rlabel=\"13 TeV\")\n",
    "\n",
    "        # --- Caja de Texto con Estadísticas ---\n",
    "        FL_val = phys_params_dict.get('FL', 0)\n",
    "        AFB_val = phys_params_dict.get('AFB', 0)\n",
    "        S3_val = phys_params_dict.get('S3', 0)\n",
    "        S9_val = phys_params_dict.get('S9', 0)\n",
    "\n",
    "        # Usamos p-value simple para evitar error de LaTeX en backend\n",
    "        param_text = (\n",
    "            rf'$F_L = {FL_val:.3f}$' + '\\n' +\n",
    "            rf'$A_{{FB}} = {AFB_val:.3f}$' + '\\n' +\n",
    "            rf'$S_3 = {S3_val:.3f}$' + '\\n' +\n",
    "            rf'$S_9 = {S9_val:.3f}$' + '\\n' +\n",
    "            r'----------------' + '\\n' + \n",
    "            rf'$\\chi^2/\\mathrm{{ndof}} = {chi2_val:.1f}/{ndof} = {chi2_red:.2f}$' + '\\n' +\n",
    "            rf'$p$-value = {p_val:.3g}'\n",
    "        )\n",
    "\n",
    "        ax0.text(0.05, 0.92, param_text, transform=ax0.transAxes, fontsize=12, \n",
    "                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='#dddddd'))\n",
    "\n",
    "        # --- Panel Inferior (Pulls) ---\n",
    "        ax1.errorbar(bin_centers, pulls, \n",
    "                     yerr=1.0,           \n",
    "                     xerr=0,             \n",
    "                     fmt='ks',           \n",
    "                     markersize=3,       \n",
    "                     elinewidth=1.0,     \n",
    "                     capsize=0)          \n",
    "        \n",
    "        ax1.axhline(0, color='black', linewidth=1.0, linestyle='-')\n",
    "        ax1.axhline(3, color='gray', linestyle=':', linewidth=1, alpha=0.8) \n",
    "        ax1.axhline(-3, color='gray', linestyle=':', linewidth=1, alpha=0.8)\n",
    "        \n",
    "        ax1.fill_between([lower, upper], -1, 1, color='yellow', alpha=0.1) \n",
    "        ax1.fill_between([lower, upper], -2, 2, color='green', alpha=0.05) \n",
    "\n",
    "        xlabel = latex_labels.get(obs_name, obs_name)\n",
    "        ax1.set_xlabel(xlabel, fontsize=16)\n",
    "        ax1.set_ylabel(r'Pull $(\\sigma)$', fontsize=13)\n",
    "        ax1.set_xlim(lower, upper)\n",
    "        ax1.set_ylim(-4.9, 4.9)\n",
    "        ax1.grid(True, alpha=0.2)\n",
    "\n",
    "        ax0.tick_params(axis='both', which='major', labelsize=14) \n",
    "        ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "        outname = os.path.join(folder_out, f\"CMS_Proj_{obs_name}.png\")\n",
    "        plt.savefig(outname, bbox_inches='tight', dpi=200)\n",
    "        plt.close(fig)\n",
    "        print(f\"    -> Gráfica guardada: {outname} (Chi2/ndof={chi2_red:.2f})\")\n",
    "\n",
    "    print(\">>> Todas las proyecciones estilo CMS generadas.\")\n",
    "\n",
    "# --- LLAMADA A LA FUNCIÓN ---\n",
    "plot_analytical_projections_cms(\n",
    "    sampler=sampler,\n",
    "    phys_params_dict=best_fit_phys_dict,\n",
    "    folder_out=\"Plots/Analytic_Projections_CMS\",\n",
    "    n_bins=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534212c5",
   "metadata": {},
   "source": [
    "# Transformed vs physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c1ad286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando imágenes en: Plots/physical_vs_transformed/\n",
      " -> Generado: FL_Transformation.png\n",
      " -> Generado: S3_Transversal.png\n",
      " -> Generado: AFB_Transversal.png\n",
      " -> Generado: S9_Transversal_CPodd.png\n",
      " -> Generado: S5_Interference_P5p.png\n",
      " -> Generado: S7_Interference_CPodd.png\n",
      " -> Generado: S4_Interference.png\n",
      " -> Generado: S8_Interference_CPodd.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import os\n",
    "\n",
    "hep.style.use(\"CMS\") \n",
    "\n",
    "def generar_plots_individuales():\n",
    "    # Configuración de datos\n",
    "    x_hat = np.linspace(-5, 5, 600)\n",
    "    val_infimo = 0.001\n",
    "    \n",
    "    # CAMBIO: Se reemplazó 0.8 por 0.9 en la lista\n",
    "    casos_fl = [val_infimo, 0.3, 0.5, 0.9, 1.0]\n",
    "    \n",
    "    # Colores para las 5 lineas\n",
    "    colores = ['blue', 'cyan', 'green', 'orange', 'red']\n",
    "    \n",
    "    # CAMBIO: Se actualizó la etiqueta correspondiente\n",
    "    labels_fl = [\n",
    "        fr'$F_L={val_infimo}$', \n",
    "        r'$F_L=0.3$', \n",
    "        r'$F_L=0.5$', \n",
    "        r'$F_L=0.9$',  # Etiqueta actualizada\n",
    "        r'$F_L=1.0$'\n",
    "    ]\n",
    "    \n",
    "    # Crear carpeta de destino\n",
    "    output_dir = \"Plots/physical_vs_transformed\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Guardando imágenes en: {output_dir}/\")\n",
    "\n",
    "    # Función auxiliar para generar y guardar un solo plot\n",
    "    def generar_plot_individual(simbolo, nombre_archivo, func_limite, func_prefactor, is_fl=False):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        hep.cms.label(loc=0, ax=ax, data=False)\n",
    "        \n",
    "        ax.set_xlabel(fr'$\\hat{{{simbolo}}}$', fontsize=25)\n",
    "        ax.set_ylabel(fr'${simbolo}$', fontsize=25)\n",
    "        \n",
    "        for i, fl in enumerate(casos_fl):\n",
    "            color = colores[i]\n",
    "            label = labels_fl[i]\n",
    "            \n",
    "            limite = func_limite(fl)\n",
    "            amplitud = func_prefactor(fl)\n",
    "            y_curve = amplitud * np.tanh(x_hat)\n",
    "            \n",
    "            # Caso especial para el plot de FL\n",
    "            if is_fl:\n",
    "                if i == 0: \n",
    "                    y_base = 0.5 * (1 + np.tanh(x_hat))\n",
    "                    ax.plot(x_hat, y_base, 'k-', linewidth=2.0, label=r'Transformation')\n",
    "                    ax.axhline(1, color='red', linestyle='--', alpha=0.6)\n",
    "                    ax.text(4.6, 1, r'$\\mathbf{1.0}$', color='black', va='bottom', fontsize=18)\n",
    "                    ax.axhline(0, color='red', linestyle='--', alpha=0.6)\n",
    "                    ax.text(4.6, 0, r'$\\mathbf{0.0}$', color='black', va='bottom', fontsize=18)\n",
    "                continue\n",
    "\n",
    "            # Dibujar curva\n",
    "            ax.plot(x_hat, y_curve, color=color, linewidth=2.0, label=label)\n",
    "            \n",
    "            # Dibujar límites\n",
    "            if limite > 1e-4:\n",
    "                ax.axhline(limite, color=color, linestyle=':', linewidth=1.5)\n",
    "                ax.text(4.6, limite, r'$\\mathbf{' + f'{limite:.3f}' + r'}$', color='black', va='bottom', fontsize=14)\n",
    "                \n",
    "                ax.axhline(-limite, color=color, linestyle=':', linewidth=1.5)\n",
    "                ax.text(4.6, -limite, r'$\\mathbf{-' + f'{limite:.3f}' + r'}$', color='black', va='top', fontsize=14)\n",
    "            else:\n",
    "                pass \n",
    "\n",
    "        ax.axhline(0, color='black', linewidth=0.8)\n",
    "        ax.axvline(0, color='black', linewidth=0.8)\n",
    "        ax.set_xlim(-4.5, 5.5)\n",
    "        \n",
    "        if is_fl:\n",
    "             ax.set_ylim(-0.1, 1.1)\n",
    "        else:\n",
    "            ax.legend(loc='upper left', fontsize=13, frameon=True, fancybox=False, edgecolor='black', ncol=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Guardar\n",
    "        ruta_completa = os.path.join(output_dir, f\"{nombre_archivo}.png\")\n",
    "        plt.savefig(ruta_completa)\n",
    "        plt.close()\n",
    "        print(f\" -> Generado: {nombre_archivo}.png\")\n",
    "\n",
    "    # --- GENERACIÓN DE PLOTS ---\n",
    "\n",
    "    # 1. FL\n",
    "    generar_plot_individual('F_L', 'FL_Transformation',\n",
    "                            lambda x: 0, lambda x: 0, is_fl=True)\n",
    "\n",
    "    # 2. S3\n",
    "    generar_plot_individual('S_3', 'S3_Transversal', \n",
    "                            func_limite=lambda fl: 0.5 * (1 - fl), \n",
    "                            func_prefactor=lambda fl: 0.5 * (1 - fl))\n",
    "\n",
    "    # 3. AFB\n",
    "    generar_plot_individual('A_{FB}', 'AFB_Transversal', \n",
    "                            func_limite=lambda fl: 0.75 * (1 - fl),\n",
    "                            func_prefactor=lambda fl: 0.75 * (1 - fl))\n",
    "\n",
    "    # 4. S9\n",
    "    generar_plot_individual('S_9', 'S9_Transversal_CPodd', \n",
    "                            func_limite=lambda fl: 0.5 * (1 - fl), \n",
    "                            func_prefactor=lambda fl: 0.5 * (1 - fl))\n",
    "\n",
    "    # 5. S5\n",
    "    generar_plot_individual('S_5', 'S5_Interference_P5p', \n",
    "                            func_limite=lambda fl: np.sqrt(fl * (1 - fl)), \n",
    "                            func_prefactor=lambda fl: np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "    # 6. S7\n",
    "    generar_plot_individual('S_7', 'S7_Interference_CPodd', \n",
    "                            func_limite=lambda fl: np.sqrt(fl * (1 - fl)), \n",
    "                            func_prefactor=lambda fl: np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "    # 7. S4\n",
    "    generar_plot_individual('S_4', 'S4_Interference', \n",
    "                            func_limite=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)), \n",
    "                            func_prefactor=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "    # 8. S8\n",
    "    generar_plot_individual('S_8', 'S8_Interference_CPodd', \n",
    "                            func_limite=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)), \n",
    "                            func_prefactor=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generar_plots_individuales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b0f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import mplhep as hep\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.colors as mcolors\n",
    "\n",
    "# # Configuración de estilo CMS\n",
    "# hep.style.use(\"CMS\")\n",
    "\n",
    "# def graficar_scan_individual():\n",
    "#     x_hat = np.linspace(-5, 5, 600)\n",
    "    \n",
    "#     # Rango de FL para el scan\n",
    "#     casos_fl = np.array([0.0, 0.13, 0.25, 0.38, 0.47, 0.55, 0.68, 0.79, 0.92, 1.0])\n",
    "    \n",
    "#     # Mapa de color y normalización\n",
    "#     cmap = plt.get_cmap('viridis') \n",
    "#     norm = mcolors.Normalize(vmin=0.0, vmax=1.0)\n",
    "\n",
    "#     # --- FUNCIÓN GENERADORA DE UN SOLO PLOT ---\n",
    "#     def plot_single_observable(simbolo, func_limite, func_prefactor, is_fl=False):\n",
    "#         # Creamos una figura grande e independiente para cada uno\n",
    "#         # figsize=(12, 10) da buen espacio para papers/slides\n",
    "#         fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "#         hep.cms.label(loc=0, ax=ax, data=False)\n",
    "        \n",
    "#         ax.set_xlabel(fr'$\\hat{{{simbolo}}}$', fontsize=30)\n",
    "#         ax.set_ylabel(fr'${simbolo}$', fontsize=30)\n",
    "        \n",
    "#         # Ejes de referencia (Grid)\n",
    "#         ax.axhline(0, color='gray', linewidth=1.0, alpha=0.4, zorder=0)\n",
    "#         ax.axvline(0, color='gray', linewidth=1.0, alpha=0.4, zorder=0)\n",
    "\n",
    "#         max_val_teorico = 0.0 # Para calcular el límite del eje Y automáticamente\n",
    "\n",
    "#         # --- BUCLE DE SCAN ---\n",
    "#         for fl in casos_fl:\n",
    "#             color_linea = cmap(norm(fl))\n",
    "            \n",
    "#             limite = func_limite(fl)\n",
    "#             amplitud = func_prefactor(fl)\n",
    "#             y_curve = amplitud * np.tanh(x_hat)\n",
    "            \n",
    "#             # Rastreamos el valor máximo para ajustar el zoom después\n",
    "#             if limite > max_val_teorico:\n",
    "#                 max_val_teorico = limite\n",
    "\n",
    "#             if is_fl:\n",
    "#                 pass # Se dibuja fuera del loop\n",
    "#             else:\n",
    "#                 ax.plot(x_hat, y_curve, color=color_linea, linewidth=2, alpha=0.9, zorder=2)\n",
    "                \n",
    "#                 # Asintotas solo extremos\n",
    "#                 if fl == 0.0 or fl == 1.0:\n",
    "#                     if limite > 1e-3:\n",
    "#                         style = '--' if fl == 1.0 else ':'\n",
    "#                         ax.axhline(limite, color=color_linea, linestyle=style, linewidth=1, alpha=0.8, zorder=1)\n",
    "#                         ax.axhline(-limite, color=color_linea, linestyle=style, linewidth=1, alpha=0.8, zorder=1)\n",
    "                        \n",
    "#                         # Texto de la asintota\n",
    "#                         ax.text(4.8, limite, f'{limite:.3f}', color=color_linea, \n",
    "#                                 va='bottom', ha='right', fontsize=18, fontweight='bold', zorder=5)\n",
    "\n",
    "#         # --- LÓGICA ESPECÍFICA PARA F_L (Transformación base) ---\n",
    "#         if is_fl:\n",
    "#             y_base = 0.5 * (1 + np.tanh(x_hat))\n",
    "#             ax.plot(x_hat, y_base, 'k-', linewidth=3, zorder=5)\n",
    "#             # Límites 0 y 1\n",
    "#             ax.axhline(1, color=cmap(norm(1.0)), linestyle='--', alpha=0.8)\n",
    "#             ax.text(4.8, 1.02, r'$\\mathbf{1.0}$', color=cmap(norm(1.0)), fontsize=18, ha='right')\n",
    "#             ax.axhline(0, color=cmap(norm(0.0)), linestyle=':', alpha=0.8)\n",
    "#             ax.text(4.8, -0.08, r'$\\mathbf{0.0}$', color=cmap(norm(0.0)), fontsize=18, ha='right')\n",
    "            \n",
    "#             ax.set_ylim(-0.2, 1.2) # Fijo para FL\n",
    "#         else:\n",
    "#             # --- AJUSTE AUTOMÁTICO DE ESCALA Y ---\n",
    "#             # Le damos un 40% extra de aire arriba y abajo del valor máximo encontrado\n",
    "#             # Esto asegura que las etiquetas de texto NUNCA se corten.\n",
    "#             if max_val_teorico < 0.1: max_val_teorico = 0.1 # Evitar colapso si todo es 0\n",
    "#             margen = max_val_teorico * 1.4 \n",
    "#             ax.set_ylim(-margen, margen)\n",
    "\n",
    "#         ax.set_xlim(-5.0, 5.0)\n",
    "        \n",
    "#         # --- BARRA DE COLOR INDIVIDUAL ---\n",
    "#         sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "#         sm.set_array([])\n",
    "#         cbar = fig.colorbar(sm, ax=ax, pad=0.02)\n",
    "#         cbar.set_label(r'$F_L$ Value', fontsize=15, rotation=270, labelpad=20)\n",
    "#         cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.show() # Muestra este plot y espera a que lo cierres para mostrar el siguiente\n",
    "\n",
    "#     # ==========================================\n",
    "#     # GENERACIÓN DE LOS 8 GRÁFICOS\n",
    "#     # ==========================================\n",
    "    \n",
    "#     # 1. FL\n",
    "#     print(\"Generando F_L...\")\n",
    "#     plot_single_observable('F_L', lambda x: 0, lambda x: 0, is_fl=True)\n",
    "\n",
    "#     # 2. S3\n",
    "#     print(\"Generando S_3...\")\n",
    "#     plot_single_observable('S_3', \n",
    "#                    func_limite=lambda fl: 0.5 * (1 - fl), \n",
    "#                    func_prefactor=lambda fl: 0.5 * (1 - fl))\n",
    "\n",
    "#     # 3. AFB\n",
    "#     print(\"Generando A_FB...\")\n",
    "#     plot_single_observable('A_{FB}', \n",
    "#                    func_limite=lambda fl: 0.75 * (1 - fl),\n",
    "#                    func_prefactor=lambda fl: 0.75 * (1 - fl))\n",
    "\n",
    "#     # 4. S9\n",
    "#     print(\"Generando S_9...\")\n",
    "#     plot_single_observable('S_9', \n",
    "#                    func_limite=lambda fl: 0.5 * (1 - fl), \n",
    "#                    func_prefactor=lambda fl: 0.5 * (1 - fl))\n",
    "\n",
    "#     # 5. S5\n",
    "#     print(\"Generando S_5...\")\n",
    "#     plot_single_observable('S_5', \n",
    "#                    func_limite=lambda fl: np.sqrt(fl * (1 - fl)), \n",
    "#                    func_prefactor=lambda fl: np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "#     # 6. S7\n",
    "#     print(\"Generando S_7...\")\n",
    "#     plot_single_observable('S_7', \n",
    "#                    func_limite=lambda fl: np.sqrt(fl * (1 - fl)), \n",
    "#                    func_prefactor=lambda fl: np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "#     # 7. S4\n",
    "#     print(\"Generando S_4...\")\n",
    "#     plot_single_observable('S_4', \n",
    "#                    func_limite=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)), \n",
    "#                    func_prefactor=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "#     # 8. S8\n",
    "#     print(\"Generando S_8...\")\n",
    "#     plot_single_observable('S_8', \n",
    "#                    func_limite=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)), \n",
    "#                    func_prefactor=lambda fl: 0.5 * np.sqrt(fl * (1 - fl)))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     graficar_scan_individual()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haza_wokr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
