{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1960c1d6-e790-405d-93ad-04141d1ddbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "from pandas import Series, DataFrame \n",
    "import matplotlib.pyplot as plt \n",
    "import uproot \n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import comb\n",
    "from scipy.stats import chi2\n",
    "from scipy.special import comb\n",
    "from scipy.optimize import lsq_linear\n",
    "import math\n",
    "import sys\n",
    "import os \n",
    "from plot_tools import *\n",
    "from customStats import *\n",
    "#import tools\n",
    "import common_tools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "# from selection_cuts import selection_nominal\n",
    "import mplhep as hep\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.figure()\n",
    "plt.close()\n",
    "plt.rcParams.update({'figure.figsize':[10,8]})\n",
    "plt.rcParams.update({'font.size':24})\n",
    "### E F F I C I E N C Y \n",
    "import tensorflow as tf\n",
    "import math\n",
    "import zfit\n",
    "from zfit import z\n",
    "import xgboost as xgb\n",
    "from scipy.interpolate import make_interp_spline\n",
    "# from loadCutXGB import load_and_cutXGBclfs\n",
    "from scipy.special import comb\n",
    "from scipy.optimize import lsq_linear\n",
    "zfit.settings.set_verbosity(0)\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49dd09",
   "metadata": {},
   "source": [
    "# FUNCTIONS FOR CALCULATING EFFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19db1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bernstein_1d(n, k, t):\n",
    "    \"\"\"Bernstein base polynomial B_{n,k}(t) on t in [0,1].\"\"\"\n",
    "    return comb(n, k) * (t**k) * ((1.0 - t)**(n - k))\n",
    "\n",
    "\n",
    "def bernstein2d_matrix(nx, ny, x, y):\n",
    "    \"\"\"\n",
    "    Build the design matrix for Bernstein2D basis.\n",
    "    Input: x, y in [-1,1] (arrays)\n",
    "    Output: B matrix of size (Npoints, (nx+1)*(ny+1))\n",
    "    \"\"\"\n",
    "    # map [-1,1] -> [0,1]\n",
    "    tx = 0.5*(x + 1.0)\n",
    "    ty = 0.5*(y + 1.0)\n",
    "\n",
    "    B_list = []\n",
    "    for i in range(nx+1):\n",
    "        for j in range(ny+1):\n",
    "            B_list.append(bernstein_1d(nx, i, tx) * bernstein_1d(ny, j, ty))\n",
    "    B = np.vstack(B_list).T   # shape (Npoints, Ncoef)\n",
    "    return B\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2) Fit Bernstein2D to a 2D efficiency map\n",
    "# ======================================================\n",
    "\n",
    "def fit_bernstein2d( xcenters, ycenters, eff2d, ngen2d, nx=8, ny=8, min_counts_mask=None,reg_lambda=1e-10,):\n",
    "    \"\"\"\n",
    "    Fits a Bernstein2D polynomial to a 2D efficiency map using least squares + Tikhonov reg.\n",
    "\n",
    "    Inputs:\n",
    "        xcenters, ycenters   1D arrays (bin centers)\n",
    "        eff2d                2D array with efficiency values (NaNs allowed)\n",
    "        nx, ny               polynomial orders\n",
    "        min_counts_mask      Boolean 2D mask (valid bins: True)\n",
    "        reg_lambda           regularization parameter\n",
    "\n",
    "    Returns:\n",
    "        coef                 fitted coefficients\n",
    "        eff_model            modeled efficiency on the grid\n",
    "\n",
    "    \n",
    "    Weighted fit of a Bernstein2D polynomial to a 2D efficiency map.\n",
    "\n",
    "    The weights are derived from binomial uncertainties:\n",
    "        sigma^2 = eff * (1 - eff) / ngen\n",
    "    \"\"\"\n",
    "\n",
    "    XX, YY = np.meshgrid(xcenters, ycenters, indexing=\"ij\")\n",
    "    xflat = XX.ravel()\n",
    "    yflat = YY.ravel()\n",
    "    eff_flat = eff2d.ravel()\n",
    "    ngen_flat = ngen2d.ravel()\n",
    "\n",
    "    # Valid bins\n",
    "    if min_counts_mask is None: use = (~np.isnan(eff_flat)) & (ngen_flat > 0)\n",
    "    else:\n",
    "        use = (min_counts_mask.ravel() & ~np.isnan(eff_flat)& (ngen_flat > 0))\n",
    "\n",
    "    x_use = xflat[use]\n",
    "    y_use = yflat[use]\n",
    "    eff_use = eff_flat[use]\n",
    "    ngen_use = ngen_flat[use]\n",
    "\n",
    "    # Binomial uncertainty\n",
    "    sigma2 = eff_use * (1.0 - eff_use) / ngen_use\n",
    "    sigma2 = np.clip(sigma2, 1e-12, None)\n",
    "    w = 1.0 / np.sqrt(sigma2)\n",
    "    B = bernstein2d_matrix(nx, ny, x_use, y_use)\n",
    "\n",
    "    # Apply weights\n",
    "    Bw = B * w[:, None]\n",
    "    yw = eff_use * w\n",
    "\n",
    "    # Regularized weighted least squares\n",
    "    BTB = Bw.T @ Bw + reg_lambda * np.eye(B.shape[1])\n",
    "    BTy = Bw.T @ yw\n",
    "    coef = np.linalg.solve(BTB, BTy)\n",
    "    Bfull = bernstein2d_matrix(nx, ny, xflat, yflat)\n",
    "    eff_model_flat = Bfull @ coef\n",
    "    eff_model = eff_model_flat.reshape(eff2d.shape)\n",
    "    return coef, eff_model\n",
    "\n",
    "def build_efficiency_2d(gen_all_x, gen_all_y, gen_fid_x, gen_fid_y, reco_fid_x, reco_fid_y, reco_x, reco_y, \n",
    "                        weights_reco=None, nbx=20, nby=20, nxg=8, nyg=8, nxr=8, nyr=8, min_gen=0, reg_acc=1e-4, reg_reco=1e-4):\n",
    "    xedges = np.linspace(-1, 1, nbx + 1)\n",
    "    yedges = np.linspace(-1, 1, nby + 1)\n",
    "    xcenters = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "    ycenters = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "\n",
    "    # Pesos \n",
    "    if weights_reco is None:\n",
    "        weights_reco = np.ones(len(reco_x))\n",
    "\n",
    "    # Histograms\n",
    "    gen_allH, _, _ = np.histogram2d(gen_all_x, gen_all_y, bins=[xedges, yedges])\n",
    "    gen_fidH, _, _ = np.histogram2d(gen_fid_x, gen_fid_y, bins=[xedges, yedges])\n",
    "    # Denominador Reco\n",
    "    reco_fidH, _, _ = np.histogram2d(reco_fid_x, reco_fid_y, bins=[xedges, yedges])    \n",
    "    # Numerador Reco (CON PESOS APLICADOS)\n",
    "    recoH, _, _ = np.histogram2d(reco_x, reco_y, bins=[xedges, yedges], weights=weights_reco)\n",
    "\n",
    "    # ============================\n",
    "    # Acceptance\n",
    "    # ============================\n",
    "    mask_gen = gen_allH > min_gen\n",
    "    acc_gen = np.full_like(gen_allH, np.nan)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_gen[mask_gen] = gen_fidH[mask_gen] / gen_allH[mask_gen]\n",
    "\n",
    "    # ============================\n",
    "    # Reconstruction efficiency\n",
    "    # ============================\n",
    "    eff_reco = np.full_like(gen_allH, np.nan)\n",
    "    valid = mask_gen & (reco_fidH > 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        eff_reco[valid] = recoH[valid] / reco_fidH[valid]\n",
    "    \n",
    "    # ============================\n",
    "    # Bernstein fits\n",
    "    # ============================\n",
    "    # Nota: Los fits también deben saber que recoH ahora tiene pesos (float), no solo counts (int).\n",
    "    # Asegúrate de que fit_bernstein2d maneje arrays de floats en \"data_hist\" (recoH).\n",
    "    coef_acc, acc_gen_model = fit_bernstein2d( xcenters, ycenters, acc_gen, gen_allH, nx=nxg, ny=nyg, min_counts_mask=mask_gen, reg_lambda=reg_acc)\n",
    "    coef_reco, eff_reco_model = fit_bernstein2d(xcenters, ycenters, eff_reco, reco_fidH, nx=nxr, ny=nyr, min_counts_mask=valid, reg_lambda=reg_reco)\n",
    "\n",
    "    return (xcenters, ycenters, acc_gen, acc_gen_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen)\n",
    "\n",
    "def build_efficiency_1d(gen_all, gen_fid, reco_fid, reco, weights_reco=None, nbins=30, n_poly=4, min_gen=10, reg_acc=1e-6, reg_reco=1e-5):\n",
    "\n",
    "    limit_min, limit_max = -np.pi, np.pi\n",
    "    edges = np.linspace(limit_min, limit_max, nbins + 1)\n",
    "    centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    centers_norm = 2 * (centers - limit_min) / (limit_max - limit_min) - 1.0\n",
    "\n",
    "    # Pesos\n",
    "    if weights_reco is None:\n",
    "        weights_reco = np.ones(len(reco))\n",
    "    \n",
    "    # Histograms\n",
    "    gen_allH, _ = np.histogram(gen_all, bins=edges)\n",
    "    gen_fidH, _ = np.histogram(gen_fid, bins=edges)\n",
    "    reco_fidH, _ = np.histogram(reco_fid, bins=edges)\n",
    "    \n",
    "    # Numerador Reco CON PESOS\n",
    "    recoH, _ = np.histogram(reco, bins=edges, weights=weights_reco)\n",
    "\n",
    "    # Acceptance\n",
    "    mask_gen = gen_allH > min_gen\n",
    "    acc_gen = np.full_like(gen_allH, np.nan, dtype=float)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_gen[mask_gen] = gen_fidH[mask_gen] / gen_allH[mask_gen]\n",
    "    coef_acc, acc_model = fit_bernstein1d( centers_norm, acc_gen, gen_allH, n=n_poly, min_counts_mask=mask_gen, reg_lambda=reg_acc)\n",
    "    \n",
    "    # Efficiency reco\n",
    "    eff_reco = np.full_like(gen_allH, np.nan, dtype=float)\n",
    "    valid_reco = mask_gen & (reco_fidH > 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        eff_reco[valid_reco] = recoH[valid_reco] / reco_fidH[valid_reco]\n",
    "    coef_reco, eff_reco_model = fit_bernstein1d(centers_norm, eff_reco, reco_fidH, n=n_poly, min_counts_mask=valid_reco, reg_lambda=reg_reco)\n",
    "\n",
    "    return centers, acc_gen, acc_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen\n",
    "\n",
    "\n",
    "# def build_efficiency_2d(\n",
    "#     gen_all_x, gen_all_y,gen_fid_x, gen_fid_y,\n",
    "#     reco_fid_x, reco_fid_y,reco_x, reco_y,\n",
    "#     nbx=20, nby=20,nxg=8, nyg=8, nxr=8, nyr=8,\n",
    "#     min_gen=0, reg_acc=1e-4,reg_reco=1e-4):\n",
    "#     xedges = np.linspace(-1, 1, nbx + 1)\n",
    "#     yedges = np.linspace(-1, 1, nby + 1)\n",
    "#     xcenters = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "#     ycenters = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "\n",
    "#     # Histograms\n",
    "#     gen_allH, _, _ = np.histogram2d(gen_all_x, gen_all_y, bins=[xedges, yedges])\n",
    "#     gen_fidH, _, _ = np.histogram2d(gen_fid_x, gen_fid_y, bins=[xedges, yedges])\n",
    "#     reco_fidH, _, _ = np.histogram2d(reco_fid_x, reco_fid_y, bins=[xedges, yedges])\n",
    "#     recoH, _, _ = np.histogram2d(reco_x, reco_y, bins=[xedges, yedges])\n",
    "\n",
    "#     # ============================\n",
    "#     # Acceptance (GEN level)\n",
    "#     # ============================\n",
    "#     mask_gen = gen_allH > min_gen\n",
    "#     acc_gen = np.full_like(gen_allH, np.nan)\n",
    "#     acc_gen[mask_gen] = gen_fidH[mask_gen] / gen_allH[mask_gen]\n",
    "\n",
    "#     # ============================\n",
    "#     # Reconstruction efficiency\n",
    "#     # ============================\n",
    "#     eff_reco = np.full_like(gen_allH, np.nan)\n",
    "#     valid = mask_gen & (reco_fidH > 0)\n",
    "#     eff_reco[valid] = recoH[valid] / reco_fidH[valid]\n",
    "    \n",
    "#    # ============================\n",
    "#     # Bernstein fits\n",
    "#     # ============================\n",
    "#     coef_acc, acc_gen_model = fit_bernstein2d(xcenters, ycenters, acc_gen, gen_allH, nx=nxg, ny=nyg, min_counts_mask=mask_gen, reg_lambda=reg_acc)\n",
    "#     coef_reco, eff_reco_model = fit_bernstein2d( xcenters, ycenters, eff_reco, reco_fidH, nx=nxr, ny=nyr, min_counts_mask=valid,reg_lambda=reg_reco)\n",
    "#     return (xcenters, ycenters, acc_gen, acc_gen_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen)\n",
    "\n",
    "\n",
    "# def build_efficiency_1d( gen_all, gen_fid, reco_fid, reco, nbins=30, n_poly=4, min_gen=10, reg_acc=1e-6, reg_reco=1e-5):\n",
    "\n",
    "#     limit_min, limit_max = -np.pi, np.pi\n",
    "#     edges = np.linspace(limit_min, limit_max, nbins + 1)\n",
    "#     centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "#     centers_norm = 2 * (centers - limit_min) / (limit_max - limit_min) - 1.0\n",
    "\n",
    "#     # Histograms\n",
    "#     gen_allH, _ = np.histogram(gen_all, bins=edges)\n",
    "#     gen_fidH, _ = np.histogram(gen_fid, bins=edges)\n",
    "#     reco_fidH, _ = np.histogram(reco_fid, bins=edges)\n",
    "#     recoH,    _ = np.histogram(reco,    bins=edges)\n",
    "    \n",
    "#     # --- Acceptance ---\n",
    "#     mask_gen = gen_allH > min_gen\n",
    "#     acc_gen = np.full_like(gen_allH, np.nan, dtype=float)\n",
    "#     acc_gen[mask_gen] = gen_fidH[mask_gen] / gen_allH[mask_gen]\n",
    "#     coef_acc, acc_model = fit_bernstein1d( centers_norm, acc_gen, gen_allH, n=n_poly, min_counts_mask=mask_gen, reg_lambda=reg_acc)\n",
    "    \n",
    "#     # --- Efficiency reco ---\n",
    "#     eff_reco = np.full_like(gen_allH, np.nan, dtype=float)\n",
    "#     valid_reco = mask_gen & (reco_fidH > 0)\n",
    "#     eff_reco[valid_reco] = recoH[valid_reco] / reco_fidH[valid_reco]\n",
    "#     coef_reco, eff_reco_model = fit_bernstein1d( centers_norm, eff_reco, reco_fidH, n=n_poly, min_counts_mask=valid_reco, reg_lambda=reg_reco)\n",
    "\n",
    "#     return centers, acc_gen, acc_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen\n",
    "\n",
    "\n",
    "def bernstein2d_eval(x, y, model):\n",
    "    \"\"\"\n",
    "    Evaluate a fitted Bernstein2D model.\n",
    "    \"\"\"\n",
    "    nx = model[\"nx\"]\n",
    "    ny = model[\"ny\"]\n",
    "    coef = np.asarray(model[\"coef\"])\n",
    "    tx = 0.5 * (x + 1.0)\n",
    "    ty = 0.5 * (y + 1.0)\n",
    "    eff = np.zeros_like(tx, dtype=float)\n",
    "    idx = 0\n",
    "    for i in range(nx + 1):\n",
    "        Bx = bernstein_1d(nx, i, tx)\n",
    "        for j in range(ny + 1):\n",
    "            By = bernstein_1d(ny, j, ty)\n",
    "            eff += coef[idx] * Bx * By\n",
    "            idx += 1\n",
    "\n",
    "    return eff\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Save / Load Bernstein models\n",
    "# ======================================================\n",
    "def save_bernstein2d_model(filename, coef, nx, ny):\n",
    "    model = {\"nx\": nx, \"ny\": ny, \"coef\": coef.tolist(), \"x_range\": [-1.0, 1.0], \"y_range\": [-1.0, 1.0]}\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(model, f, indent=2)\n",
    "\n",
    "\n",
    "def load_bernstein_model(filename):\n",
    "    with open(filename) as f:\n",
    "        model = json.load(f)\n",
    "    return (np.asarray(model[\"coef\"], dtype=np.float64), model[\"nx\"], model[\"ny\"])\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#   plots\n",
    "# ======================================================\n",
    "def project_with_errors_x(data2d, mask):\n",
    "    \"\"\"Project 2D efficiency to x with diagnostic errors.\"\"\"\n",
    "    proj = []\n",
    "    err = []\n",
    "    for i in range(data2d.shape[0]):   # x bins\n",
    "        vals = data2d[i, :][mask[i, :]]\n",
    "        if len(vals) == 0:\n",
    "            proj.append(np.nan)\n",
    "            err.append(np.nan)\n",
    "        else:\n",
    "            proj.append(np.mean(vals))\n",
    "            err.append(np.std(vals, ddof=0) / np.sqrt(len(vals)))\n",
    "    return np.array(proj), np.array(err)\n",
    "\n",
    "\n",
    "def project_with_errors_y(data2d, mask):\n",
    "    \"\"\"Project 2D efficiency to y with diagnostic errors.\"\"\"\n",
    "    proj = []\n",
    "    err = []\n",
    "    for j in range(data2d.shape[1]):   # y bins\n",
    "        vals = data2d[:, j][mask[:, j]]\n",
    "        if len(vals) == 0:\n",
    "            proj.append(np.nan)\n",
    "            err.append(np.nan)\n",
    "        else:\n",
    "            proj.append(np.mean(vals))\n",
    "            err.append(np.std(vals, ddof=0) / np.sqrt(len(vals)))\n",
    "    return np.array(proj), np.array(err)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# CMS Style Plotting\n",
    "# ======================================================\n",
    "def _plot_cms_style(centers, data, data_err, model, xlabel, title, y_label=\"Efficiency\", ylim=None, path_dir=\"plots\"):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3.5, 1.5], hspace=0.05)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "\n",
    "    # --- AUTO-SCALING LOGIC ---\n",
    "    if ylim is None:\n",
    "        # Calculamos el punto más alto considerando el error superior\n",
    "        # Usamos nanmax para ignorar posibles NaNs\n",
    "        max_data = np.nanmax(data + data_err) if data_err is not None else np.nanmax(data)\n",
    "        max_model = np.nanmax(model)\n",
    "        global_max = max(max_data, max_model)\n",
    "        \n",
    "        # Si por alguna razón todo es 0 o NaN, ponemos un default\n",
    "        if np.isnan(global_max) or global_max <= 0:\n",
    "            global_max = 1.0\n",
    "            \n",
    "        # Definimos el límite: 0 abajo, y Max + 30% arriba para la leyenda/CMS label\n",
    "        current_ylim = (0.0, global_max * 1.30)\n",
    "    else:\n",
    "        current_ylim = ylim\n",
    "    # --------------------------\n",
    "\n",
    "    # Plot principal\n",
    "    ax0.plot(centers, model, '-', color='blue', linewidth=2.5, label=\"Bernstein Model\")\n",
    "    ax0.errorbar(centers, data, yerr=data_err, fmt='ks', markersize=5, elinewidth=1.5, capsize=2, label=\"Binned MC\")\n",
    "    ax0.set_ylabel(y_label, fontsize=16)\n",
    "    ax0.set_title(title, loc='center', fontsize=14, fontweight='medium', y=1.05)\n",
    "    \n",
    "    # Aplicamos el límite calculado o el manual\n",
    "    ax0.set_ylim(current_ylim)\n",
    "\n",
    "    hep.cms.label(data=False, loc=0, ax=ax0, rlabel=\"13 TeV\", fontname=\"sans-serif\", fontsize=16)\n",
    "    ax0.legend(frameon=False, fontsize=13, loc='upper right')\n",
    "    ax0.grid(True, alpha=0.3)\n",
    "    plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "\n",
    "    # Pulls (El resto sigue igual)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        pulls = (data - model) / data_err\n",
    "    pulls[~np.isfinite(pulls)] = 0.0 \n",
    "\n",
    "    width = centers[1] - centers[0]\n",
    "    lower = centers[0] - width/2\n",
    "    upper = centers[-1] + width/2\n",
    "\n",
    "    ax1.errorbar(centers, pulls, yerr=1.0, xerr=0, fmt='ks',markersize=4, elinewidth=1.0,capsize=0)          \n",
    "    ax1.axhline(0, color='black', linewidth=1.0, linestyle='-')\n",
    "    ax1.axhline(3, color='gray', linestyle=':', linewidth=1, alpha=0.8) \n",
    "    ax1.axhline(-3, color='gray', linestyle=':', linewidth=1, alpha=0.8)    \n",
    "    ax1.fill_between([lower, upper], -3, 3, color='gray', alpha=0.15, label=r'$3\\sigma$') \n",
    "    ax1.set_xlabel(xlabel, fontsize=16)\n",
    "    ax1.set_ylabel(r'Pull $(\\sigma)$', fontsize=13)\n",
    "    ax1.set_xlim(lower, upper)\n",
    "    ax1.set_ylim(-4.9, 4.9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=14, direction='in', top=True, right=True) \n",
    "    ax1.tick_params(axis='both', which='major', labelsize=14, direction='in', top=True, right=True)\n",
    "    \n",
    "    # Guardado seguro\n",
    "    save_path = os.path.join(path_dir, f\"{title}.png\")\n",
    "    directory = os.path.dirname(save_path)\n",
    "    if directory:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "# def _plot_cms_style(centers, data, data_err, model, xlabel, title, y_label=\"Efficiency\", ylim=None, path_dir = \"plots\"):\n",
    "#     fig = plt.figure(figsize=(8, 8))\n",
    "#     gs = gridspec.GridSpec(2, 1, height_ratios=[3.5, 1.5], hspace=0.05)\n",
    "#     ax0 = plt.subplot(gs[0])\n",
    "#     ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "\n",
    "#     # Plot principal\n",
    "#     ax0.plot(centers, model, '-', color='blue', linewidth=2.5, label=\"Bernstein Model\")\n",
    "#     ax0.errorbar(centers, data, yerr=data_err, fmt='ks', markersize=5, elinewidth=1.5, capsize=2, label=\"Binned MC\")\n",
    "#     ax0.set_ylabel(y_label, fontsize=16)\n",
    "#     ax0.set_title(title, loc='center', fontsize=14, fontweight='medium', y=1.05)\n",
    "#     ax0.set_ylim(ylim)\n",
    "\n",
    "#     hep.cms.label(data=False, loc=0, ax=ax0, rlabel=\"13 TeV\", fontname=\"sans-serif\", fontsize=16)\n",
    "#     ax0.legend(frameon=False, fontsize=13, loc='upper right')\n",
    "#     ax0.grid(True, alpha=0.3)\n",
    "#     plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "\n",
    "#     with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#         pulls = (data - model) / data_err\n",
    "#     pulls[~np.isfinite(pulls)] = 0.0 \n",
    "\n",
    "#     width = centers[1] - centers[0]\n",
    "#     lower = centers[0] - width/2\n",
    "#     upper = centers[-1] + width/2\n",
    "\n",
    "#     ax1.errorbar(centers, pulls, yerr=1.0, xerr=0, fmt='ks',markersize=4, elinewidth=1.0,capsize=0)          \n",
    "#     ax1.axhline(0, color='black', linewidth=1.0, linestyle='-')\n",
    "#     ax1.axhline(3, color='gray', linestyle=':', linewidth=1, alpha=0.8) \n",
    "#     ax1.axhline(-3, color='gray', linestyle=':', linewidth=1, alpha=0.8)    \n",
    "#     ax1.fill_between([lower, upper], -3, 3, color='gray', alpha=0.15, label=r'$3\\sigma$') \n",
    "#     ax1.set_xlabel(xlabel, fontsize=16)\n",
    "#     ax1.set_ylabel(r'Pull $(\\sigma)$', fontsize=13)\n",
    "#     ax1.set_xlim(lower, upper)\n",
    "#     ax1.set_ylim(-4.9, 4.9)\n",
    "#     ax1.grid(True, alpha=0.3)\n",
    "#     ax0.tick_params(axis='both', which='major', labelsize=14, direction='in', top=True, right=True) \n",
    "#     ax1.tick_params(axis='both', which='major', labelsize=14, direction='in', top=True, right=True)\n",
    "#     plt.subplots_adjust(left=0.14, right=0.95, top=0.92, bottom=0.12)\n",
    "#     save_path = os.path.join(path_dir, f\"{title}.png\")\n",
    "#     directory = os.path.dirname(save_path)\n",
    "#     if directory:\n",
    "#         os.makedirs(directory, exist_ok=True)\n",
    "#     plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Public Functions (Wrappers)\n",
    "# ======================================================\n",
    "def plot_projection_x_with_errors(xc, data2d, model2d, mask, title, ylim=None, path=None):\n",
    "    \"\"\"\n",
    "    Proyección en X (cosThetaL)\n",
    "    \"\"\"\n",
    "\n",
    "    data_proj, data_err = project_with_errors_x(data2d, mask)\n",
    "    model_proj, _ = project_with_errors_x(model2d, mask)\n",
    "    if np.nanmean(model_proj) != 0:\n",
    "        scale = np.nanmean(data_proj) / np.nanmean(model_proj)\n",
    "    else:\n",
    "        scale = 1.0\n",
    "    model_proj_scaled = model_proj * scale\n",
    "    _plot_cms_style(centers=xc, data=data_proj, data_err=data_err, model=model_proj_scaled, xlabel=r\"$\\cos\\theta_\\ell$\", title=title, ylim=ylim, path_dir=path)\n",
    "\n",
    "\n",
    "def plot_projection_y_with_errors(yc, data2d, model2d, mask, title, ylim, path):\n",
    "    \"\"\"\n",
    "    Proyección en Y (cosThetaK)\n",
    "    \"\"\"\n",
    "    data_proj, data_err = project_with_errors_y(data2d, mask)\n",
    "    model_proj, _ = project_with_errors_y(model2d, mask)\n",
    "    \n",
    "    if np.nanmean(model_proj) != 0:\n",
    "        scale = np.nanmean(data_proj) / np.nanmean(model_proj)\n",
    "    else:\n",
    "        scale = 1.0\n",
    "    model_proj_scaled = model_proj * scale\n",
    "\n",
    "    _plot_cms_style(centers=yc, data=data_proj, data_err=data_err, model=model_proj_scaled, xlabel=r\"$\\cos\\theta_K$\", title=title, ylim=ylim, path_dir=path) \n",
    "\n",
    "\n",
    "def select_q2_bin(df, n_bin, cut):\n",
    "    q2_bins = dict()\n",
    "    q2_bins = { \"bin0\":[1.1,23.0],   \"bin1\":[1.1, 2.0],\"bin2\": [2.0, 4.0],\"bin3\":[4.0, 6.0],\n",
    "                \"bin4\":[6.0, 7.0],   \"bin5\":[7.0, 8.0], \"bin6\": [8.0, 11.0],\"bin7\":[11.0, 12.5],\n",
    "                \"bin8\":[12.5, 15.0], \"bin9\":[15.0, 17.0], \"bin10\":[17.0, 23.0]}\n",
    "    df_ = df[(df[cut]>=q2_bins[n_bin][0]) & (df[cut] <= q2_bins[n_bin][1])].copy()\n",
    "    return df_\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# PHI  1D Bernstei\n",
    "# ======================================================\n",
    "\n",
    "def save_bernstein1d_model(filename, coef, n):\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    model = {\"n\": n, \"coef\": coef.tolist(), \"range\": [-np.pi, np.pi]}\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(model, f, indent=2)\n",
    "\n",
    "def bernstein1d_matrix(n, x):\n",
    "    \"\"\"\n",
    "    Build the design matrix for Bernstein 1D basis.\n",
    "    Input: x in [-1, 1] (array)\n",
    "    Output: B matrix of size (Npoints, n+1)\n",
    "    \"\"\"\n",
    "    # map [-1,1] -> [0,1]\n",
    "    t = 0.5 * (x + 1.0)\n",
    "    B_list = []\n",
    "    for i in range(n+1):\n",
    "        B_list.append(bernstein_1d(n, i, t))\n",
    "    B = np.vstack(B_list).T\n",
    "\n",
    "    return B\n",
    "\n",
    "\n",
    "def fit_bernstein1d(xcenters, eff1d, ngen1d, n=4, min_counts_mask=None, reg_lambda=1e-10):\n",
    "    \"\"\"\n",
    "    Fits a Bernstein 1D polynomial to a 1D efficiency histogram.\n",
    "    \"\"\"\n",
    "    # Filter NaNs and Zero Gen\n",
    "    if min_counts_mask is None:\n",
    "        use = (~np.isnan(eff1d)) & (ngen1d > 0)\n",
    "    else:\n",
    "        use = min_counts_mask & ~np.isnan(eff1d) & (ngen1d > 0)\n",
    "        \n",
    "    x_use = xcenters[use]\n",
    "    eff_use = eff1d[use]\n",
    "    ngen_use = ngen1d[use]\n",
    "    # Binomial uncertainty weights\n",
    "    sigma2 = eff_use * (1.0 - eff_use) / ngen_use\n",
    "    sigma2 = np.clip(sigma2, 1e-12, None)\n",
    "    w = 1.0 / np.sqrt(sigma2)\n",
    "    \n",
    "    B = bernstein1d_matrix(n, x_use)\n",
    "    Bw = B * w[:, None]\n",
    "    yw = eff_use * w\n",
    "    BTB = Bw.T @ Bw + reg_lambda * np.eye(B.shape[1])\n",
    "    BTy = Bw.T @ yw\n",
    "    coef = np.linalg.solve(BTB, BTy)\n",
    "    Bfull = bernstein1d_matrix(n, xcenters)\n",
    "    eff_model = Bfull @ coef\n",
    "    \n",
    "    return coef, eff_model\n",
    "\n",
    "def load_bernstein1d_model(filename):\n",
    "    \"\"\"Carga un modelo de Bernstein 1D desde un JSON.\"\"\"\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    coef = np.asarray(data[\"coef\"], dtype=np.float64)\n",
    "    if \"degree\" in data:\n",
    "        degree = data[\"degree\"]\n",
    "    else:\n",
    "        degree = len(coef) - 1\n",
    "        \n",
    "    return coef, degree\n",
    "\n",
    "\n",
    "def plot_1d_result(centers, data, model, mask, title, ylim, path):\n",
    "    valid = mask\n",
    "    dummy_err = np.zeros_like(data)\n",
    "    dummy_err[valid] = 0.05 * data[valid]     \n",
    "    _plot_cms_style(centers[valid], data[valid], dummy_err[valid], model[valid], xlabel=r\"$\\phi$\", title=title,ylim=ylim, path_dir=path)\n",
    "\n",
    "\n",
    "def run_fit(model, data):\n",
    "    nll = zfit.loss.UnbinnedNLL(model=model, data=data)\n",
    "    minimizer = zfit.minimize.Minuit()\n",
    "    result = minimizer.minimize(nll)\n",
    "    err = None\n",
    "    try:\n",
    "        err, _ = result.errors(name=\"minos\", method=\"minuit_minos\", cl=0.682)\n",
    "    except Exception as e:\n",
    "        print(\"MINOS failed:\", e)\n",
    "    return result, err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7c110",
   "metadata": {},
   "source": [
    "#  CODE FOR EFFICIENCY CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc58f68-dfcf-40d7-b335-25f997c73149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA=\"2022\"\n",
    "# YEAR='20'+ ERA.split(\"20\")[1]\n",
    "# path = f'/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/Bstomumuphi_{YEAR}/'\n",
    "# qsBinning=[]\n",
    "# #if args.decay == 'nonResonant':\n",
    "# qsBinning = [\"bin\"+str(i+1) for i in range(8)]\n",
    "# qsBinning.remove(\"bin4\")\n",
    "# qsBinning.remove(\"bin6\")\n",
    "# #elif args.decay == 'ResonantJpsi':\n",
    "# #    qsBinning = [\"bin4\"]\n",
    "# #elif args.decay == 'ResonantPsi':\n",
    "# #    qsBinning = [\"bin6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de5be7e-66b2-4c69-96bf-001757dd1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Gen Non-Filtered (genNFtr) cargado: 11589148 eventos\n",
      "2. Gen Filtered (genFtr) cargado: 307688 eventos\n",
      "3. Reco Gen Level Denom (recoGen) cargado: 6298017 eventos\n",
      "4. Reco Final (recoFtr) cargado: 900424 eventos\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "# --- RUTAS DE ARCHIVOS ---\n",
    "f_gen = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/datasets/GenLevel_Angular_Merged.root\"\n",
    "f_gen_filtered = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/datasets/GenLevel_Angular_Merged_Filtered.root\"\n",
    "f_reco_gen = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/datasets/RecoGenV2_Angular_Merged.root\"  \n",
    "x_gboost_cut = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/BdtoK0smumu-20251110T171511Z-1-001/MyReweiting/ResultsB0_2022/AntiRadVeto_MC_NoRes_2022_Era1_v0_XGBoost_fom_cut_BDT.root\"\n",
    "\n",
    "vars_gen_to_load = [\"gen_cosThetaK\", \"gen_cosThetaL\", \"gen_phi\", \"q2Gen\"]\n",
    "vars_reco_to_load = [\"CosThetaK_best\", \"CosThetaL_best\", \"Phi_best\", \"massJ\"] \n",
    "vars_xgboost_to_load = [\"CosThetaK\", \"CosThetaL\", \"Phi\", \"massB_test\", \"massJ\", \"TotalWeight\"] \n",
    "\n",
    "# --- CARGA DE DATOS ---\n",
    "#Gen NO filt\n",
    "genNFtr = uproot.open(f_gen)['ntuple'].arrays(vars_gen_to_load, library='pd')\n",
    "print(f\"1. Gen Non-Filtered (genNFtr) cargado: {len(genNFtr)} eventos\")\n",
    "# Gen Filtered\n",
    "genFtr = uproot.open(f_gen_filtered)['ntuple'].arrays(vars_gen_to_load, library='pd')\n",
    "print(f\"2. Gen Filtered (genFtr) cargado: {len(genFtr)} eventos\")\n",
    "# Reco Gen Level\n",
    "recoGen = uproot.open(f_reco_gen)['ntuple'].arrays(vars_reco_to_load, library='pd')\n",
    "print(f\"3. Reco Gen Level Denom (recoGen) cargado: {len(recoGen)} eventos\")\n",
    "# Final selection \n",
    "recoFtr = uproot.open(x_gboost_cut)['treeBd'].arrays(vars_xgboost_to_load, library='pd')\n",
    "print(f\"4. Reco Final (recoFtr) cargado: {len(recoFtr)} eventos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d00903e-cd4f-4c1d-a550-cbf0868ee246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recoFtr[\"q2\"] = recoFtr[\"massJ\"]**2 \n",
    "recoGen[\"q2Gen\"] = recoGen[\"massJ\"]**2  \n",
    "\n",
    "GenNFlt = genNFtr.copy()     \n",
    "GenFlt  = genFtr.copy()       \n",
    "\n",
    "RecoGenFlt = recoGen.copy()             \n",
    "mask_mass = (recoFtr[\"massB_test\"] > 5.0) & (recoFtr[\"massB_test\"] < 5.6)\n",
    "Reco = recoFtr[mask_mass].copy()\n",
    "\n",
    "eff_Gen, obs_Gen = train_test_split(GenNFlt, test_size=0.1, random_state=42)\n",
    "eff_GenFtr, obs_GenFtr = train_test_split(GenFlt, test_size=0.1, random_state=42)\n",
    "eff_RecoGenFtr, obs_RecoGenFtr = train_test_split(RecoGenFlt, test_size=0.1, random_state=42)\n",
    "eff_RecoFtr, obs_RecoFtr = train_test_split(Reco, test_size=0.1, random_state=42)\n",
    "\n",
    "a1 = np.array(obs_Gen[\"gen_cosThetaL\"])\n",
    "a2 = np.array(obs_Gen[\"gen_cosThetaK\"])\n",
    "a3 = np.array(obs_Gen[\"gen_phi\"])\n",
    "\n",
    "angles = np.array([a1, a2, a3])\n",
    "valid_observations_mask = ~np.isnan(angles).any(axis=0)\n",
    "filtered_data = angles[:, valid_observations_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd412c8-edfc-4a8e-93cb-e624871977c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# corr_matrix = np.corrcoef(filtered_data)\n",
    "# print(\"Matriz de correlación (Gen Level):\")\n",
    "# print(f\"{'':>15} {'cos(theta_L)':>12} {'cos(theta_K)':>12} {'phi':>12}\")\n",
    "# print(f\"{'cos(theta_L)':>15} {corr_matrix[0,0]:12.4f} {corr_matrix[0,1]:12.4f} {corr_matrix[0,2]:12.4f}\")\n",
    "# print(f\"{'cos(theta_K)':>15} {corr_matrix[1,0]:12.4f} {corr_matrix[1,1]:12.4f} {corr_matrix[1,2]:12.4f}\")\n",
    "# print(f\"{'phi':>15}          {corr_matrix[2,0]:12.4f} {corr_matrix[2,1]:12.4f} {corr_matrix[2,2]:12.4f}\")\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set(style=\"whitegrid\")\n",
    "# plt.figure(figsize=(8, 6)) \n",
    "# labels = [r\"$\\cos(\\theta_{\\ell})$\", r\"$\\cos(\\theta_K)$\", r\"$\\phi$\"]\n",
    "\n",
    "# sns.heatmap(corr_matrix, annot=True, fmt=\".5f\", cmap=\"coolwarm\", vmin=-1, vmax=1, xticklabels=labels, yticklabels=labels)\n",
    "# plt.title(f\"Correlation Matrix - Gen Level (2022)\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4712e529-e4f1-44bc-ad17-aeba5333b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Procesando bin1 ===\n",
      "\n",
      "=== Procesando bin2 ===\n",
      "\n",
      "=== Procesando bin3 ===\n",
      "\n",
      "=== Procesando bin4 ===\n",
      "\n",
      "=== Procesando bin5 ===\n",
      "\n",
      "=== Procesando bin7 ===\n",
      "\n",
      "=== Procesando bin9 ===\n",
      "\n",
      "=== Procesando bin10 ===\n"
     ]
    }
   ],
   "source": [
    "nbx=20\n",
    "nby=20\n",
    "nx_gen=4 \n",
    "ny_gen=4 \n",
    "nx_rec=4 \n",
    "ny_rec=4\n",
    "ylim_ck_a=(0.0, 0.040)\n",
    "ylim_cl_a=(0.0, 0.040)\n",
    "ylim_ck_r=(0.0, 0.30)\n",
    "ylim_cl_r=(0.2, 0.450)\n",
    "ylim_ck_t=(0.0, 0.008)\n",
    "ylim_cl_t=(0.0, 0.008)\n",
    "ylim_p_a=(0.0, 0.06)\n",
    "ylim_p_r=(0.0, 0.25)\n",
    "ylim_p_t=(0.0, 0.006)\n",
    "\n",
    "bin_configs = {\n",
    "    \"bin1\":  {\"q2_range\": [1.1, 2.0],   \"nbx\": 12, \"nby\": 12, \"nx_gen\": 5, \"ny_gen\": 5, \"nx_rec\": 5, \"ny_rec\": 5},\n",
    "    \"bin2\":  {\"q2_range\": [2.0, 4.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin3\":  {\"q2_range\": [4.0, 6.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin4\":  {\"q2_range\": [6.0, 7.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin5\":  {\"q2_range\": [7.0, 8.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin7\":  {\"q2_range\": [11.0, 12.5], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin9\":  {\"q2_range\": [15.0, 17.0], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin10\": {\"q2_range\": [17.0, 23.0], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec}\n",
    "}\n",
    "# bin_configs = {\n",
    "#     \"bin1\":  {\"q2_range\": [1.1, 2.0],   \"nbx\": 12, \"nby\": 12, \"nx_gen\": 5, \"ny_gen\": 5, \"nx_rec\": 5, \"ny_rec\": 5,                     \"ylim_ck_a\" : (0.0, 0.06), \"ylim_cl_a\": (0.0,0.06), \"ylim_ck_r\": (0.01,0.5), \"ylim_cl_r\": ylim_cl_r, \"ylim_cl_t\": (0.0,0.015), \"ylim_ck_t\": ylim_ck_t,\"ylim_p_a\" : (0.0, 0.040), \"ylim_p_r\": (0.0,0.5), \"ylim_p_t\": ylim_p_t},\n",
    "#     \"bin2\":  {\"q2_range\": [2.0, 4.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec, \"ylim_ck_a\" : ylim_ck_a, \"ylim_cl_a\": (0.0, 0.045), \"ylim_ck_r\": (0.0,0.5), \"ylim_cl_r\": (0.2,0.6), \"ylim_cl_t\": ylim_cl_t, \"ylim_ck_t\": ylim_ck_t, \"ylim_p_a\": (0.0,0.04), \"ylim_p_r\": (0.0,0.5), \"ylim_p_t\": ylim_p_t},\n",
    "#     \"bin3\":  {\"q2_range\": [4.0, 6.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec, \"ylim_ck_a\" : ylim_ck_a, \"ylim_cl_a\": ylim_cl_a, \"ylim_ck_r\": (0.0,0.5), \"ylim_cl_r\": ylim_cl_r, \"ylim_cl_t\": ylim_cl_t, \"ylim_ck_t\": ylim_ck_t, \"ylim_p_a\": (0.0,0.04), \"ylim_p_r\": (0.0,0.5), \"ylim_p_t\": ylim_p_t},\n",
    "#     \"bin4\":  {\"q2_range\": [6.0, 7.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec, \"ylim_ck_a\" : ylim_ck_a, \"ylim_cl_a\": ylim_cl_a, \"ylim_ck_r\": (0.0,0.5), \"ylim_cl_r\": ylim_cl_r, \"ylim_cl_t\": ylim_cl_t, \"ylim_ck_t\": ylim_ck_t, \"ylim_p_a\": (0.0,0.04), \"ylim_p_r\": (0.0,0.5), \"ylim_p_t\": ylim_p_t},\n",
    "#     \"bin5\":  {\"q2_range\": [7.0, 8.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec, \"ylim_ck_a\" : ylim_ck_a, \"ylim_cl_a\": ylim_cl_a, \"ylim_ck_r\": ylim_ck_r, \"ylim_cl_r\": ylim_cl_r, \"ylim_cl_t\": ylim_cl_t, \"ylim_ck_t\": ylim_ck_t, \"ylim_p_a\": ylim_p_a, \"ylim_p_r\": ylim_p_r, \"ylim_p_t\": ylim_p_t},\n",
    "#     \"bin7\":  {\"q2_range\": [11.0, 12.5],\"nbx\" : nbx,\"nby\" : nby,\"nx_gen\" : nx_gen,\"ny_gen\" : ny_gen,\"nx_rec\" : nx_rec,\"ny_rec\" : ny_rec, \"ylim_ck_a\" : (0.02,0.05),\"ylim_cl_a\" : (0.02,0.04),\"ylim_ck_r\" : ylim_ck_r,\"ylim_cl_r\" : ylim_cl_r, \"ylim_cl_t\": ylim_cl_t, \"ylim_ck_t\": ylim_ck_t,\"ylim_p_a\" : ylim_p_a,\"ylim_p_r\" : ylim_p_r,\"ylim_p_t\" : ylim_p_t},\n",
    "#     \"bin9\":  {\"q2_range\": [15.0, 17.0], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec, \"ylim_ck_a\" : (0.02,0.05),\"ylim_cl_a\" : (0.03,0.05),\"ylim_ck_r\" : ylim_ck_r,\"ylim_cl_r\" : (0.0,0.35), \"ylim_cl_t\": ylim_cl_t, \"ylim_ck_t\": ylim_ck_t,\"ylim_p_a\" : ylim_p_a,\"ylim_p_r\" : ylim_p_r,\"ylim_p_t\" : (0.002,0.015)},\n",
    "#     \"bin10\": {\"q2_range\": [17.0, 23.0], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec, \"ylim_ck_a\" : (0.0, 0.1),\"ylim_cl_a\" : (0.0, 0.1),\"ylim_ck_r\" : ylim_ck_r,\"ylim_cl_r\" : (0.02,0.35), \"ylim_cl_t\": (0.0,0.1), \"ylim_ck_t\": ylim_ck_t,\"ylim_p_a\" : ylim_p_a,\"ylim_p_r\" : ylim_p_r,\"ylim_p_t\" : (0.0, 0.015)}\n",
    "# }\n",
    "\n",
    "\n",
    "for binN, config in bin_configs.items():\n",
    "    print(f\"\\n=== Procesando {binN} ===\")\n",
    "    # ... (Configuración de variables igual que antes) ...\n",
    "    nbx=config[\"nbx\"]\n",
    "    nby=config[\"nby\"]\n",
    "    nx_gen=config[\"nx_gen\"]\n",
    "    ny_gen=config[\"ny_gen\"]\n",
    "    nx_rec=config[\"nx_rec\"]\n",
    "    ny_rec=config[\"ny_rec\"]\n",
    "    # ylim_ck_a=config[\"ylim_ck_a\"]\n",
    "    # ylim_cl_a=config[\"ylim_cl_a\"]\n",
    "    # ylim_ck_r=config[\"ylim_ck_r\"]\n",
    "    # ylim_cl_r=config[\"ylim_cl_r\"]\n",
    "    # ylim_cl_t=config[\"ylim_cl_t\"]\n",
    "    # ylim_ck_t=config[\"ylim_ck_t\"]\n",
    "    # ylim_p_a=config[\"ylim_p_a\"]\n",
    "    # ylim_p_r=config[\"ylim_p_r\"]\n",
    "    # ylim_p_t=config[\"ylim_p_t\"]\n",
    "\n",
    "    # 1. SELECCIÓN DE DATOS POR BIN Q2\n",
    "    eff_Gen_q2 =        select_q2_bin(eff_Gen, binN, \"q2Gen\")\n",
    "    eff_GenFtr_q2 =     select_q2_bin(eff_GenFtr, binN, \"q2Gen\")\n",
    "    eff_RecoGenFtr_q2 = select_q2_bin(eff_RecoGenFtr, binN, \"q2Gen\")\n",
    "    eff_RecoFtr_q2 =    select_q2_bin(eff_RecoFtr, binN, \"q2\") # Numerador Reco\n",
    "\n",
    "    # 2. EXTRACCIÓN DE VARIABLES Y PESOS\n",
    "    gen_x = eff_Gen_q2[\"gen_cosThetaL\"].values  \n",
    "    gen_y = eff_Gen_q2[\"gen_cosThetaK\"].values  \n",
    "    \n",
    "    genFid_x = eff_GenFtr_q2[\"gen_cosThetaL\"].values \n",
    "    genFid_y = eff_GenFtr_q2[\"gen_cosThetaK\"].values\n",
    "    \n",
    "    recoFid_x = eff_RecoGenFtr_q2[\"CosThetaL_best\"].values \n",
    "    recoFid_y = eff_RecoGenFtr_q2[\"CosThetaK_best\"].values\n",
    "    \n",
    "    reco_x = eff_RecoFtr_q2[\"CosThetaL\"].values\n",
    "    reco_y = eff_RecoFtr_q2[\"CosThetaK\"].values\n",
    "    \n",
    "    # --- NUEVO: Extraemos los pesos del BDT ---\n",
    "    reco_w = eff_RecoFtr_q2[\"TotalWeight\"].values  ### <--- CAMBIO CRÍTICO\n",
    "\n",
    "    # 3. CÁLCULO DE EFICIENCIA 2D CON PESOS\n",
    "    xcenters, ycenters, acc_gen, acc_gen_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen = build_efficiency_2d( \n",
    "        gen_x, gen_y, \n",
    "        genFid_x, genFid_y, \n",
    "        recoFid_x, recoFid_y, \n",
    "        reco_x, reco_y,\n",
    "        weights_reco=reco_w,   ### <--- SE PASAN LOS PESOS AQUÍ\n",
    "        nbx=nbx, nby=nby, \n",
    "        nxg=nx_gen, nyg=ny_gen, nxr=nx_rec, nyr=ny_rec, \n",
    "        min_gen=10, reg_acc=1e-5, reg_reco=1e-5\n",
    "    )\n",
    "\n",
    "    # ======================================================\n",
    "    # phi \n",
    "    # ======================================================\n",
    "    phi_gen_all = eff_Gen_q2[\"gen_phi\"].values\n",
    "    phi_gen_fid = eff_GenFtr_q2[\"gen_phi\"].values\n",
    "    phi_reco_fid = eff_RecoGenFtr_q2[\"Phi_best\"].values\n",
    "    phi_reco = eff_RecoFtr_q2[\"Phi\"].values\n",
    "    \n",
    "    # 4. CÁLCULO DE EFICIENCIA 1D CON PESOS\n",
    "    centers_phi, acc_phi, acc_phi_model, coef_acc_phi, eff_reco_phi, eff_reco_phi_model, coef_reco_phi, mask_phi = build_efficiency_1d( \n",
    "        phi_gen_all, \n",
    "        phi_gen_fid, \n",
    "        phi_reco_fid, \n",
    "        phi_reco, \n",
    "        weights_reco=reco_w,   ### <--- SE PASAN LOS PESOS AQUÍ TAMBIÉN\n",
    "        nbins=20, n_poly=4, reg_acc=1e-5, reg_reco=1e-5\n",
    "    )\n",
    "\n",
    "    # ... (El resto del código de ploteo y guardado se mantiene igual) ...\n",
    "    plt.ioff()\n",
    "    acc_model_file = f\"acc_gen_model_{binN}.json\"\n",
    "    reco_model_file = f\"eff_reco_model_{binN}.json\"\n",
    "    path_models = f\"models/{binN}/\"\n",
    "    path_plots = f\"plots/projections/{binN}/\"\n",
    "\n",
    "    save_bernstein2d_model(path_models + reco_model_file, coef_reco, nx_rec, ny_rec)\n",
    "    save_bernstein2d_model(path_models + acc_model_file, coef_acc, nx_gen, ny_gen)\n",
    "    save_bernstein1d_model(f\"models/{binN}/acc_gen_model_phi_{binN}.json\", coef_acc_phi, 4)\n",
    "    save_bernstein1d_model(f\"models/{binN}/eff_reco_model_phi_{binN}.json\", coef_reco_phi, 4)\n",
    "    \n",
    "    # ======================================================\n",
    "    # PLOTEOS (Sin cambios necesarios, usan los arrays ya calculados)\n",
    "    # ======================================================\n",
    "    # ... (Tus llamadas a plot_projection_x_with_errors, etc. siguen igual) ...\n",
    "    # CosThetaL y CosThetaK\n",
    "    plot_projection_x_with_errors(xcenters, acc_gen, acc_gen_model, mask_gen, f\"{binN} \"+r\"Gen Acceptance: $\\cos\\theta_\\ell$\", ylim=None, path=path_plots)\n",
    "    plot_projection_y_with_errors( ycenters, acc_gen, acc_gen_model, mask_gen,  f\"{binN} \"+r\"Gen Acceptance: $\\cos\\theta_K$\",  ylim=None, path=path_plots)\n",
    "    \n",
    "    plot_projection_x_with_errors(xcenters, eff_reco, eff_reco_model, mask_gen, f\"{binN} \"+r\"Reco Efficiency: $\\cos\\theta_\\ell$\", ylim=None, path=path_plots)\n",
    "    plot_projection_y_with_errors(ycenters, eff_reco, eff_reco_model, mask_gen, f\"{binN} \"+r\"Reco Efficiency: $\\cos\\theta_K$\", ylim=None, path=path_plots)\n",
    "    \n",
    "    plot_projection_x_with_errors( xcenters, acc_gen*eff_reco, acc_gen_model*eff_reco_model, mask_gen, f\"{binN} \"+r\"Total efficiency: projection cos$\\theta_\\ell$\",ylim=None,path=path_plots)\n",
    "    plot_projection_y_with_errors( xcenters, acc_gen*eff_reco, acc_gen_model*eff_reco_model, mask_gen, f\"{binN} \"+r\"Total efficiency: projection cos$\\theta_K$\",ylim=None, path=path_plots)\n",
    "\n",
    "    # Phi\n",
    "    plot_1d_result(centers_phi, acc_phi, acc_phi_model, mask_phi, f\"{binN} \"+r\"Gen Acceptance $\\phi$\",ylim=None,path=path_plots)\n",
    "    plot_1d_result(centers_phi, eff_reco_phi, eff_reco_phi_model, mask_phi, f\"{binN} \"+r\"Reco Efficiency $\\phi$\",ylim=None,path=path_plots)\n",
    "    plot_1d_result(centers_phi, acc_phi*eff_reco_phi, acc_phi_model*eff_reco_phi_model, mask_phi, f\"{binN} \"+r\"Total efficiency $\\phi$\",ylim=None,path=path_plots)\n",
    "    plt.ion()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for binN, config in bin_configs.items():\n",
    "#     print(f\"\\n=== Procesando {binN} ===\")\n",
    "#     nbx=config[\"nbx\"]\n",
    "#     nby=config[\"nby\"]\n",
    "#     nx_gen=config[\"nx_gen\"]\n",
    "#     ny_gen=config[\"ny_gen\"]\n",
    "#     nx_rec=config[\"nx_rec\"]\n",
    "#     ny_rec=config[\"ny_rec\"]\n",
    "#     ylim_ck_a=config[\"ylim_ck_a\"]\n",
    "#     ylim_cl_a=config[\"ylim_cl_a\"]\n",
    "#     ylim_ck_r=config[\"ylim_ck_r\"]\n",
    "#     ylim_cl_r=config[\"ylim_cl_r\"]\n",
    "#     ylim_cl_t=config[\"ylim_cl_t\"]\n",
    "#     ylim_ck_t=config[\"ylim_ck_t\"]\n",
    "#     ylim_p_a=config[\"ylim_p_a\"]\n",
    "#     ylim_p_r=config[\"ylim_p_r\"]\n",
    "#     ylim_p_t=config[\"ylim_p_t\"]\n",
    "\n",
    "#     eff_Gen_q2 =   select_q2_bin(eff_Gen, binN, \"q2Gen\")\n",
    "#     eff_GenFtr_q2 =   select_q2_bin(eff_GenFtr, binN, \"q2Gen\")\n",
    "#     eff_RecoGenFtr_q2 =   select_q2_bin(eff_RecoGenFtr,binN, \"q2Gen\")\n",
    "#     eff_RecoFtr_q2 =   select_q2_bin(eff_RecoFtr,binN, \"q2\")\n",
    "\n",
    "#     gen_x = eff_Gen_q2[\"gen_cosThetaL\"].values  \n",
    "#     gen_y = eff_Gen_q2[\"gen_cosThetaK\"].values  \n",
    "#     genFid_x = eff_GenFtr_q2[\"gen_cosThetaL\"].values \n",
    "#     genFid_y = eff_GenFtr_q2[\"gen_cosThetaK\"].values\n",
    "#     recoFid_x = eff_RecoGenFtr_q2[\"CosThetaL_best\"].values \n",
    "#     recoFid_y = eff_RecoGenFtr_q2[\"CosThetaK_best\"].values\n",
    "#     reco_x = eff_RecoFtr_q2[\"CosThetaL\"].values\n",
    "#     reco_y = eff_RecoFtr_q2[\"CosThetaK\"].values \n",
    "\n",
    "#     xcenters, ycenters,  acc_gen, acc_gen_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen = build_efficiency_2d( \n",
    "#         gen_x, gen_y, genFid_x, genFid_y, recoFid_x, recoFid_y, reco_x, reco_y,nbx=nbx, nby=nby, \n",
    "#         nxg=nx_gen, nyg=ny_gen, nxr=nx_rec, nyr=ny_rec, min_gen=10, reg_acc=1e-5, reg_reco=1e-5)\n",
    "\n",
    "#     # ======================================================\n",
    "#     # phi \n",
    "#     # ======================================================\n",
    "#     phi_gen_all = eff_Gen_q2[\"gen_phi\"].values\n",
    "#     phi_gen_fid = eff_GenFtr_q2[\"gen_phi\"].values\n",
    "#     phi_reco_fid = eff_RecoGenFtr_q2[\"Phi_best\"].values\n",
    "#     phi_reco = eff_RecoFtr_q2[\"Phi\"].values\n",
    "#     centers_phi, acc_phi, acc_phi_model, coef_acc_phi, eff_reco_phi, eff_reco_phi_model, coef_reco_phi, mask_phi = build_efficiency_1d( \n",
    "#         phi_gen_all, phi_gen_fid, phi_reco_fid, phi_reco, nbins=20, n_poly=4, reg_acc=1e-5,reg_reco=1e-5)\n",
    "#     plt.ioff()\n",
    "#     acc_model_file = f\"acc_gen_model_{binN}.json\"\n",
    "#     reco_model_file = f\"eff_reco_model_{binN}.json\"\n",
    "#     path_models = f\"models/{binN}/\"\n",
    "#     path_plots = f\"plots/projections/{binN}/\"\n",
    "\n",
    "#     save_bernstein2d_model(path_models + reco_model_file, coef_reco, nx_rec, ny_rec)\n",
    "#     save_bernstein2d_model(path_models + acc_model_file, coef_acc, nx_gen, ny_gen)\n",
    "#     save_bernstein1d_model(f\"models/{binN}/acc_gen_model_phi_{binN}.json\", coef_acc_phi, 4)\n",
    "#     save_bernstein1d_model(f\"models/{binN}/eff_reco_model_phi_{binN}.json\", coef_reco_phi, 4)\n",
    "#     # ======================================================\n",
    "#     # cosThetaL y cosThetaK\n",
    "#     # ======================================================\n",
    "#     # Acceptance\n",
    "#     plot_projection_x_with_errors(xcenters, acc_gen, acc_gen_model, mask_gen, f\"{binN} \"+r\"Gen Acceptance: $\\cos\\theta_\\ell$\", ylim=ylim_cl_a, path=path_plots)\n",
    "#     plot_projection_y_with_errors( ycenters, acc_gen, acc_gen_model, mask_gen,  f\"{binN} \"+r\"Gen Acceptance: $\\cos\\theta_K$\",  ylim=ylim_ck_a, path=path_plots)\n",
    "#     # Reconstruction efficiency\n",
    "#     plot_projection_x_with_errors(xcenters, eff_reco, eff_reco_model, mask_gen, f\"{binN} \"+r\"Reco Efficiency: $\\cos\\theta_\\ell$\", ylim=ylim_cl_r, path=path_plots)\n",
    "#     plot_projection_y_with_errors(ycenters, eff_reco, eff_reco_model, mask_gen, f\"{binN} \"+r\"Reco Efficiency: $\\cos\\theta_K$\", ylim=ylim_ck_r, path=path_plots)\n",
    "#     # Total efficiency (Acceptance * Reco)\n",
    "#     plot_projection_x_with_errors( xcenters, acc_gen*eff_reco, acc_gen_model*eff_reco_model, mask_gen, f\"{binN} \"+r\"Total efficiency: projection cos$\\theta_\\ell$\",ylim=ylim_cl_t,path=path_plots)\n",
    "#     plot_projection_y_with_errors( xcenters, acc_gen*eff_reco, acc_gen_model*eff_reco_model, mask_gen, f\"{binN} \"+r\"Total efficiency: projection cos$\\theta_K$\",ylim=ylim_ck_t, path=path_plots)\n",
    "\n",
    "#     # ======================================================\n",
    "#     # Phi\n",
    "#     # ======================================================\n",
    "#     # Acceptance\n",
    "#     plot_1d_result(centers_phi, acc_phi, acc_phi_model, mask_phi, f\"{binN} \"+r\"Gen Acceptance $\\phi$\",ylim=ylim_p_a,path=path_plots)\n",
    "#     # Reconstruction efficiency\n",
    "#     plot_1d_result(centers_phi, eff_reco_phi, eff_reco_phi_model, mask_phi, f\"{binN} \"+r\"Reco Efficiency $\\phi$\",ylim=ylim_p_r,path=path_plots)\n",
    "#     # Total efficiency (Acceptance * Reco)\n",
    "#     plot_1d_result(centers_phi, acc_phi*eff_reco_phi, acc_phi_model*eff_reco_phi_model, mask_phi, f\"{binN} \"+r\"Total efficiency $\\phi$\",ylim=ylim_p_t,path=path_plots)\n",
    "#     plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348446c8-d622-4387-b373-00feaf3e0614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153583ea-b8a9-44d7-b739-f6bf5ec5c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,5))\n",
    "# plt.scatter(eff_reco[mask_gen], eff_reco_model[mask_gen], s=8, alpha=0.4)\n",
    "# plt.plot([0,0.2], [0,0.2], \"r--\")\n",
    "# plt.xlabel(\"Binned efficiency\")\n",
    "# plt.ylabel(\"Bernstein model\")\n",
    "# plt.grid(True)\n",
    "# plt.title(\"Bin-by-bin comparison\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a1ecd",
   "metadata": {},
   "source": [
    "# CODE FOR FIT INCLUDING EFFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddaa82-5d15-4a30-808f-8bfba8c1f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zfit\n",
    "from zfit import z\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PDFs import FullAngular_Transformed_PDF, apply_transformation_equations\n",
    "\n",
    "def tf_bernstein_basis_vectorized(n, t):\n",
    "    M = tf.shape(t)[0]\n",
    "    k = tf.range(n + 1, dtype=tf.float64)\n",
    "    n_float = tf.cast(n, tf.float64)\n",
    "    log_binom = tf.math.lgamma(n_float + 1.0) - tf.math.lgamma(k + 1.0) - tf.math.lgamma(n_float - k + 1.0)\n",
    "    binom = tf.exp(log_binom)\n",
    "    t_col = tf.expand_dims(t, -1) \n",
    "    k_row = tf.expand_dims(k, 0)\n",
    "    term1 = tf.pow(t_col, k_row)\n",
    "    term2 = tf.pow(1.0 - t_col, n_float - k_row)\n",
    "    basis = binom * term1 * term2 \n",
    "    return basis\n",
    "\n",
    "class Efficiency_Bernstein_Factorized(zfit.pdf.BasePDF):\n",
    "    def __init__(self, obs,coef_acc_2d, coef_acc_phi, nx_acc, ny_acc, n_phi_acc, coef_reco_2d, coef_reco_phi, nx_reco, ny_reco, n_phi_reco,\n",
    "                 name=\"Full_Efficiency_Model\"):\n",
    "        \"\"\"\n",
    "        Modelo Completo: Aceptancia * Eficiencia de Reconstrucción.\n",
    "        Cada parte factorizada en 2D(cosL, cosK) * 1D(phi).\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'c_acc_2d': zfit.Parameter(f\"c_a2d_{name}\", tf.cast(coef_acc_2d, tf.float64), floating=False),\n",
    "            'c_acc_phi': zfit.Parameter(f\"c_aphi_{name}\", tf.cast(coef_acc_phi, tf.float64), floating=False),\n",
    "            'c_reco_2d': zfit.Parameter(f\"c_r2d_{name}\", tf.cast(coef_reco_2d, tf.float64), floating=False),\n",
    "            'c_reco_phi': zfit.Parameter(f\"c_rphi_{name}\", tf.cast(coef_reco_phi, tf.float64), floating=False),\n",
    "        }\n",
    "        \n",
    "        # Guardamos los grados de los polinomios\n",
    "        self.nx_acc, self.ny_acc = nx_acc, ny_acc\n",
    "        self.n_phi_acc = n_phi_acc\n",
    "        self.nx_reco, self.ny_reco = nx_reco, ny_reco\n",
    "        self.n_phi_reco = n_phi_reco\n",
    "        \n",
    "        super().__init__(obs, params, name=name)\n",
    "\n",
    "    def _unnormalized_pdf(self, x):\n",
    "        vars_list = z.unstack_x(x)\n",
    "        cos_l, cos_k, phi = vars_list[0], vars_list[1], vars_list[2]\n",
    "\n",
    "        # [-1, 1] -> [0, 1] y [-pi, pi] -> [0, 1]\n",
    "        tx = 0.5 * (cos_l + 1.0)\n",
    "        ty = 0.5 * (cos_k + 1.0)\n",
    "        t_phi = (phi + np.pi) / (2.0 * np.pi)\n",
    "        # ======================================================\n",
    "        # ACEPTANCIA\n",
    "        # ======================================================\n",
    "        # Bases\n",
    "        Bx_acc = tf_bernstein_basis_vectorized(self.nx_acc, tx)\n",
    "        By_acc = tf_bernstein_basis_vectorized(self.ny_acc, ty)\n",
    "        Bphi_acc = tf_bernstein_basis_vectorized(self.n_phi_acc, t_phi)\n",
    "        \n",
    "        # 2D part\n",
    "        c_acc_2d_mat = tf.reshape(self.params['c_acc_2d'], (self.nx_acc + 1, self.ny_acc + 1))\n",
    "        acc_2d = tf.einsum('mi,mj,ij->m', Bx_acc, By_acc, c_acc_2d_mat)\n",
    "        # 1D part\n",
    "        acc_phi = tf.einsum('mk,k->m', Bphi_acc, self.params['c_acc_phi'])\n",
    "        # Total Acceptance\n",
    "        total_acc = acc_2d * acc_phi\n",
    "\n",
    "        # ======================================================\n",
    "        # EFICIENCIA DE RECONSTRUCCIÓN\n",
    "        # ======================================================\n",
    "        # Bases\n",
    "        Bx_reco = tf_bernstein_basis_vectorized(self.nx_reco, tx)\n",
    "        By_reco = tf_bernstein_basis_vectorized(self.ny_reco, ty)\n",
    "        Bphi_reco = tf_bernstein_basis_vectorized(self.n_phi_reco, t_phi)\n",
    "        \n",
    "        # 2D part\n",
    "        c_reco_2d_mat = tf.reshape(self.params['c_reco_2d'], (self.nx_reco + 1, self.ny_reco + 1))\n",
    "        reco_2d = tf.einsum('mi,mj,ij->m', Bx_reco, By_reco, c_reco_2d_mat)\n",
    "        # 1D part\n",
    "        reco_phi = tf.einsum('mk,k->m', Bphi_reco, self.params['c_reco_phi'])\n",
    "        # Total Reco Efficiency\n",
    "        total_reco = reco_2d * reco_phi\n",
    "\n",
    "        # ======================================================\n",
    "        # EFICIENCIA FINAL\n",
    "        # ======================================================\n",
    "        return tf.maximum(total_acc * total_reco, 1e-15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_fit_results(result, bin_n, base_dir=\"fit_results\"):\n",
    "    \"\"\"\n",
    "    Guarda resultados buscando errores con nombres personalizados ('minos') \n",
    "    o por defecto ('minuit_minos', 'minuit_hesse').\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Crear directorios (ej: fit_results/gen/bin2)\n",
    "    output_folder = os.path.join(base_dir, f\"{bin_n}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(output_folder, \"fit_results.json\")\n",
    "    \n",
    "    params_dict = {}\n",
    "    \n",
    "    for p in result.params:\n",
    "        val = result.params[p]['value']\n",
    "        p_data = result.params[p] # Diccionario de resultados para este parámetro\n",
    "        \n",
    "        # --- LÓGICA DE BÚSQUEDA DE ERRORES CORREGIDA ---\n",
    "        lower_err = 0.0\n",
    "        upper_err = 0.0\n",
    "        sym_err = 0.0\n",
    "        error_type = \"none\"\n",
    "\n",
    "        # 1. Buscamos 'minos' (El nombre que tú usaste en run_fit)\n",
    "        if 'minos' in p_data:\n",
    "            err_data = p_data['minos']\n",
    "            lower_err = err_data.get('lower', 0.0)\n",
    "            upper_err = err_data.get('upper', 0.0)\n",
    "            sym_err = (abs(lower_err) + abs(upper_err)) / 2.0\n",
    "            error_type = \"minos (custom)\"\n",
    "\n",
    "        # 2. Buscamos 'minuit_minos' (Nombre default de zfit)\n",
    "        elif 'minuit_minos' in p_data:\n",
    "            err_data = p_data['minuit_minos']\n",
    "            lower_err = err_data.get('lower', 0.0)\n",
    "            upper_err = err_data.get('upper', 0.0)\n",
    "            sym_err = (abs(lower_err) + abs(upper_err)) / 2.0\n",
    "            error_type = \"minos (default)\"\n",
    "            \n",
    "        # 3. Buscamos Hesse (Simétrico)\n",
    "        elif 'minuit_hesse' in p_data:\n",
    "            err_data = p_data['minuit_hesse']\n",
    "            sym_err = err_data.get('error', -999.0)\n",
    "            lower_err = -sym_err\n",
    "            upper_err = sym_err\n",
    "            error_type = \"hesse\"\n",
    "            \n",
    "        else:\n",
    "            sym_err = -999.0\n",
    "            error_type = \"failed\"\n",
    "\n",
    "        params_dict[p.name] = {\n",
    "            'value': float(val),\n",
    "            'error': float(sym_err),\n",
    "            'error_low': float(lower_err),\n",
    "            'error_up': float(upper_err),\n",
    "            'error_source': error_type\n",
    "        }\n",
    "\n",
    "    # Extracción de Covarianza\n",
    "    try:\n",
    "        cov_matrix = result.covariance()\n",
    "        cov_list = np.array(cov_matrix).tolist()\n",
    "    except Exception:\n",
    "        cov_list = None\n",
    "\n",
    "    data_to_save = {\n",
    "        'bin_index': str(bin_n),\n",
    "        'valid': bool(result.valid),\n",
    "        'converged': bool(result.converged),\n",
    "        'fmin': float(result.fmin),\n",
    "        'status': result.status,\n",
    "        'parameters': params_dict,\n",
    "        'covariance': cov_list\n",
    "    }\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data_to_save, f, indent=4)\n",
    "        \n",
    "    print(f\"[CheckPoint] Resultados guardados en: {output_file}\")\n",
    "    return output_file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_bins = {\"bin1\":[1.1, 2.0],\"bin2\": [2.0, 4.0],\"bin3\":[4.0, 6.0], \"bin4\":[6.0, 7.0], \"bin5\":[7.0, 8.0],\"bin7\":[11.0, 12.5], \"bin9\":[15.0, 17.0], \"bin10\":[17.0, 23.0]}\n",
    "\n",
    "\n",
    "\n",
    "for binN in q2_bins.keys():\n",
    "    print(f\"\\n{'='*60}\\nProcesando {binN} con rango q2: {q2_bins[binN]}\\n{'='*60}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # CONFIGURACIÓN DEL ESPACIO \n",
    "    # ======================================================\n",
    "    cos_l = zfit.Space('cos_l', limits=(-1, 1))\n",
    "    cos_k = zfit.Space('cos_k', limits=(-1, 1))\n",
    "    phi   = zfit.Space('phi',   limits=(-np.pi, np.pi)) \n",
    "    obs_ang = cos_l * cos_k * phi  \n",
    "\n",
    "    # Parámetros Físicos\n",
    "    rFL  = zfit.Parameter(f'rFL_{binN}',  0.1, step_size=0.01)\n",
    "    rS3  = zfit.Parameter(f'rS3_{binN}',  0.0, step_size=0.01)\n",
    "    rS9  = zfit.Parameter(f'rS9_{binN}',  0.0, step_size=0.01)\n",
    "    rAFB = zfit.Parameter(f'rAFB_{binN}', 0.0, step_size=0.01)\n",
    "    rS4  = zfit.Parameter(f'rS4_{binN}',  0.0, step_size=0.01)\n",
    "    rS7  = zfit.Parameter(f'rS7_{binN}',  0.0, step_size=0.01)\n",
    "    rS5  = zfit.Parameter(f'rS5_{binN}',  0.0, step_size=0.01)\n",
    "    rS8  = zfit.Parameter(f'rS8_{binN}',  0.0, step_size=0.01)\n",
    "\n",
    "    # Listas auxiliares\n",
    "    r_keys = ['rFL', 'rS3', 'rS9', 'rAFB', 'rS4', 'rS7', 'rS5', 'rS8']\n",
    "    fit_params_list = [rFL, rS3, rS9, rAFB, rS4, rS7, rS5, rS8]\n",
    "\n",
    "    # ======================================================\n",
    "    # CONSTRUCCIÓN DE PDFs Y CARGA DE DATOS\n",
    "    # ======================================================\n",
    "\n",
    "    # PDF  Transformada\n",
    "    pdf_ang_trans = FullAngular_Transformed_PDF(obs_ang, rFL, rS3, rS9, rAFB, rS4, rS7, rS5, rS8)\n",
    "\n",
    "    # PDF de Eficiencia\n",
    "    coef_acc, nx_acc, ny_acc = load_bernstein_model(f\"models/{binN}/acc_gen_model_{binN}.json\")\n",
    "    coef_acc_phi, n_phi_acc = load_bernstein1d_model(f\"models/{binN}/acc_gen_model_phi_{binN}.json\")\n",
    "\n",
    "    coef_reco, nx_reco, ny_reco = load_bernstein_model(f\"models/{binN}/eff_reco_model_{binN}.json\")\n",
    "    coef_reco_phi, n_phi_reco = load_bernstein1d_model(f\"models/{binN}/eff_reco_model_phi_{binN}.json\")\n",
    "\n",
    "    eff_pdf = Efficiency_Bernstein_Factorized(\n",
    "        obs=obs_ang, coef_acc_2d=coef_acc, coef_acc_phi=coef_acc_phi, nx_acc=nx_acc, ny_acc=ny_acc, n_phi_acc=n_phi_acc,\n",
    "        coef_reco_2d=coef_reco, coef_reco_phi=coef_reco_phi,nx_reco=nx_reco, ny_reco=ny_reco, n_phi_reco=n_phi_reco, name=f\"Eff_Model_{binN}\")\n",
    "    pdf_sig = zfit.pdf.ProductPDF([pdf_ang_trans, eff_pdf])\n",
    "\n",
    "\n",
    "    # Carga de Datos\n",
    "    obs_Gen_q2 = select_q2_bin(obs_Gen, binN, \"q2Gen\")\n",
    "    obs_RecoFtr_q2 = select_q2_bin(obs_RecoFtr, binN, \"q2\")\n",
    "\n",
    "    data_true = zfit.Data.from_numpy(array=obs_Gen_q2[[\"gen_cosThetaL\", \"gen_cosThetaK\", \"gen_phi\"]].to_numpy(), obs=obs_ang)\n",
    "    data_reco = zfit.Data.from_numpy(array=obs_RecoFtr_q2[[\"CosThetaL\", \"CosThetaK\", \"Phi\"]].to_numpy(), obs=obs_ang)\n",
    "\n",
    "    # ======================================================\n",
    "    # FITS\n",
    "    # ======================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\">>> INICIANDO FIT GEN LEVEL (CONTROL)\")\n",
    "    print(\"=\"*60)\n",
    "    result_gen, errors_gen = run_fit(pdf_ang_trans, data_true)\n",
    "    print(result_gen.params)\n",
    "    results_gen_save = save_fit_results(result_gen, binN, base_dir=\"fit_results/gen\")\n",
    "    \n",
    "\n",
    "    r_values = [result_gen.params[p]['value'] for p in fit_params_list]\n",
    "    phys_vals = apply_transformation_equations(*r_values)\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(f\"RESUMEN DE OBSERVABLES FÍSICOS (Bin: {binN})\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"{'Observable':<10} | {'Valor Físico':<15}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # Orden deseado de impresión\n",
    "    print_order = ['FL', 'AFB', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9']\n",
    "    \n",
    "    for key in print_order:\n",
    "        val = phys_vals.get(key, 0.0) # get seguro\n",
    "        print(f\"{key:<10} | {val:>15.6f}\")\n",
    "    print(\"-\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\">>> INICIANDO FIT RECO)\")\n",
    "    # print(\"=\"*60)\n",
    "    # for p in fit_params_list: p.set_value(0.01)    \n",
    "    # pdf_sig.update_integration_options(max_draws=200000, tol=1e-5)\n",
    "    # result_reco, errors_reco = run_fit(pdf_sig, data_reco)\n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\">>> RESULTADOS FINALES DEL FIT RECO\")\n",
    "    # print(\"=\"*60)\n",
    "    # print(result_reco)\n",
    "    # results_save = save_fit_results(result_reco, binN, base_dir=\"fit_results/reco\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8c6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haza_wokr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
