{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1960c1d6-e790-405d-93ad-04141d1ddbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 11:39:04.914546: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-21 11:39:05.087182: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-21 11:39:05.672860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ghcp/miniconda3/envs/haza_wokr_env/lib/python3.8/site-packages/zfit/__init__.py:63: UserWarning: TensorFlow warnings are by default suppressed by zfit. In order to show them, set the environment variable ZFIT_DISABLE_TF_WARNINGS=0. In order to suppress the TensorFlow warnings AND this warning, set ZFIT_DISABLE_TF_WARNINGS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from pandas import Series, DataFrame \n",
    "import uproot \n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import comb\n",
    "from scipy.stats import chi2\n",
    "from scipy.special import comb\n",
    "from scipy.optimize import lsq_linear\n",
    "import sys\n",
    "from plot_tools import *\n",
    "from customStats import *\n",
    "#import tools\n",
    "import common_tools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "# from selection_cuts import selection_nominal\n",
    "import mplhep as hep\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams['figure.figsize'] = [10,8]\n",
    "plt.rcParams['font.size'] = 24\n",
    "plt.figure()\n",
    "plt.close()\n",
    "plt.rcParams.update({'figure.figsize':[10,8]})\n",
    "plt.rcParams.update({'font.size':24})\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import zfit\n",
    "from zfit import z\n",
    "import xgboost as xgb\n",
    "from scipy.interpolate import make_interp_spline\n",
    "# from loadCutXGB import load_and_cutXGBclfs\n",
    "from scipy.special import comb\n",
    "from scipy.optimize import lsq_linear\n",
    "zfit.settings.set_verbosity(0)\n",
    "import json\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Oculta los mensajes de INFO y WARNING\n",
    "from PDFs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49dd09",
   "metadata": {},
   "source": [
    "# FUNCTIONS FOR CALCULATING EFFICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19db1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bernstein_1d(n, k, t):\n",
    "    \"\"\"Bernstein base polynomial B_{n,k}(t) on t in [0,1].\"\"\"\n",
    "    return comb(n, k) * (t**k) * ((1.0 - t)**(n - k))\n",
    "\n",
    "\n",
    "def bernstein2d_matrix(nx, ny, x, y):\n",
    "    \"\"\"\n",
    "    Build the design matrix for Bernstein2D basis.\n",
    "    Input: x, y in [-1,1] (arrays)\n",
    "    Output: B matrix of size (Npoints, (nx+1)*(ny+1))\n",
    "    \"\"\"\n",
    "    # map [-1,1] -> [0,1]\n",
    "    tx = 0.5*(x + 1.0)\n",
    "    ty = 0.5*(y + 1.0)\n",
    "\n",
    "    B_list = []\n",
    "    for i in range(nx+1):\n",
    "        for j in range(ny+1):\n",
    "            B_list.append(bernstein_1d(nx, i, tx) * bernstein_1d(ny, j, ty))\n",
    "    B = np.vstack(B_list).T   # shape (Npoints, Ncoef)\n",
    "    return B\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# 2) Fit Bernstein2D to a 2D efficiency map\n",
    "# ======================================================\n",
    "def fit_bernstein2d( xcenters, ycenters, eff2d, ngen2d, nx=8, ny=8, min_counts_mask=None,reg_lambda=1e-10,):\n",
    "    \"\"\"\n",
    "    Fits a Bernstein2D polynomial to a 2D efficiency map using least squares + Tikhonov reg.\n",
    "\n",
    "    Inputs:\n",
    "        xcenters, ycenters   1D arrays (bin centers)\n",
    "        eff2d                2D array with efficiency values (NaNs allowed)\n",
    "        nx, ny               polynomial orders\n",
    "        min_counts_mask      Boolean 2D mask (valid bins: True)\n",
    "        reg_lambda           regularization parameter\n",
    "\n",
    "    Returns:\n",
    "        coef                 fitted coefficients\n",
    "        eff_model            modeled efficiency on the grid\n",
    "\n",
    "    \n",
    "    Weighted fit of a Bernstein2D polynomial to a 2D efficiency map.\n",
    "\n",
    "    The weights are derived from binomial uncertainties:\n",
    "        sigma^2 = eff * (1 - eff) / ngen\n",
    "    \"\"\"\n",
    "\n",
    "    XX, YY = np.meshgrid(xcenters, ycenters, indexing=\"ij\")\n",
    "    xflat = XX.ravel()\n",
    "    yflat = YY.ravel()\n",
    "    eff_flat = eff2d.ravel()\n",
    "    ngen_flat = ngen2d.ravel()\n",
    "\n",
    "    # Valid bins\n",
    "    if min_counts_mask is None: use = (~np.isnan(eff_flat)) & (ngen_flat > 0)\n",
    "    else:\n",
    "        use = (min_counts_mask.ravel() & ~np.isnan(eff_flat)& (ngen_flat > 0))\n",
    "\n",
    "    x_use = xflat[use]\n",
    "    y_use = yflat[use]\n",
    "    eff_use = eff_flat[use]\n",
    "    ngen_use = ngen_flat[use]\n",
    "\n",
    "    # Binomial uncertainty\n",
    "    sigma2 = eff_use * (1.0 - eff_use) / ngen_use\n",
    "    sigma2 = np.clip(sigma2, 1e-12, None)\n",
    "    w = 1.0 / np.sqrt(sigma2)\n",
    "    B = bernstein2d_matrix(nx, ny, x_use, y_use)\n",
    "\n",
    "    # Apply weights\n",
    "    Bw = B * w[:, None]\n",
    "    yw = eff_use * w\n",
    "\n",
    "    # Regularized weighted least squares\n",
    "    BTB = Bw.T @ Bw + reg_lambda * np.eye(B.shape[1])\n",
    "    BTy = Bw.T @ yw\n",
    "    coef = np.linalg.solve(BTB, BTy)\n",
    "    Bfull = bernstein2d_matrix(nx, ny, xflat, yflat)\n",
    "    eff_model_flat = Bfull @ coef\n",
    "    eff_model = eff_model_flat.reshape(eff2d.shape)\n",
    "    return coef, eff_model\n",
    "\n",
    "\n",
    "def build_efficiency_2d(gen_all_x, gen_all_y, gen_fid_x, gen_fid_y, reco_fid_x, reco_fid_y, reco_x, reco_y, \n",
    "                        weights_reco=None, nbx=20, nby=20, nxg=8, nyg=8, nxr=8, nyr=8, min_gen=0, reg_acc=1e-4, reg_reco=1e-4):\n",
    "    xedges = np.linspace(-1, 1, nbx + 1)\n",
    "    yedges = np.linspace(-1, 1, nby + 1)\n",
    "    xcenters = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "    ycenters = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "\n",
    "    # Pesos \n",
    "    if weights_reco is None:\n",
    "        weights_reco = np.ones(len(reco_x))\n",
    "\n",
    "    # Histograms\n",
    "    gen_allH, _, _ = np.histogram2d(gen_all_x, gen_all_y, bins=[xedges, yedges])\n",
    "    gen_fidH, _, _ = np.histogram2d(gen_fid_x, gen_fid_y, bins=[xedges, yedges])\n",
    "    # Denominador Reco\n",
    "    reco_fidH, _, _ = np.histogram2d(reco_fid_x, reco_fid_y, bins=[xedges, yedges])    \n",
    "    # Numerador Reco (CON PESOS APLICADOS)\n",
    "    recoH, _, _ = np.histogram2d(reco_x, reco_y, bins=[xedges, yedges], weights=weights_reco)\n",
    "\n",
    "    # ============================\n",
    "    # Acceptance\n",
    "    # ============================\n",
    "    mask_gen = gen_allH > min_gen\n",
    "    acc_gen = np.full_like(gen_allH, np.nan)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_gen[mask_gen] = gen_fidH[mask_gen] / gen_allH[mask_gen]\n",
    "\n",
    "    # ============================\n",
    "    # Reconstruction efficiency\n",
    "    # ============================\n",
    "    eff_reco = np.full_like(gen_allH, np.nan)\n",
    "    valid = mask_gen & (reco_fidH > 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        eff_reco[valid] = recoH[valid] / reco_fidH[valid]\n",
    "    \n",
    "    # ============================\n",
    "    # Bernstein fits\n",
    "    # ============================\n",
    "    # Nota: Los fits también deben saber que recoH ahora tiene pesos (float), no solo counts (int).\n",
    "    # Asegúrate de que fit_bernstein2d maneje arrays de floats en \"data_hist\" (recoH).\n",
    "    coef_acc, acc_gen_model = fit_bernstein2d( xcenters, ycenters, acc_gen, gen_allH, nx=nxg, ny=nyg, min_counts_mask=mask_gen, reg_lambda=reg_acc)\n",
    "    coef_reco, eff_reco_model = fit_bernstein2d(xcenters, ycenters, eff_reco, reco_fidH, nx=nxr, ny=nyr, min_counts_mask=valid, reg_lambda=reg_reco)\n",
    "\n",
    "    return (xcenters, ycenters, acc_gen, acc_gen_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen)\n",
    "\n",
    "\n",
    "def build_efficiency_1d(gen_all, gen_fid, reco_fid, reco, weights_reco=None, nbins=30, n_poly=4, min_gen=10, reg_acc=1e-6, reg_reco=1e-5):\n",
    "\n",
    "    limit_min, limit_max = -np.pi, np.pi\n",
    "    edges = np.linspace(limit_min, limit_max, nbins + 1)\n",
    "    centers = 0.5 * (edges[:-1] + edges[1:])\n",
    "    centers_norm = 2 * (centers - limit_min) / (limit_max - limit_min) - 1.0\n",
    "\n",
    "    # Pesos\n",
    "    if weights_reco is None:\n",
    "        weights_reco = np.ones(len(reco))\n",
    "    \n",
    "    # Histograms\n",
    "    gen_allH, _ = np.histogram(gen_all, bins=edges)\n",
    "    gen_fidH, _ = np.histogram(gen_fid, bins=edges)\n",
    "    reco_fidH, _ = np.histogram(reco_fid, bins=edges)\n",
    "    \n",
    "    # Numerador Reco CON PESOS\n",
    "    recoH, _ = np.histogram(reco, bins=edges, weights=weights_reco)\n",
    "\n",
    "    # Acceptance\n",
    "    mask_gen = gen_allH > min_gen\n",
    "    acc_gen = np.full_like(gen_allH, np.nan, dtype=float)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_gen[mask_gen] = gen_fidH[mask_gen] / gen_allH[mask_gen]\n",
    "    coef_acc, acc_model = fit_bernstein1d( centers_norm, acc_gen, gen_allH, n=n_poly, min_counts_mask=mask_gen, reg_lambda=reg_acc)\n",
    "    \n",
    "    # Efficiency reco\n",
    "    eff_reco = np.full_like(gen_allH, np.nan, dtype=float)\n",
    "    valid_reco = mask_gen & (reco_fidH > 0)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        eff_reco[valid_reco] = recoH[valid_reco] / reco_fidH[valid_reco]\n",
    "    coef_reco, eff_reco_model = fit_bernstein1d(centers_norm, eff_reco, reco_fidH, n=n_poly, min_counts_mask=valid_reco, reg_lambda=reg_reco)\n",
    "\n",
    "    return centers, acc_gen, acc_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen\n",
    "\n",
    "\n",
    "def bernstein2d_eval(x, y, model):\n",
    "    \"\"\"\n",
    "    Evaluate a fitted Bernstein2D model.\n",
    "    \"\"\"\n",
    "    nx = model[\"nx\"]\n",
    "    ny = model[\"ny\"]\n",
    "    coef = np.asarray(model[\"coef\"])\n",
    "    tx = 0.5 * (x + 1.0)\n",
    "    ty = 0.5 * (y + 1.0)\n",
    "    eff = np.zeros_like(tx, dtype=float)\n",
    "    idx = 0\n",
    "    for i in range(nx + 1):\n",
    "        Bx = bernstein_1d(nx, i, tx)\n",
    "        for j in range(ny + 1):\n",
    "            By = bernstein_1d(ny, j, ty)\n",
    "            eff += coef[idx] * Bx * By\n",
    "            idx += 1\n",
    "\n",
    "    return eff\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Save / Load Bernstein models\n",
    "# ======================================================\n",
    "def save_bernstein2d_model(filename, coef, nx, ny):\n",
    "    model = {\"nx\": nx, \"ny\": ny, \"coef\": coef.tolist(), \"x_range\": [-1.0, 1.0], \"y_range\": [-1.0, 1.0]}\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(model, f, indent=2)\n",
    "\n",
    "\n",
    "def load_bernstein_model(filename):\n",
    "    with open(filename) as f:\n",
    "        model = json.load(f)\n",
    "    return (np.asarray(model[\"coef\"], dtype=np.float64), model[\"nx\"], model[\"ny\"])\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "#   plots\n",
    "# ======================================================\n",
    "def project_with_errors_x(data2d, mask):\n",
    "    \"\"\"Project 2D efficiency to x with diagnostic errors.\"\"\"\n",
    "    proj = []\n",
    "    err = []\n",
    "    for i in range(data2d.shape[0]):   # x bins\n",
    "        vals = data2d[i, :][mask[i, :]]\n",
    "        if len(vals) == 0:\n",
    "            proj.append(np.nan)\n",
    "            err.append(np.nan)\n",
    "        else:\n",
    "            proj.append(np.mean(vals))\n",
    "            err.append(np.std(vals, ddof=0) / np.sqrt(len(vals)))\n",
    "    return np.array(proj), np.array(err)\n",
    "\n",
    "\n",
    "def project_with_errors_y(data2d, mask):\n",
    "    \"\"\"Project 2D efficiency to y with diagnostic errors.\"\"\"\n",
    "    proj = []\n",
    "    err = []\n",
    "    for j in range(data2d.shape[1]):   # y bins\n",
    "        vals = data2d[:, j][mask[:, j]]\n",
    "        if len(vals) == 0:\n",
    "            proj.append(np.nan)\n",
    "            err.append(np.nan)\n",
    "        else:\n",
    "            proj.append(np.mean(vals))\n",
    "            err.append(np.std(vals, ddof=0) / np.sqrt(len(vals)))\n",
    "    return np.array(proj), np.array(err)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# CMS Style Plotting\n",
    "# ======================================================\n",
    "def _plot_cms_style(centers, data, data_err, model, xlabel, title, y_label=\"Efficiency\", ylim=None, path_dir=\"plots\"):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[3.5, 1.5], hspace=0.05)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "\n",
    "    # --- AUTO-SCALING LOGIC ---\n",
    "    if ylim is None:\n",
    "        # Calculamos el punto más alto considerando el error superior\n",
    "        # Usamos nanmax para ignorar posibles NaNs\n",
    "        max_data = np.nanmax(data + data_err) if data_err is not None else np.nanmax(data)\n",
    "        max_model = np.nanmax(model)\n",
    "        global_max = max(max_data, max_model)\n",
    "        \n",
    "        # Si por alguna razón todo es 0 o NaN, ponemos un default\n",
    "        if np.isnan(global_max) or global_max <= 0:\n",
    "            global_max = 1.0\n",
    "            \n",
    "        # Definimos el límite: 0 abajo, y Max + 30% arriba para la leyenda/CMS label\n",
    "        current_ylim = (0.0, global_max * 1.30)\n",
    "    else:\n",
    "        current_ylim = ylim\n",
    "    # --------------------------\n",
    "\n",
    "    # Plot principal\n",
    "    ax0.plot(centers, model, '-', color='blue', linewidth=2.5, label=\"Bernstein Model\")\n",
    "    ax0.errorbar(centers, data, yerr=data_err, fmt='ks', markersize=5, elinewidth=1.5, capsize=2, label=\"Binned MC\")\n",
    "    ax0.set_ylabel(y_label, fontsize=16)\n",
    "    ax0.set_title(title, loc='center', fontsize=14, fontweight='medium', y=1.05)\n",
    "    \n",
    "    # Aplicamos el límite calculado o el manual\n",
    "    ax0.set_ylim(current_ylim)\n",
    "\n",
    "    hep.cms.label(data=False, loc=0, ax=ax0, rlabel=\"13 TeV\", fontname=\"sans-serif\", fontsize=16)\n",
    "    ax0.legend(frameon=False, fontsize=13, loc='upper right')\n",
    "    ax0.grid(True, alpha=0.3)\n",
    "    plt.setp(ax0.get_xticklabels(), visible=False)\n",
    "\n",
    "    # Pulls (El resto sigue igual)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        pulls = (data - model) / data_err\n",
    "    pulls[~np.isfinite(pulls)] = 0.0 \n",
    "\n",
    "    width = centers[1] - centers[0]\n",
    "    lower = centers[0] - width/2\n",
    "    upper = centers[-1] + width/2\n",
    "\n",
    "    ax1.errorbar(centers, pulls, yerr=1.0, xerr=0, fmt='ks',markersize=4, elinewidth=1.0,capsize=0)          \n",
    "    ax1.axhline(0, color='black', linewidth=1.0, linestyle='-')\n",
    "    ax1.axhline(3, color='gray', linestyle=':', linewidth=1, alpha=0.8) \n",
    "    ax1.axhline(-3, color='gray', linestyle=':', linewidth=1, alpha=0.8)    \n",
    "    ax1.fill_between([lower, upper], -3, 3, color='gray', alpha=0.15, label=r'$3\\sigma$') \n",
    "    ax1.set_xlabel(xlabel, fontsize=16)\n",
    "    ax1.set_ylabel(r'Pull $(\\sigma)$', fontsize=13)\n",
    "    ax1.set_xlim(lower, upper)\n",
    "    ax1.set_ylim(-4.9, 4.9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=14, direction='in', top=True, right=True) \n",
    "    ax1.tick_params(axis='both', which='major', labelsize=14, direction='in', top=True, right=True)\n",
    "    \n",
    "    # Guardado seguro\n",
    "    save_path = os.path.join(path_dir, f\"{title}.png\")\n",
    "    directory = os.path.dirname(save_path)\n",
    "    if directory:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Public Functions (Wrappers)\n",
    "# ======================================================\n",
    "def plot_projection_x_with_errors(xc, data2d, model2d, mask, title, ylim=None, path=None):\n",
    "    \"\"\"\n",
    "    Proyección en X (cosThetaL)\n",
    "    \"\"\"\n",
    "\n",
    "    data_proj, data_err = project_with_errors_x(data2d, mask)\n",
    "    model_proj, _ = project_with_errors_x(model2d, mask)\n",
    "    if np.nanmean(model_proj) != 0:\n",
    "        scale = np.nanmean(data_proj) / np.nanmean(model_proj)\n",
    "    else:\n",
    "        scale = 1.0\n",
    "    model_proj_scaled = model_proj * scale\n",
    "    _plot_cms_style(centers=xc, data=data_proj, data_err=data_err, model=model_proj_scaled, xlabel=r\"$\\cos\\theta_\\ell$\", title=title, ylim=ylim, path_dir=path)\n",
    "\n",
    "\n",
    "def plot_projection_y_with_errors(yc, data2d, model2d, mask, title, ylim, path):\n",
    "    \"\"\"\n",
    "    Proyección en Y (cosThetaK)\n",
    "    \"\"\"\n",
    "    data_proj, data_err = project_with_errors_y(data2d, mask)\n",
    "    model_proj, _ = project_with_errors_y(model2d, mask)\n",
    "    \n",
    "    if np.nanmean(model_proj) != 0:\n",
    "        scale = np.nanmean(data_proj) / np.nanmean(model_proj)\n",
    "    else:\n",
    "        scale = 1.0\n",
    "    model_proj_scaled = model_proj * scale\n",
    "\n",
    "    _plot_cms_style(centers=yc, data=data_proj, data_err=data_err, model=model_proj_scaled, xlabel=r\"$\\cos\\theta_K$\", title=title, ylim=ylim, path_dir=path) \n",
    "\n",
    "\n",
    "def select_q2_bin(df, n_bin, cut):\n",
    "    q2_bins = dict()\n",
    "    q2_bins = { \"bin0\":[1.1,23.0],   \"bin1\":[1.1, 2.0],\"bin2\": [2.0, 4.0],\"bin3\":[4.0, 6.0],\n",
    "                \"bin4\":[6.0, 7.0],   \"bin5\":[7.0, 8.0], \"bin6\": [8.0, 11.0],\"bin7\":[11.0, 12.5],\n",
    "                \"bin8\":[12.5, 15.0], \"bin9\":[15.0, 17.0], \"bin10\":[17.0, 23.0]}\n",
    "    df_ = df[(df[cut]>=q2_bins[n_bin][0]) & (df[cut] <= q2_bins[n_bin][1])].copy()\n",
    "    return df_\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# PHI  1D Bernstei\n",
    "# ======================================================\n",
    "\n",
    "def save_bernstein1d_model(filename, coef, n):\n",
    "    directory = os.path.dirname(filename)\n",
    "    if directory:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    model = {\"n\": n, \"coef\": coef.tolist(), \"range\": [-np.pi, np.pi]}\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(model, f, indent=2)\n",
    "\n",
    "def bernstein1d_matrix(n, x):\n",
    "    \"\"\"\n",
    "    Build the design matrix for Bernstein 1D basis.\n",
    "    Input: x in [-1, 1] (array)\n",
    "    Output: B matrix of size (Npoints, n+1)\n",
    "    \"\"\"\n",
    "    # map [-1,1] -> [0,1]\n",
    "    t = 0.5 * (x + 1.0)\n",
    "    B_list = []\n",
    "    for i in range(n+1):\n",
    "        B_list.append(bernstein_1d(n, i, t))\n",
    "    B = np.vstack(B_list).T\n",
    "\n",
    "    return B\n",
    "\n",
    "\n",
    "def fit_bernstein1d(xcenters, eff1d, ngen1d, n=4, min_counts_mask=None, reg_lambda=1e-10):\n",
    "    \"\"\"\n",
    "    Fits a Bernstein 1D polynomial to a 1D efficiency histogram.\n",
    "    \"\"\"\n",
    "    # Filter NaNs and Zero Gen\n",
    "    if min_counts_mask is None:\n",
    "        use = (~np.isnan(eff1d)) & (ngen1d > 0)\n",
    "    else:\n",
    "        use = min_counts_mask & ~np.isnan(eff1d) & (ngen1d > 0)\n",
    "        \n",
    "    x_use = xcenters[use]\n",
    "    eff_use = eff1d[use]\n",
    "    ngen_use = ngen1d[use]\n",
    "    # Binomial uncertainty weights\n",
    "    sigma2 = eff_use * (1.0 - eff_use) / ngen_use\n",
    "    sigma2 = np.clip(sigma2, 1e-12, None)\n",
    "    w = 1.0 / np.sqrt(sigma2)\n",
    "    \n",
    "    B = bernstein1d_matrix(n, x_use)\n",
    "    Bw = B * w[:, None]\n",
    "    yw = eff_use * w\n",
    "    BTB = Bw.T @ Bw + reg_lambda * np.eye(B.shape[1])\n",
    "    BTy = Bw.T @ yw\n",
    "    coef = np.linalg.solve(BTB, BTy)\n",
    "    Bfull = bernstein1d_matrix(n, xcenters)\n",
    "    eff_model = Bfull @ coef\n",
    "    \n",
    "    return coef, eff_model\n",
    "\n",
    "def load_bernstein1d_model(filename):\n",
    "    \"\"\"Carga un modelo de Bernstein 1D desde un JSON.\"\"\"\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    coef = np.asarray(data[\"coef\"], dtype=np.float64)\n",
    "    if \"degree\" in data:\n",
    "        degree = data[\"degree\"]\n",
    "    else:\n",
    "        degree = len(coef) - 1\n",
    "        \n",
    "    return coef, degree\n",
    "\n",
    "\n",
    "def plot_1d_result(centers, data, model, mask, title, ylim, path):\n",
    "    valid = mask\n",
    "    dummy_err = np.zeros_like(data)\n",
    "    dummy_err[valid] = 0.05 * data[valid]     \n",
    "    _plot_cms_style(centers[valid], data[valid], dummy_err[valid], model[valid], xlabel=r\"$\\phi$\", title=title,ylim=ylim, path_dir=path)\n",
    "\n",
    "\n",
    "def run_fit(model, data):\n",
    "    nll = zfit.loss.UnbinnedNLL(model=model, data=data)\n",
    "    minimizer = zfit.minimize.Minuit()\n",
    "    result = minimizer.minimize(nll)\n",
    "    err = None\n",
    "    try:\n",
    "        err, _ = result.errors(name=\"minos\", method=\"minuit_minos\", cl=0.682)\n",
    "    except Exception as e:\n",
    "        print(\"MINOS failed:\", e)\n",
    "    return result, err\n",
    "\n",
    "# =====================================================\n",
    "# CODE FOR FIT INCLUDING EFFICIENCY\n",
    "# =====================================================\n",
    "\n",
    "def tf_bernstein_basis_vectorized(n, t):\n",
    "    M = tf.shape(t)[0]\n",
    "    k = tf.range(n + 1, dtype=tf.float64)\n",
    "    n_float = tf.cast(n, tf.float64)\n",
    "    log_binom = tf.math.lgamma(n_float + 1.0) - tf.math.lgamma(k + 1.0) - tf.math.lgamma(n_float - k + 1.0)\n",
    "    binom = tf.exp(log_binom)\n",
    "    t_col = tf.expand_dims(t, -1) \n",
    "    k_row = tf.expand_dims(k, 0)\n",
    "    term1 = tf.pow(t_col, k_row)\n",
    "    term2 = tf.pow(1.0 - t_col, n_float - k_row)\n",
    "    basis = binom * term1 * term2 \n",
    "    return basis\n",
    "\n",
    "\n",
    "class Efficiency_Bernstein_Factorized(zfit.pdf.BasePDF):\n",
    "    def __init__(self, obs,coef_acc_2d, coef_acc_phi, nx_acc, ny_acc, n_phi_acc, coef_reco_2d, coef_reco_phi, nx_reco, ny_reco, n_phi_reco,\n",
    "                 name=\"Full_Efficiency_Model\"):\n",
    "        \"\"\"\n",
    "        Modelo Completo: Aceptancia * Eficiencia de Reconstrucción.\n",
    "        Cada parte factorizada en 2D(cosL, cosK) * 1D(phi).\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            'c_acc_2d': zfit.Parameter(f\"c_a2d_{name}\", tf.cast(coef_acc_2d, tf.float64), floating=False),\n",
    "            'c_acc_phi': zfit.Parameter(f\"c_aphi_{name}\", tf.cast(coef_acc_phi, tf.float64), floating=False),\n",
    "            'c_reco_2d': zfit.Parameter(f\"c_r2d_{name}\", tf.cast(coef_reco_2d, tf.float64), floating=False),\n",
    "            'c_reco_phi': zfit.Parameter(f\"c_rphi_{name}\", tf.cast(coef_reco_phi, tf.float64), floating=False),\n",
    "        }\n",
    "        \n",
    "        # Guardamos los grados de los polinomios\n",
    "        self.nx_acc, self.ny_acc = nx_acc, ny_acc\n",
    "        self.n_phi_acc = n_phi_acc\n",
    "        self.nx_reco, self.ny_reco = nx_reco, ny_reco\n",
    "        self.n_phi_reco = n_phi_reco\n",
    "        \n",
    "        super().__init__(obs, params, name=name)\n",
    "\n",
    "    def _unnormalized_pdf(self, x):\n",
    "        vars_list = z.unstack_x(x)\n",
    "        cos_l, cos_k, phi = vars_list[0], vars_list[1], vars_list[2]\n",
    "\n",
    "        # [-1, 1] -> [0, 1] y [-pi, pi] -> [0, 1]\n",
    "        tx = 0.5 * (cos_l + 1.0)\n",
    "        ty = 0.5 * (cos_k + 1.0)\n",
    "        t_phi = (phi + np.pi) / (2.0 * np.pi)\n",
    "        # ======================================================\n",
    "        # ACEPTANCIA\n",
    "        # ======================================================\n",
    "        # Bases\n",
    "        Bx_acc = tf_bernstein_basis_vectorized(self.nx_acc, tx)\n",
    "        By_acc = tf_bernstein_basis_vectorized(self.ny_acc, ty)\n",
    "        Bphi_acc = tf_bernstein_basis_vectorized(self.n_phi_acc, t_phi)\n",
    "        \n",
    "        # 2D part\n",
    "        c_acc_2d_mat = tf.reshape(self.params['c_acc_2d'], (self.nx_acc + 1, self.ny_acc + 1))\n",
    "        acc_2d = tf.einsum('mi,mj,ij->m', Bx_acc, By_acc, c_acc_2d_mat)\n",
    "        # 1D part\n",
    "        acc_phi = tf.einsum('mk,k->m', Bphi_acc, self.params['c_acc_phi'])\n",
    "        # Total Acceptance\n",
    "        total_acc = acc_2d * acc_phi\n",
    "\n",
    "        # ======================================================\n",
    "        # EFICIENCIA DE RECONSTRUCCIÓN\n",
    "        # ======================================================\n",
    "        # Bases\n",
    "        Bx_reco = tf_bernstein_basis_vectorized(self.nx_reco, tx)\n",
    "        By_reco = tf_bernstein_basis_vectorized(self.ny_reco, ty)\n",
    "        Bphi_reco = tf_bernstein_basis_vectorized(self.n_phi_reco, t_phi)\n",
    "        \n",
    "        # 2D part\n",
    "        c_reco_2d_mat = tf.reshape(self.params['c_reco_2d'], (self.nx_reco + 1, self.ny_reco + 1))\n",
    "        reco_2d = tf.einsum('mi,mj,ij->m', Bx_reco, By_reco, c_reco_2d_mat)\n",
    "        # 1D part\n",
    "        reco_phi = tf.einsum('mk,k->m', Bphi_reco, self.params['c_reco_phi'])\n",
    "        # Total Reco Efficiency\n",
    "        total_reco = reco_2d * reco_phi\n",
    "\n",
    "        # ======================================================\n",
    "        # EFICIENCIA FINAL\n",
    "        # ======================================================\n",
    "        return tf.maximum(total_acc * total_reco, 1e-15)\n",
    "\n",
    "\n",
    "def save_fit_results(result, bin_n, base_dir=\"fit_results\", name=\"fit_results\"):\n",
    "    \"\"\"\n",
    "    Guarda resultados buscando errores con nombres personalizados ('minos') \n",
    "    o por defecto ('minuit_minos', 'minuit_hesse').\n",
    "    \"\"\"\n",
    "    \n",
    "    output_folder = os.path.join(base_dir, f\"{bin_n}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_file = os.path.join(output_folder, f\"{name}.json\")\n",
    "    \n",
    "    params_dict = {}\n",
    "    \n",
    "    for p in result.params:\n",
    "        val = result.params[p]['value']\n",
    "        p_data = result.params[p] \n",
    "\n",
    "        lower_err = 0.0\n",
    "        upper_err = 0.0\n",
    "        sym_err = 0.0\n",
    "        error_type = \"none\"\n",
    "\n",
    "        # busca minos\n",
    "        if 'minos' in p_data:\n",
    "            err_data = p_data['minos']\n",
    "            lower_err = err_data.get('lower', 0.0)\n",
    "            upper_err = err_data.get('upper', 0.0)\n",
    "            sym_err = (abs(lower_err) + abs(upper_err)) / 2.0\n",
    "            error_type = \"minos (custom)\"\n",
    "\n",
    "        # busca minuit_minos\n",
    "        elif 'minuit_minos' in p_data:\n",
    "            err_data = p_data['minuit_minos']\n",
    "            lower_err = err_data.get('lower', 0.0)\n",
    "            upper_err = err_data.get('upper', 0.0)\n",
    "            sym_err = (abs(lower_err) + abs(upper_err)) / 2.0\n",
    "            error_type = \"minos (default)\"\n",
    "            \n",
    "        # busca Hesse\n",
    "        elif 'minuit_hesse' in p_data:\n",
    "            err_data = p_data['minuit_hesse']\n",
    "            sym_err = err_data.get('error', -999.0)\n",
    "            lower_err = -sym_err\n",
    "            upper_err = sym_err\n",
    "            error_type = \"hesse\"\n",
    "            \n",
    "\n",
    "        params_dict[p.name] = {'value': float(val), 'error': float(sym_err), 'error_low': float(lower_err), 'error_up': float(upper_err), 'error_source': error_type}\n",
    "\n",
    "\n",
    "    cov_matrix = result.covariance()\n",
    "    cov_list = np.array(cov_matrix).tolist()\n",
    "    data_to_save = {'bin_index': str(bin_n), 'valid': bool(result.valid), 'converged': bool(result.converged), 'fmin': float(result.fmin), 'status': result.status,'parameters': params_dict,'covariance': cov_list}\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(data_to_save, f, indent=4)\n",
    "        \n",
    "    print(f\"[CheckPoint] Resultados guardados en: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "def save_correlation_matrix(result, params_list, bin_name, out_dir=\"plots/correlations\"):\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)    \n",
    "    corr_matrix_raw = result.correlation()    \n",
    "    zfit_params = list(result.params.keys())\n",
    "    n_params = len(params_list)\n",
    "    corr_matrix = np.zeros((n_params, n_params))    \n",
    "    param_names = [p.name.split('_')[0] for p in params_list]    \n",
    "    for i, p1 in enumerate(params_list):\n",
    "        for j, p2 in enumerate(params_list):\n",
    "            idx1 = zfit_params.index(p1)\n",
    "            idx2 = zfit_params.index(p2)\n",
    "            corr_matrix[i, j] = corr_matrix_raw[idx1, idx2]\n",
    "                \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, xticklabels=param_names, yticklabels=param_names, fmt=\".2f\", square=True, cbar_kws={\"shrink\": .8})\n",
    "    plt.title(f\"Matriz de Correlación - {bin_name}\", fontsize=14, pad=15)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    filepath = os.path.join(out_dir, f\"corr_matrix_{bin_name}.png\")\n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.close() \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7c110",
   "metadata": {},
   "source": [
    "#  CODE FOR EFFICIENCY CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc58f68-dfcf-40d7-b335-25f997c73149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERA=\"2022\"\n",
    "# YEAR='20'+ ERA.split(\"20\")[1]\n",
    "# path = f'/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/Bstomumuphi_{YEAR}/'\n",
    "# qsBinning=[]\n",
    "# #if args.decay == 'nonResonant':\n",
    "# qsBinning = [\"bin\"+str(i+1) for i in range(8)]\n",
    "# qsBinning.remove(\"bin4\")\n",
    "# qsBinning.remove(\"bin6\")\n",
    "# #elif args.decay == 'ResonantJpsi':\n",
    "# #    qsBinning = [\"bin4\"]\n",
    "# #elif args.decay == 'ResonantPsi':\n",
    "# #    qsBinning = [\"bin6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de5be7e-66b2-4c69-96bf-001757dd1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Gen Non-Filtered (genNFtr) cargado: 11589148 eventos\n",
      "2. Gen Filtered (genFtr) cargado: 307688 eventos\n",
      "3. Reco Gen Level Denom (recoGen) cargado: 6298017 eventos\n",
      "4. Reco Final (recoFtr) cargado: 900424 eventos\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "# --- RUTAS DE ARCHIVOS ---\n",
    "f_gen = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/datasets/GenLevel_Angular_Merged.root\"\n",
    "f_gen_filtered = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/datasets/GenLevel_Angular_Merged_Filtered.root\"\n",
    "f_reco_gen = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/angular/efficiencies/datasets/RecoGenV2_Angular_Merged.root\"  \n",
    "x_gboost_cut = \"/home/ghcp/Documentos/CINVESTAV/ANALISYS_B0tomumuKstar/BdtoK0smumu-20251110T171511Z-1-001/MyReweiting/ResultsB0_2022/AntiRadVeto_MC_NoRes_2022_Era1_v0_XGBoost_fom_cut_BDT.root\"\n",
    "\n",
    "vars_gen_to_load = [\"gen_cosThetaK\", \"gen_cosThetaL\", \"gen_phi\", \"q2Gen\"]\n",
    "vars_reco_to_load = [\"CosThetaK_best\", \"CosThetaL_best\", \"Phi_best\", \"massJ\"] \n",
    "vars_xgboost_to_load = [\"CosThetaK\", \"CosThetaL\", \"Phi\", \"massB_test\", \"massJ\", \"TotalWeight\"] \n",
    "\n",
    "# --- CARGA DE DATOS ---\n",
    "#Gen NO filt\n",
    "genNFtr = uproot.open(f_gen)['ntuple'].arrays(vars_gen_to_load, library='pd')\n",
    "print(f\"1. Gen Non-Filtered (genNFtr) cargado: {len(genNFtr)} eventos\")\n",
    "# Gen Filtered\n",
    "genFtr = uproot.open(f_gen_filtered)['ntuple'].arrays(vars_gen_to_load, library='pd')\n",
    "print(f\"2. Gen Filtered (genFtr) cargado: {len(genFtr)} eventos\")\n",
    "# Reco Gen Level\n",
    "recoGen = uproot.open(f_reco_gen)['ntuple'].arrays(vars_reco_to_load, library='pd')\n",
    "print(f\"3. Reco Gen Level Denom (recoGen) cargado: {len(recoGen)} eventos\")\n",
    "# Final selection \n",
    "recoFtr = uproot.open(x_gboost_cut)['treeBd'].arrays(vars_xgboost_to_load, library='pd')\n",
    "print(f\"4. Reco Final (recoFtr) cargado: {len(recoFtr)} eventos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d00903e-cd4f-4c1d-a550-cbf0868ee246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recoFtr[\"q2\"] = recoFtr[\"massJ\"]**2 \n",
    "recoGen[\"q2Gen\"] = recoGen[\"massJ\"]**2  \n",
    "\n",
    "GenNFlt = genNFtr.copy()     \n",
    "GenFlt  = genFtr.copy()       \n",
    "\n",
    "RecoGenFlt = recoGen.copy()             \n",
    "mask_mass = (recoFtr[\"massB_test\"] > 5.0) & (recoFtr[\"massB_test\"] < 5.6)\n",
    "Reco = recoFtr[mask_mass].copy()\n",
    "#2\n",
    "eff_Gen, obs_Gen = train_test_split(GenNFlt, test_size=0.005, random_state=2)\n",
    "eff_GenFtr, obs_GenFtr = train_test_split(GenFlt, test_size=0.1, random_state=2)\n",
    "eff_RecoGenFtr, obs_RecoGenFtr = train_test_split(RecoGenFlt, test_size=0.3, random_state=2)\n",
    "eff_RecoFtr, obs_RecoFtr = train_test_split(Reco, test_size=0.1, random_state=2)\n",
    "\n",
    "a1 = np.array(obs_Gen[\"gen_cosThetaL\"])\n",
    "a2 = np.array(obs_Gen[\"gen_cosThetaK\"])\n",
    "a3 = np.array(obs_Gen[\"gen_phi\"])\n",
    "\n",
    "angles = np.array([a1, a2, a3])\n",
    "valid_observations_mask = ~np.isnan(angles).any(axis=0)\n",
    "filtered_data = angles[:, valid_observations_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd412c8-edfc-4a8e-93cb-e624871977c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# corr_matrix = np.corrcoef(filtered_data)\n",
    "# print(\"Matriz de correlación (Gen Level):\")\n",
    "# print(f\"{'':>15} {'cos(theta_L)':>12} {'cos(theta_K)':>12} {'phi':>12}\")\n",
    "# print(f\"{'cos(theta_L)':>15} {corr_matrix[0,0]:12.4f} {corr_matrix[0,1]:12.4f} {corr_matrix[0,2]:12.4f}\")\n",
    "# print(f\"{'cos(theta_K)':>15} {corr_matrix[1,0]:12.4f} {corr_matrix[1,1]:12.4f} {corr_matrix[1,2]:12.4f}\")\n",
    "# print(f\"{'phi':>15}          {corr_matrix[2,0]:12.4f} {corr_matrix[2,1]:12.4f} {corr_matrix[2,2]:12.4f}\")\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set(style=\"whitegrid\")\n",
    "# plt.figure(figsize=(8, 6)) \n",
    "# labels = [r\"$\\cos(\\theta_{\\ell})$\", r\"$\\cos(\\theta_K)$\", r\"$\\phi$\"]\n",
    "\n",
    "# sns.heatmap(corr_matrix, annot=True, fmt=\".5f\", cmap=\"coolwarm\", vmin=-1, vmax=1, xticklabels=labels, yticklabels=labels)\n",
    "# plt.title(f\"Correlation Matrix - Gen Level (2022)\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712e529-e4f1-44bc-ad17-aeba5333b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbx=20\n",
    "nby=20\n",
    "nx_gen=4 \n",
    "ny_gen=4 \n",
    "nx_rec=4 \n",
    "ny_rec=4\n",
    "ylim_ck_a=(0.0, 0.040)\n",
    "ylim_cl_a=(0.0, 0.040)\n",
    "ylim_ck_r=(0.0, 0.30)\n",
    "ylim_cl_r=(0.2, 0.450)\n",
    "ylim_ck_t=(0.0, 0.008)\n",
    "ylim_cl_t=(0.0, 0.008)\n",
    "ylim_p_a=(0.0, 0.06)\n",
    "ylim_p_r=(0.0, 0.25)\n",
    "ylim_p_t=(0.0, 0.006)\n",
    "\n",
    "bin_configs = {\n",
    "    \"bin1\":  {\"q2_range\": [1.1, 2.0],   \"nbx\": 12, \"nby\": 12, \"nx_gen\": 5, \"ny_gen\": 5, \"nx_rec\": 5, \"ny_rec\": 5},\n",
    "    \"bin2\":  {\"q2_range\": [2.0, 4.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin3\":  {\"q2_range\": [4.0, 6.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin4\":  {\"q2_range\": [6.0, 7.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin5\":  {\"q2_range\": [7.0, 8.0],   \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin7\":  {\"q2_range\": [11.0, 12.5], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin9\":  {\"q2_range\": [15.0, 17.0], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec},\n",
    "    \"bin10\": {\"q2_range\": [17.0, 23.0], \"nbx\": nbx, \"nby\": nby, \"nx_gen\": nx_gen, \"ny_gen\": ny_gen, \"nx_rec\": nx_rec, \"ny_rec\": ny_rec}\n",
    "}\n",
    "\n",
    "\n",
    "for binN, config in bin_configs.items():\n",
    "    print(f\"\\n=== Procesando {binN} ===\")\n",
    "    nbx=config[\"nbx\"]\n",
    "    nby=config[\"nby\"]\n",
    "    nx_gen=config[\"nx_gen\"]\n",
    "    ny_gen=config[\"ny_gen\"]\n",
    "    nx_rec=config[\"nx_rec\"]\n",
    "    ny_rec=config[\"ny_rec\"]\n",
    "\n",
    "    eff_Gen_q2 =        select_q2_bin(eff_Gen, binN, \"q2Gen\")\n",
    "    eff_GenFtr_q2 =     select_q2_bin(eff_GenFtr, binN, \"q2Gen\")\n",
    "    eff_RecoGenFtr_q2 = select_q2_bin(eff_RecoGenFtr, binN, \"q2Gen\")\n",
    "    eff_RecoFtr_q2 =    select_q2_bin(eff_RecoFtr, binN, \"q2\") \n",
    "\n",
    "    gen_x = eff_Gen_q2[\"gen_cosThetaL\"].values  \n",
    "    gen_y = eff_Gen_q2[\"gen_cosThetaK\"].values      \n",
    "    genFid_x = eff_GenFtr_q2[\"gen_cosThetaL\"].values \n",
    "    genFid_y = eff_GenFtr_q2[\"gen_cosThetaK\"].values\n",
    "    recoFid_x = eff_RecoGenFtr_q2[\"CosThetaL_best\"].values \n",
    "    recoFid_y = eff_RecoGenFtr_q2[\"CosThetaK_best\"].values\n",
    "    reco_x = eff_RecoFtr_q2[\"CosThetaL\"].values\n",
    "    reco_y = eff_RecoFtr_q2[\"CosThetaK\"].values\n",
    "    reco_w = eff_RecoFtr_q2[\"TotalWeight\"].values  \n",
    "\n",
    "    xcenters, ycenters, acc_gen, acc_gen_model, coef_acc, eff_reco, eff_reco_model, coef_reco, mask_gen = build_efficiency_2d( \n",
    "        gen_x, gen_y, genFid_x, genFid_y, recoFid_x, recoFid_y, reco_x, reco_y, weights_reco=reco_w, nbx=nbx, nby=nby, \n",
    "        nxg=nx_gen, nyg=ny_gen, nxr=nx_rec, nyr=ny_rec, min_gen=10, reg_acc=1e-5, reg_reco=1e-5 )\n",
    "\n",
    "    # ======================================================\n",
    "    # phi \n",
    "    # ======================================================\n",
    "    phi_gen_all = eff_Gen_q2[\"gen_phi\"].values\n",
    "    phi_gen_fid = eff_GenFtr_q2[\"gen_phi\"].values\n",
    "    phi_reco_fid = eff_RecoGenFtr_q2[\"Phi_best\"].values\n",
    "    phi_reco = eff_RecoFtr_q2[\"Phi\"].values\n",
    "    \n",
    "    centers_phi, acc_phi, acc_phi_model, coef_acc_phi, eff_reco_phi, eff_reco_phi_model, coef_reco_phi, mask_phi = build_efficiency_1d( \n",
    "        phi_gen_all, phi_gen_fid, phi_reco_fid, phi_reco, \n",
    "        weights_reco=reco_w,nbins=20, n_poly=4, reg_acc=1e-5, reg_reco=1e-5)\n",
    "\n",
    "    plt.ioff()\n",
    "    acc_model_file = f\"acc_gen_model_{binN}.json\"\n",
    "    reco_model_file = f\"eff_reco_model_{binN}.json\"\n",
    "    path_models = f\"models/{binN}/\"\n",
    "    path_plots = f\"plots/projections/{binN}/\"\n",
    "\n",
    "    save_bernstein2d_model(path_models + reco_model_file, coef_reco, nx_rec, ny_rec)\n",
    "    save_bernstein2d_model(path_models + acc_model_file, coef_acc, nx_gen, ny_gen)\n",
    "    save_bernstein1d_model(f\"models/{binN}/acc_gen_model_phi_{binN}.json\", coef_acc_phi, 4)\n",
    "    save_bernstein1d_model(f\"models/{binN}/eff_reco_model_phi_{binN}.json\", coef_reco_phi, 4)\n",
    "    \n",
    "    # ======================================================\n",
    "    # PLOTs\n",
    "    # ======================================================\n",
    "\n",
    "    plot_projection_x_with_errors(xcenters, acc_gen, acc_gen_model, mask_gen, f\"{binN} \"+r\"Gen Acceptance: $\\cos\\theta_\\ell$\", ylim=None, path=path_plots)\n",
    "    plot_projection_y_with_errors( ycenters, acc_gen, acc_gen_model, mask_gen,  f\"{binN} \"+r\"Gen Acceptance: $\\cos\\theta_K$\",  ylim=None, path=path_plots)\n",
    "    \n",
    "    plot_projection_x_with_errors(xcenters, eff_reco, eff_reco_model, mask_gen, f\"{binN} \"+r\"Reco Efficiency: $\\cos\\theta_\\ell$\", ylim=None, path=path_plots)\n",
    "    plot_projection_y_with_errors(ycenters, eff_reco, eff_reco_model, mask_gen, f\"{binN} \"+r\"Reco Efficiency: $\\cos\\theta_K$\", ylim=None, path=path_plots)\n",
    "    \n",
    "    plot_projection_x_with_errors( xcenters, acc_gen*eff_reco, acc_gen_model*eff_reco_model, mask_gen, f\"{binN} \"+r\"Total efficiency: projection cos$\\theta_\\ell$\",ylim=None,path=path_plots)\n",
    "    plot_projection_y_with_errors( xcenters, acc_gen*eff_reco, acc_gen_model*eff_reco_model, mask_gen, f\"{binN} \"+r\"Total efficiency: projection cos$\\theta_K$\",ylim=None, path=path_plots)\n",
    "\n",
    "    # Phi\n",
    "    plot_1d_result(centers_phi, acc_phi, acc_phi_model, mask_phi, f\"{binN} \"+r\"Gen Acceptance $\\phi$\",ylim=None,path=path_plots)\n",
    "    plot_1d_result(centers_phi, eff_reco_phi, eff_reco_phi_model, mask_phi, f\"{binN} \"+r\"Reco Efficiency $\\phi$\",ylim=None,path=path_plots)\n",
    "    plot_1d_result(centers_phi, acc_phi*eff_reco_phi, acc_phi_model*eff_reco_phi_model, mask_phi, f\"{binN} \"+r\"Total efficiency $\\phi$\",ylim=None,path=path_plots)\n",
    "    plt.ion()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153583ea-b8a9-44d7-b739-f6bf5ec5c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,5))\n",
    "# plt.scatter(eff_reco[mask_gen], eff_reco_model[mask_gen], s=8, alpha=0.4)\n",
    "# plt.plot([0,0.2], [0,0.2], \"r--\")\n",
    "# plt.xlabel(\"Binned efficiency\")\n",
    "# plt.ylabel(\"Bernstein model\")\n",
    "# plt.grid(True)\n",
    "# plt.title(\"Bin-by-bin comparison\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ded7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094c999d",
   "metadata": {},
   "source": [
    "# Gen Fit Physical space SLSQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9f842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc5f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007358be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aefd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a0df61",
   "metadata": {},
   "source": [
    "# Gen Fit Physical space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4497db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Procesando bin1 con rango q2: [1.1, 2.0]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-21 11:39:16.859156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.425237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.426162: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.427869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.428686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.429445: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.501739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.502658: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.503478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2026-02-21 11:39:17.504232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4130 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name        value  (rounded)                minos    at limit\n",
      "--------  ------------------  -------------------  ----------\n",
      "FL_bin1              0.65282  -  0.016   +  0.015       False\n",
      "S3_bin1          0.000734259  -  0.021   +  0.021       False\n",
      "S9_bin1          -0.00751069  -  0.021   +   0.02       False\n",
      "AFB_bin1           0.0192128  -  0.015   +  0.015       False\n",
      "S4_bin1            0.0194374  -  0.026   +  0.026       False\n",
      "S7_bin1           -0.0209414  -  0.024   +  0.025       False\n",
      "S5_bin1           -0.0249206  -  0.025   +  0.025       False\n",
      "S8_bin1            0.0203171  -  0.025   +  0.025       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin1/fit_results_gen_physical_bin1.json\n",
      "\n",
      "============================================================\n",
      "Procesando bin2 con rango q2: [2.0, 4.0]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n",
      "name        value  (rounded)                minos    at limit\n",
      "--------  ------------------  -------------------  ----------\n",
      "FL_bin2             0.780553  - 0.0099   + 0.0098       False\n",
      "S3_bin2           -0.0154625  -  0.013   +  0.013       False\n",
      "S9_bin2           0.00473773  -  0.013   +  0.013       False\n",
      "AFB_bin2          -0.0104995  - 0.0087   + 0.0087       False\n",
      "S4_bin2            -0.121701  -  0.016   +  0.017       False\n",
      "S7_bin2            0.0125962  -  0.017   +  0.017       False\n",
      "S5_bin2           -0.0229931  -  0.017   +  0.017       False\n",
      "S8_bin2          -0.00848575  -  0.017   +  0.017       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin2/fit_results_gen_physical_bin2.json\n",
      "\n",
      "============================================================\n",
      "Procesando bin3 con rango q2: [4.0, 6.0]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n",
      "name        value  (rounded)                minos    at limit\n",
      "--------  ------------------  -------------------  ----------\n",
      "FL_bin3             0.692539  -   0.01   + 0.0099       False\n",
      "S3_bin3           -0.0240208  -  0.014   +  0.014       False\n",
      "S9_bin3           0.00778355  -  0.014   +  0.014       False\n",
      "AFB_bin3          0.00287143  - 0.0092   + 0.0091       False\n",
      "S4_bin3            -0.221496  -  0.015   +  0.015       False\n",
      "S7_bin3            0.0154887  -  0.017   +  0.017       False\n",
      "S5_bin3           -0.0104818  -  0.016   +  0.016       False\n",
      "S8_bin3            0.0354553  -  0.017   +  0.017       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin3/fit_results_gen_physical_bin3.json\n",
      "\n",
      "============================================================\n",
      "Procesando bin4 con rango q2: [6.0, 7.0]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n",
      "name        value  (rounded)                minos    at limit\n",
      "--------  ------------------  -------------------  ----------\n",
      "FL_bin4             0.633772  -  0.014   +  0.013       False\n",
      "S3_bin4            0.0141895  -  0.019   +  0.019       False\n",
      "S9_bin4           0.00196241  -  0.019   +  0.019       False\n",
      "AFB_bin4           0.0155526  -  0.013   +  0.013       False\n",
      "S4_bin4            -0.241357  -   0.02   +   0.02       False\n",
      "S7_bin4           -0.0229968  -  0.021   +  0.021       False\n",
      "S5_bin4         -0.000778545  -  0.021   +  0.021       False\n",
      "S8_bin4           -0.0310896  -  0.022   +  0.022       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin4/fit_results_gen_physical_bin4.json\n",
      "\n",
      "============================================================\n",
      "Procesando bin5 con rango q2: [7.0, 8.0]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n",
      "name        value  (rounded)                minos    at limit\n",
      "--------  ------------------  -------------------  ----------\n",
      "FL_bin5             0.560379  -  0.014   +  0.014       False\n",
      "S3_bin5           -0.0414636  -  0.019   +  0.019       False\n",
      "S9_bin5           -0.0223709  -  0.019   +  0.019       False\n",
      "AFB_bin5          -0.0118492  -  0.013   +  0.013       False\n",
      "S4_bin5            -0.260388  -   0.02   +   0.02       False\n",
      "S7_bin5            -0.027425  -  0.021   +  0.021       False\n",
      "S5_bin5           0.00119802  -   0.02   +   0.02       False\n",
      "S8_bin5            0.0373827  -  0.022   +  0.022       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin5/fit_results_gen_physical_bin5.json\n",
      "\n",
      "============================================================\n",
      "Procesando bin7 con rango q2: [11.0, 12.5]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n",
      "name        value  (rounded)                minos    at limit\n",
      "--------  ------------------  -------------------  ----------\n",
      "FL_bin7             0.436388  -   0.01   +   0.01       False\n",
      "S3_bin7           -0.0629046  -  0.016   +  0.015       False\n",
      "S9_bin7           -0.0198202  -  0.015   +  0.015       False\n",
      "AFB_bin7          0.00579761  -  0.011   +  0.011       False\n",
      "S4_bin7            -0.290681  -  0.014   +  0.014       False\n",
      "S7_bin7           0.00646981  -  0.015   +  0.015       False\n",
      "S5_bin7          -0.00517674  -  0.014   +  0.014       False\n",
      "S8_bin7           -0.0130174  -  0.016   +  0.016       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin7/fit_results_gen_physical_bin7.json\n",
      "\n",
      "============================================================\n",
      "Procesando bin9 con rango q2: [15.0, 17.0]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n",
      "name        value  (rounded)                minos    at limit\n",
      "--------  ------------------  -------------------  ----------\n",
      "FL_bin9             0.376005  - 0.0095   + 0.0095       False\n",
      "S3_bin9            -0.150949  -  0.014   +  0.014       False\n",
      "S9_bin9          -0.00922202  -  0.015   +  0.015       False\n",
      "AFB_bin9          0.00984435  -  0.011   +  0.011       False\n",
      "S4_bin9             -0.30076  -  0.013   +  0.014       False\n",
      "S7_bin9           -0.0035294  -  0.015   +  0.015       False\n",
      "S5_bin9           -0.0167139  -  0.013   +  0.013       False\n",
      "S8_bin9          0.000520797  -  0.016   +  0.015       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin9/fit_results_gen_physical_bin9.json\n",
      "\n",
      "============================================================\n",
      "Procesando bin10 con rango q2: [17.0, 23.0]\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      ">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\n",
      "============================================================\n",
      "name         value  (rounded)                minos    at limit\n",
      "---------  ------------------  -------------------  ----------\n",
      "FL_bin10              0.34649  -  0.012   +  0.012       False\n",
      "S3_bin10            -0.257922  -  0.016   +  0.017       False\n",
      "S9_bin10           -0.0372748  -  0.019   +  0.019       False\n",
      "AFB_bin10         0.000902186  -  0.014   +  0.014       False\n",
      "S4_bin10            -0.316875  -  0.014   +  0.015       False\n",
      "S7_bin10            0.0245412  -  0.019   +  0.019       False\n",
      "S5_bin10          -0.00541006  -  0.015   +  0.015       False\n",
      "S8_bin10            0.0353432  -   0.02   +   0.02       False\n",
      "\n",
      "------------------------------------------------------------\n",
      "[CheckPoint] Resultados guardados en: fit_results/gen_phy/bin10/fit_results_gen_physical_bin10.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q2_bins = {\"bin1\":[1.1, 2.0],\"bin2\": [2.0, 4.0],\"bin3\":[4.0, 6.0], \"bin4\":[6.0, 7.0], \"bin5\":[7.0, 8.0],\"bin7\":[11.0, 12.5], \"bin9\":[15.0, 17.0], \"bin10\":[17.0, 23.0]}\n",
    "\n",
    "for binN in q2_bins.keys():\n",
    "    print(f\"\\n{'='*60}\\nProcesando {binN} con rango q2: {q2_bins[binN]}\\n{'='*60}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # CONFIGURACIÓN DEL ESPACIO \n",
    "    # ======================================================\n",
    "    cos_l = zfit.Space('cos_l', limits=(-1, 1))\n",
    "    cos_k = zfit.Space('cos_k', limits=(-1, 1))\n",
    "    phi   = zfit.Space('phi',   limits=(-np.pi, np.pi)) \n",
    "    obs_ang = cos_l * cos_k * phi  \n",
    "\n",
    "\n",
    "    # Parámetros Físicos con límites\n",
    "    FL  = zfit.Parameter(f'FL_{binN}',  0.5)\n",
    "    S3  = zfit.Parameter(f'S3_{binN}',  0.0)\n",
    "    S9  = zfit.Parameter(f'S9_{binN}',  0.0)\n",
    "    AFB = zfit.Parameter(f'AFB_{binN}', 0.0)\n",
    "    S4  = zfit.Parameter(f'S4_{binN}',  0.0)\n",
    "    S7  = zfit.Parameter(f'S7_{binN}',  0.0)\n",
    "    S5  = zfit.Parameter(f'S5_{binN}',  0.0)\n",
    "    S8  = zfit.Parameter(f'S8_{binN}',  0.0)\n",
    "    # Listas auxiliares\n",
    "    r_keys = ['FL', 'S3', 'S9', 'AFB', 'S4', 'S7', 'S5', 'S8']\n",
    "    fit_params_list_phy = [FL, S3, S9, AFB, S4, S7, S5, S8]\n",
    "\n",
    "    # ======================================================\n",
    "    # CONSTRUCCIÓN DE PDFs Y CARGA DE DATOS\n",
    "    # ======================================================\n",
    "\n",
    "    # PDF  \n",
    "    pdf_ang_phy = FullAngular_Physical_PDF(obs_ang, FL, S3, S9, AFB, S4, S7, S5, S8)\n",
    "    # Carga de Datos\n",
    "    obs_Gen_q2 = select_q2_bin(obs_Gen, binN, \"q2Gen\")\n",
    "    data_true = zfit.Data.from_numpy(array=obs_Gen_q2[[\"gen_cosThetaL\", \"gen_cosThetaK\", \"gen_phi\"]].to_numpy(), obs=obs_ang)\n",
    "\n",
    "    # ======================================================\n",
    "    # FITS\n",
    "    # ======================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\">>> INICIANDO FIT GEN LEVEL PHYSICAL PDF <<<\")\n",
    "    print(\"=\"*60)\n",
    "    result_gen_phy, errors_gen_phy = run_fit(pdf_ang_phy, data_true)\n",
    "    print(result_gen_phy.params)\n",
    "    # results_gen_save = save_fit_results(result_gen, binN, base_dir=\"fit_results/gen\", name=f\"fit_results_gen_transformed_{binN}\")\n",
    "    phy_values = [result_gen_phy.params[p]['value'] for p in fit_params_list_phy]\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    save_correlation_matrix(result_gen_phy, fit_params_list_phy, binN, out_dir=f\"fit_results/gen_phy/{binN}\")\n",
    "    results_gen_save = save_fit_results(result_gen_phy, binN, base_dir=\"fit_results/gen_phy\", name=f\"fit_results_gen_physical_{binN}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_gen_phy_fit.txt', 'w') as archivo:\n",
    "    archivo.write(data_gen_phy_fit.stdout) \n",
    "    archivo.write(data_gen_phy_fit.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b2b58",
   "metadata": {},
   "source": [
    "# Gen  FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0dcfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture data_gen_fit\n",
    "\n",
    "q2_bins = {\"bin1\":[1.1, 2.0],\"bin2\": [2.0, 4.0],\"bin3\":[4.0, 6.0], \"bin4\":[6.0, 7.0], \"bin5\":[7.0, 8.0],\"bin7\":[11.0, 12.5], \"bin9\":[15.0, 17.0], \"bin10\":[17.0, 23.0]}\n",
    "\n",
    "for binN in q2_bins.keys():\n",
    "    print(f\"\\n{'='*60}\\nProcesando {binN} con rango q2: {q2_bins[binN]}\\n{'='*60}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # CONFIGURACIÓN DEL ESPACIO \n",
    "    # ======================================================\n",
    "    cos_l = zfit.Space('cos_l', limits=(-1, 1))\n",
    "    cos_k = zfit.Space('cos_k', limits=(-1, 1))\n",
    "    phi   = zfit.Space('phi',   limits=(-np.pi, np.pi)) \n",
    "    obs_ang = cos_l * cos_k * phi  \n",
    "\n",
    "    lim_val = 150.0 \n",
    "\n",
    "    # Parámetros Físicos con límites\n",
    "    rFL  = zfit.Parameter(f'rFL_{binN}',  0.5, lower_limit=-lim_val, upper_limit=lim_val)\n",
    "    rS3  = zfit.Parameter(f'rS3_{binN}',  0.0, lower_limit=-lim_val, upper_limit=lim_val)\n",
    "    rS9  = zfit.Parameter(f'rS9_{binN}',  0.0, lower_limit=-lim_val, upper_limit=lim_val)\n",
    "    rAFB = zfit.Parameter(f'rAFB_{binN}', 0.0, lower_limit=-lim_val, upper_limit=lim_val)\n",
    "    rS4  = zfit.Parameter(f'rS4_{binN}',  0.0, lower_limit=-0.1, upper_limit=0.1)\n",
    "    rS7  = zfit.Parameter(f'rS7_{binN}',  0.0, lower_limit=-lim_val, upper_limit=lim_val)\n",
    "    rS5  = zfit.Parameter(f'rS5_{binN}',  0.0, lower_limit=-lim_val, upper_limit=lim_val)\n",
    "    rS8  = zfit.Parameter(f'rS8_{binN}',  0.0, lower_limit=-lim_val, upper_limit=lim_val)\n",
    "    # Listas auxiliares\n",
    "    r_keys = ['rFL', 'rS3', 'rS9', 'rAFB', 'rS4', 'rS7', 'rS5', 'rS8']\n",
    "    fit_params_list = [rFL, rS3, rS9, rAFB, rS4, rS7, rS5, rS8]\n",
    "\n",
    "    # ======================================================\n",
    "    # CONSTRUCCIÓN DE PDFs Y CARGA DE DATOS\n",
    "    # ======================================================\n",
    "\n",
    "    # PDF  Transformada\n",
    "    pdf_ang_trans = FullAngular_Transformed_PDF(obs_ang, rFL, rS3, rS9, rAFB, rS4, rS7, rS5, rS8)\n",
    "    # Carga de Datos\n",
    "    obs_Gen_q2 = select_q2_bin(obs_Gen, binN, \"q2Gen\")\n",
    "    data_true = zfit.Data.from_numpy(array=obs_Gen_q2[[\"gen_cosThetaL\", \"gen_cosThetaK\", \"gen_phi\"]].to_numpy(), obs=obs_ang)\n",
    "\n",
    "    # ======================================================\n",
    "    # FITS\n",
    "    # ======================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\">>> INICIANDO FIT GEN LEVEL \")\n",
    "    print(\"=\"*60)\n",
    "    result_gen, errors_gen = run_fit(pdf_ang_trans, data_true)\n",
    "    print(result_gen.params)\n",
    "    # results_gen_save = save_fit_results(result_gen, binN, base_dir=\"fit_results/gen\", name=f\"fit_results_gen_transformed_{binN}\")\n",
    "    r_values = [result_gen.params[p]['value'] for p in fit_params_list]\n",
    "    phys_vals_gen = apply_transformation_equations(*r_values)\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(f\"RESUMEN DE OBSERVABLES FÍSICOS (Bin: {binN})\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"{'Observable':<10} | {'Valor Físico':<15}\")\n",
    "    print(\"-\"*60)\n",
    "    print_order = ['FL', 'AFB', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9']    \n",
    "    for key in print_order:\n",
    "        val = phys_vals_gen.get(key, 0.0)\n",
    "        print(f\"{key:<10} | {val:>15.6f}\")\n",
    "    print(\"-\"*60 + \"\\n\")\n",
    "\n",
    "    save_correlation_matrix(result_gen, fit_params_list, binN, out_dir=f\"fit_results/gen/{binN}\")\n",
    "    r_values = [result_gen.params[p]['value'] for p in fit_params_list]\n",
    "    phys_vals_gen = apply_transformation_equations(*r_values)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3238ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_gen_fit.txt', 'w') as archivo:\n",
    "    archivo.write(data_gen_fit.stdout) \n",
    "    archivo.write(data_gen_fit.stderr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4330b07",
   "metadata": {},
   "source": [
    "# Fit efficiecnasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture mi_registro\n",
    "q2_bins = {\"bin1\":[1.1, 2.0],\"bin2\": [2.0, 4.0],\"bin3\":[4.0, 6.0], \"bin4\":[6.0, 7.0], \"bin5\":[7.0, 8.0],\"bin7\":[11.0, 12.5], \"bin9\":[15.0, 17.0], \"bin10\":[17.0, 23.0]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for binN in q2_bins.keys():\n",
    "    print(f\"\\n{'='*60}\\nProcesando {binN} con rango q2: {q2_bins[binN]}\\n{'='*60}\")\n",
    "\n",
    "    # ======================================================\n",
    "    # CONFIGURACIÓN DEL ESPACIO \n",
    "    # ======================================================\n",
    "    cos_l = zfit.Space('cos_l', limits=(-1, 1))\n",
    "    cos_k = zfit.Space('cos_k', limits=(-1, 1))\n",
    "    phi   = zfit.Space('phi',   limits=(-np.pi, np.pi)) \n",
    "    obs_ang = cos_l * cos_k * phi  \n",
    "\n",
    "    # Parámetros Físicos\n",
    "    rFL  = zfit.Parameter(f'rFL_{binN}',  0.1, step_size=0.1)\n",
    "    rS3  = zfit.Parameter(f'rS3_{binN}',  0.0, step_size=0.1)\n",
    "    rS9  = zfit.Parameter(f'rS9_{binN}',  0.0, step_size=0.1)\n",
    "    rAFB = zfit.Parameter(f'rAFB_{binN}', 0.0, step_size=0.1)\n",
    "    rS4  = zfit.Parameter(f'rS4_{binN}',  0.0, step_size=0.1)\n",
    "    rS7  = zfit.Parameter(f'rS7_{binN}',  0.0, step_size=0.1)\n",
    "    rS5  = zfit.Parameter(f'rS5_{binN}',  0.0, step_size=0.1)\n",
    "    rS8  = zfit.Parameter(f'rS8_{binN}',  0.0, step_size=0.1)\n",
    "    # Listas auxiliares\n",
    "    r_keys = ['rFL', 'rS3', 'rS9', 'rAFB', 'rS4', 'rS7', 'rS5', 'rS8']\n",
    "    fit_params_list = [rFL, rS3, rS9, rAFB, rS4, rS7, rS5, rS8]\n",
    "\n",
    "    # ======================================================\n",
    "    # CONSTRUCCIÓN DE PDFs Y CARGA DE DATOS\n",
    "    # ======================================================\n",
    "\n",
    "    # PDF  Transformada\n",
    "    pdf_ang_trans = FullAngular_Transformed_PDF(obs_ang, rFL, rS3, rS9, rAFB, rS4, rS7, rS5, rS8)\n",
    "\n",
    "    # PDF de Eficiencia\n",
    "    coef_acc, nx_acc, ny_acc = load_bernstein_model(f\"models/{binN}/acc_gen_model_{binN}.json\")\n",
    "    coef_acc_phi, n_phi_acc = load_bernstein1d_model(f\"models/{binN}/acc_gen_model_phi_{binN}.json\")\n",
    "\n",
    "    coef_reco, nx_reco, ny_reco = load_bernstein_model(f\"models/{binN}/eff_reco_model_{binN}.json\")\n",
    "    coef_reco_phi, n_phi_reco = load_bernstein1d_model(f\"models/{binN}/eff_reco_model_phi_{binN}.json\")\n",
    "\n",
    "    eff_pdf = Efficiency_Bernstein_Factorized(\n",
    "        obs=obs_ang, coef_acc_2d=coef_acc, coef_acc_phi=coef_acc_phi, nx_acc=nx_acc, ny_acc=ny_acc, n_phi_acc=n_phi_acc,\n",
    "        coef_reco_2d=coef_reco, coef_reco_phi=coef_reco_phi,nx_reco=nx_reco, ny_reco=ny_reco, n_phi_reco=n_phi_reco, name=f\"Eff_Model_{binN}\")\n",
    "    pdf_sig = zfit.pdf.ProductPDF([pdf_ang_trans, eff_pdf])\n",
    "\n",
    "\n",
    "    # Carga de Datos\n",
    "    obs_Gen_q2 = select_q2_bin(obs_Gen, binN, \"q2Gen\")\n",
    "    obs_RecoFtr_q2 = select_q2_bin(obs_RecoFtr, binN, \"q2\")\n",
    "\n",
    "    data_true = zfit.Data.from_numpy(array=obs_Gen_q2[[\"gen_cosThetaL\", \"gen_cosThetaK\", \"gen_phi\"]].to_numpy(), obs=obs_ang)\n",
    "    data_reco = zfit.Data.from_numpy(array=obs_RecoFtr_q2[[\"CosThetaL\", \"CosThetaK\", \"Phi\"]].to_numpy(), obs=obs_ang)\n",
    "    \n",
    "    # ======================================================\n",
    "    # FITS\n",
    "    # ======================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\">>> INICIANDO FIT GEN LEVEL (CONTROL)\")\n",
    "    print(\"=\"*60)\n",
    "    result_gen, errors_gen = run_fit(pdf_ang_trans, data_true)\n",
    "    print(result_gen.params)\n",
    "    results_gen_save = save_fit_results(result_gen, binN, base_dir=\"fit_results/gen\", name=f\"fit_results_gen_transformed_{binN}\")\n",
    "    r_values = [result_gen.params[p]['value'] for p in fit_params_list]\n",
    "    phys_vals_gen = apply_transformation_equations(*r_values)\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(f\"RESUMEN DE OBSERVABLES FÍSICOS (Bin: {binN})\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"{'Observable':<10} | {'Valor Físico':<15}\")\n",
    "    print(\"-\"*60)\n",
    "    print_order = ['FL', 'AFB', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9']    \n",
    "    for key in print_order:\n",
    "        val = phys_vals_gen.get(key, 0.0)\n",
    "        print(f\"{key:<10} | {val:>15.6f}\")\n",
    "    print(\"-\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\">>> INICIANDO FIT RECO)\")\n",
    "    # print(\"=\"*60)\n",
    "    # for p in fit_params_list: p.set_value(0.01)    \n",
    "    # pdf_sig.update_integration_options(max_draws=200000, tol=1e-5)\n",
    "    # result_reco, errors_reco = run_fit(pdf_sig, data_reco)\n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\">>> RESULTADOS FINALES DEL FIT RECO\")\n",
    "    # print(\"=\"*60)\n",
    "    # print(result_reco)\n",
    "    # results_save = save_fit_results(result_reco, binN, base_dir=\"fit_results/reco\")\n",
    "\n",
    "    # # callculo y tabla de Observables Físicos para RECO\n",
    "    # r_values_reco = [result_reco.params[p]['value'] for p in fit_params_list]\n",
    "    # phys_vals_reco = apply_transformation_equations(*r_values_reco)\n",
    "    # print(\"\\n\" + \"-\"*60)\n",
    "    # print(f\"RESUMEN DE OBSERVABLES FÍSICOS RECO (Bin: {binN})\")\n",
    "    # print(\"-\"*60)\n",
    "    # print(f\"{'Observable':<10} | {'Valor Físico':<15}\")\n",
    "    # print(\"-\"*60)\n",
    "    # print_order = ['FL', 'AFB', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9']    \n",
    "    # for key in print_order:\n",
    "    #     val = phys_vals_reco.get(key, 0.0)\n",
    "    #     print(f\"{key:<10} | {val:>15.6f}\")\n",
    "    # print(\"-\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Guardar en el archivo de texto\n",
    "with open('registro_celda.txt', 'w') as archivo:\n",
    "    archivo.write(mi_registro.stdout) # Guarda los prints normales\n",
    "    archivo.write(mi_registro.stderr) # Guarda los mensajes del sistema/TensorFlow\n",
    "\n",
    "# 2. (Opcional) Mostrarlo en la pantalla del notebook si también quieres verlo\n",
    "mi_registro.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0d4618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haza_wokr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
